{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 10\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab\n",
    "h1_size = 640\n",
    "h2_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                if l[0] not in string.punctuation:\n",
    "                    dataset[\"word\"].append(l[0])\n",
    "                    dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=20, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Sadducees</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word ne-tag\n",
       "1335  Sadducees    ORG"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head()\n",
    "en_corpus.loc[en_corpus['ne-tag'] == 'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4379</td>\n",
       "      <td>4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>313</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4379   4170\n",
       "unique   904      5\n",
       "top      the      O\n",
       "freq     313   3779"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.3 %\n",
      "MISC % = 2.4 %\n",
      "PER % = 5.59 %\n",
      "LOC % = 0.91 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.16 %\n",
      "MISC % = 1.88 %\n",
      "PER % = 8.96 %\n",
      "LOC % = 1.99 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>O</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of     the    Holy  Spirit      In   first    book  \\\n",
       "0  4170.0   4170.0  4170.0  4170.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4170.0     0.0     0.0  4170.0  4170.0  4170.0   \n",
       "2     0.0      0.0     0.0  1390.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "3     0.0      0.0  4170.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4170.0  2085.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        O  ...  considered  dream  She  save  fulfill  Immanuel  us)  woke  \\\n",
       "0     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "1  4170.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "2     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "3     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "\n",
       "   sleep  knew  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "\n",
       "[5 rows x 903 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ankles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "count      903\n",
       "unique     903\n",
       "top     ankles\n",
       "freq         1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (210, 903) (903,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "883       Eliud\n",
       "884     Eleazar\n",
       "885     Matthan\n",
       "886     husband\n",
       "887    fourteen\n",
       "888   unwilling\n",
       "889       shame\n",
       "890    resolved\n",
       "891     divorce\n",
       "892     quietly\n",
       "893  considered\n",
       "894       dream\n",
       "895         She\n",
       "896        save\n",
       "897     fulfill\n",
       "898    Immanuel\n",
       "899         us)\n",
       "900        woke\n",
       "901       sleep\n",
       "902        knew"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (903,)\n",
      "(903, 210) (903,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def visualize(X, y):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_embeded = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.scatter(X_embeded[:, 0], X_embeded[:, 1], c=y)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (605, 210)\n",
      "y_train.shape = (605, 5)\n",
      "X_val.shape = (298, 210)\n",
      "y_val.shape = (298, 5)\n",
      "O % in training data = 87.93 %\n",
      "O % in validation data = 88.93 %\n",
      "MISC % in training data = 1.65 %\n",
      "MISC % in validation data = 0.34 %\n",
      "PER % in training data = 8.1 %\n",
      "PER % in validation data = 9.4 %\n",
      "LOC % in training data = 2.15 %\n",
      "LOC % in validation data = 1.34 %\n",
      "ORG % in training data = 0.17 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teofil</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Yohannes</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>Maria</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>Emmanuel</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>Yosef</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word ne-tag\n",
       "6       Teofil    PER\n",
       "15       Yesus    PER\n",
       "86    Yohannes    PER\n",
       "104      Yesus    PER\n",
       "230      Yesus    PER\n",
       "...        ...    ...\n",
       "3676     Maria    PER\n",
       "3697     Yesus    PER\n",
       "3740  Emmanuel    PER\n",
       "3750     Yosef    PER\n",
       "3778     Yesus    PER\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.loc[ewo_corpus['ne-tag'] == 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 84.15 %\n",
      "MISC % = 2.54 %\n",
      "PER % = 6.69 %\n",
      "LOC % = 1.03 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.94 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.3 %\n",
      "LOC % = 1.86 %\n",
      "ORG % = 0.2 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3779</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>209</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   3779   3570\n",
       "unique  1024      5\n",
       "top       \\n      O\n",
       "freq     209   3180"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sÃ²</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sÃ²      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)\n",
    "# ewo_fingerprints = scale(ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>obÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>yasÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>oyolÃ«ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>bÃ«yole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>AvÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>angavÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>oyÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>anganÃ²á¹…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1003        nlo\n",
       "1004        obÃ«\n",
       "1005      mbara\n",
       "1006    yabyali\n",
       "1007      dzili\n",
       "1008       yasÃ²\n",
       "1009    oyolÃ«ge\n",
       "1010       kode\n",
       "1011       dili\n",
       "1012     atoban\n",
       "1013        sik\n",
       "1014       Ntud\n",
       "1015     bÃ«yole\n",
       "1016   Emmanuel\n",
       "1017      AvÃ«bÃ«\n",
       "1018   angavÃ«bÃ«\n",
       "1019        oyÃ²\n",
       "1020  angabende\n",
       "1021    anganÃ²á¹…\n",
       "1022   angayole"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 210) (1023,)\n",
      "(1023, 210) (1023,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023,) 1023\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 210)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43207, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43207 to 0.42395, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42395 to 0.41322, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41322\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41322\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41322\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41322\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41322\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41322\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29256, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29256 to 0.21055, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21055\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21055\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21055\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21055\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21055\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21055\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.21055 to 0.19946, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08170, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08170\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04106, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04106\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10479, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10479 to 0.09295, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09295\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06284, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06284\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14826, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14826 to 0.09965, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09965 to 0.08594, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08594\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05611, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05611\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09740, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09740\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10457, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10457 to 0.06795, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06795 to 0.06787, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06787\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06787\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06787\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06787\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06787\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06787\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 2\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46661, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.46661\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46661 to 0.42855, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42855 to 0.40420, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40420 to 0.39653, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39653\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.39653\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39653\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.39653\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16687, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16687 to 0.15985, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15985\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15985\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15985 to 0.15759, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15759\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15759\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15759\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15759\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12063, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12063 to 0.11413, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11413 to 0.07712, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07712\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16143, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16143 to 0.04858, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04858\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08756, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08756\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05516, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05516\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08673, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08673\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05515, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05515\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10627, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07657, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07657 to 0.07143, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07143\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07143\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07143\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07143\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07143\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07143\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 3\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42835, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42835 to 0.42103, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42103 to 0.41373, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41373\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41373\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41373\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41373\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41373\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41373\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14430, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14430\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06664, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06664\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03679, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03679\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09432, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09432\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09432\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09432 to 0.09345, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09345\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09345\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09345\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09345\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09345\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06754, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06754\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07572, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07572\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05671, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10672, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10672\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06164, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06164\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 4\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49307, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49307 to 0.38290, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38290 to 0.37692, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37692\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37692\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37692\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37692\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37692\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37692\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14023, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14023\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07420, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07420\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05310, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09873, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09873\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09873 to 0.09158, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09158\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09158\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09158\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09158\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09158\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09158\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08254, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08254 to 0.06597, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06597\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08720, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08720\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08720 to 0.06731, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06731\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05277, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05277\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10116, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10116\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05926, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 5\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43570, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.43570\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43570 to 0.42514, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42514\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42514\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.42514\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42514\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42514\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42514\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12717, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08346, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08346\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08346\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08346 to 0.07948, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07948\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07948\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07948\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07948\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07948\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07948\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03988, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03988\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09389, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09389 to 0.08778, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08778 to 0.08746, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08746 to 0.08660, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08660\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08660\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08660\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08660\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08660\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06495, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08567, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08567\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06000, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11618, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11618 to 0.11153, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07040, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07040 to 0.06698, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 6\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41312, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41312 to 0.37929, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37929\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15755, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15755 to 0.15210, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15210\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04715, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04715\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04722, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04722\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07886, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07886\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06726, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06562, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06562\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06008, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06008\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11356, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11356 to 0.11101, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11101\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05297, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05297\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 7\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43862, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.43862\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43862 to 0.39319, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39319\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39319\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39319\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.39319\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39319\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.39319\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13992, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13992\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09584, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09584 to 0.08325, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08325\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03081, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03081\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08504, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08504\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09352, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09352 to 0.07983, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07983\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06679, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06907, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06907\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11602, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11602 to 0.11406, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11406 to 0.11321, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11321\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11321\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11321\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11321\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11321\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11321\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08639, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08639 to 0.08200, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08200 to 0.07207, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07207\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07207 to 0.06675, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 8\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42380, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42380 to 0.41324, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41324 to 0.39107, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39107\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39107\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39107\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.39107\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39107\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.39107\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12766, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12766\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09540, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09540 to 0.08851, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08851 to 0.08162, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08162\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08162 to 0.06739, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06739\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06739\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06739\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06739\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03929, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03929\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07924, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07924\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07773, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07773\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08140, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08140\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05881, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10216, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10216\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09684, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09684 to 0.08628, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08628 to 0.08428, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08428 to 0.07408, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07408\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07408\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07408\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07408\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07408\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 9\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44523, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44523 to 0.42802, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.42802\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42802\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42802 to 0.41281, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41281\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41281\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41281\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41281\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17473, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17473\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17473\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17473 to 0.16023, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16023\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16023\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16023\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16023\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16023\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07679, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04351, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04351\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08035, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08035\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06100, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08972, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08972\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06141, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10707, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05882, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05882\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 10\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40435, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40435 to 0.37945, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37945\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37945\n",
      "number of correct positive predictions is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16830, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16830\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16830\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16830\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16830\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16830 to 0.16522, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16522\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16522\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16522\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09272, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09272 to 0.07662, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07662\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04399, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04399\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08189, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08189\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06053, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06053\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11453, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11453 to 0.07879, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07879\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05580, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05580\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10515, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10515 to 0.09414, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09414\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06327, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06327 to 0.06203, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06203\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>81.248</td>\n",
       "      <td>81.394</td>\n",
       "      <td>81.811</td>\n",
       "      <td>83.960</td>\n",
       "      <td>80.347</td>\n",
       "      <td>79.451000</td>\n",
       "      <td>82.414</td>\n",
       "      <td>84.589</td>\n",
       "      <td>81.258</td>\n",
       "      <td>76.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>85.030</td>\n",
       "      <td>87.203</td>\n",
       "      <td>88.090</td>\n",
       "      <td>86.176</td>\n",
       "      <td>87.975</td>\n",
       "      <td>88.520000</td>\n",
       "      <td>85.176</td>\n",
       "      <td>88.981</td>\n",
       "      <td>87.884</td>\n",
       "      <td>88.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>73.472</td>\n",
       "      <td>76.297</td>\n",
       "      <td>76.584</td>\n",
       "      <td>75.698</td>\n",
       "      <td>77.270</td>\n",
       "      <td>80.150000</td>\n",
       "      <td>72.100</td>\n",
       "      <td>78.937</td>\n",
       "      <td>75.725</td>\n",
       "      <td>80.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>81.614</td>\n",
       "      <td>80.883</td>\n",
       "      <td>79.467</td>\n",
       "      <td>82.696</td>\n",
       "      <td>79.325</td>\n",
       "      <td>74.123000</td>\n",
       "      <td>77.637</td>\n",
       "      <td>71.789</td>\n",
       "      <td>77.221</td>\n",
       "      <td>74.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>85.388</td>\n",
       "      <td>86.017</td>\n",
       "      <td>82.054</td>\n",
       "      <td>84.223</td>\n",
       "      <td>81.583</td>\n",
       "      <td>77.434000</td>\n",
       "      <td>82.351</td>\n",
       "      <td>75.383</td>\n",
       "      <td>82.776</td>\n",
       "      <td>78.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>71.111</td>\n",
       "      <td>69.258</td>\n",
       "      <td>67.221</td>\n",
       "      <td>69.073</td>\n",
       "      <td>65.648</td>\n",
       "      <td>61.573000</td>\n",
       "      <td>67.130</td>\n",
       "      <td>59.628</td>\n",
       "      <td>67.316</td>\n",
       "      <td>63.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>80.715</td>\n",
       "      <td>80.396</td>\n",
       "      <td>79.378</td>\n",
       "      <td>82.479</td>\n",
       "      <td>79.209</td>\n",
       "      <td>84.538889</td>\n",
       "      <td>79.428</td>\n",
       "      <td>75.168</td>\n",
       "      <td>78.480</td>\n",
       "      <td>83.557778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>84.408</td>\n",
       "      <td>86.312</td>\n",
       "      <td>84.178</td>\n",
       "      <td>84.391</td>\n",
       "      <td>83.979</td>\n",
       "      <td>81.180000</td>\n",
       "      <td>82.394</td>\n",
       "      <td>79.657</td>\n",
       "      <td>84.609</td>\n",
       "      <td>79.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>71.225</td>\n",
       "      <td>72.216</td>\n",
       "      <td>70.714</td>\n",
       "      <td>71.263</td>\n",
       "      <td>70.485</td>\n",
       "      <td>68.208000</td>\n",
       "      <td>67.742</td>\n",
       "      <td>66.359</td>\n",
       "      <td>70.549</td>\n",
       "      <td>66.652000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       0       0       0       0          0       0       0  \\\n",
       "P_test    81.248  81.394  81.811  83.960  80.347  79.451000  82.414  84.589   \n",
       "P_train   85.030  87.203  88.090  86.176  87.975  88.520000  85.176  88.981   \n",
       "P_ewo     73.472  76.297  76.584  75.698  77.270  80.150000  72.100  78.937   \n",
       "R_test    81.614  80.883  79.467  82.696  79.325  74.123000  77.637  71.789   \n",
       "R_train   85.388  86.017  82.054  84.223  81.583  77.434000  82.351  75.383   \n",
       "R_ewo     71.111  69.258  67.221  69.073  65.648  61.573000  67.130  59.628   \n",
       "F1-test   80.715  80.396  79.378  82.479  79.209  84.538889  79.428  75.168   \n",
       "F1-train  84.408  86.312  84.178  84.391  83.979  81.180000  82.394  79.657   \n",
       "F1-ewo    71.225  72.216  70.714  71.263  70.485  68.208000  67.742  66.359   \n",
       "\n",
       "               0          0  \n",
       "P_test    81.258  76.793000  \n",
       "P_train   87.884  88.841000  \n",
       "P_ewo     75.725  80.250000  \n",
       "R_test    77.221  74.117000  \n",
       "R_train   82.776  78.512000  \n",
       "R_ewo     67.316  63.055000  \n",
       "F1-test   78.480  83.557778  \n",
       "F1-train  84.609  79.088000  \n",
       "F1-ewo    70.549  66.652000  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>81.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>87.387600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>76.648300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>77.887200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>81.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>66.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>80.334967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>83.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>69.541300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "P_test    81.326500\n",
       "P_train   87.387600\n",
       "P_ewo     76.648300\n",
       "R_test    77.887200\n",
       "R_train   81.572100\n",
       "R_ewo     66.101300\n",
       "F1-test   80.334967\n",
       "F1-train  83.019600\n",
       "F1-ewo    69.541300"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>2.212128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>1.451817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>2.656602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>3.599838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>3.470942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>3.645009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>2.706969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>2.356478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>2.100916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "P_test    2.212128\n",
       "P_train   1.451817\n",
       "P_ewo     2.656602\n",
       "R_test    3.599838\n",
       "R_train   3.470942\n",
       "R_ewo     3.645009\n",
       "F1-test   2.706969\n",
       "F1-train  2.356478\n",
       "F1-ewo    2.100916"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>98.007000</td>\n",
       "      <td>98.212</td>\n",
       "      <td>98.062000</td>\n",
       "      <td>98.027000</td>\n",
       "      <td>98.042000</td>\n",
       "      <td>97.853000</td>\n",
       "      <td>97.841000</td>\n",
       "      <td>97.766000</td>\n",
       "      <td>98.108000</td>\n",
       "      <td>97.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>98.120000</td>\n",
       "      <td>98.149</td>\n",
       "      <td>97.658000</td>\n",
       "      <td>97.962000</td>\n",
       "      <td>97.602000</td>\n",
       "      <td>97.095000</td>\n",
       "      <td>97.764000</td>\n",
       "      <td>96.852000</td>\n",
       "      <td>97.785000</td>\n",
       "      <td>97.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>97.924000</td>\n",
       "      <td>98.287</td>\n",
       "      <td>98.495000</td>\n",
       "      <td>98.119000</td>\n",
       "      <td>98.510000</td>\n",
       "      <td>98.664000</td>\n",
       "      <td>97.966000</td>\n",
       "      <td>98.747000</td>\n",
       "      <td>98.454000</td>\n",
       "      <td>98.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>77.532222</td>\n",
       "      <td>76.475</td>\n",
       "      <td>75.846000</td>\n",
       "      <td>77.350000</td>\n",
       "      <td>77.374444</td>\n",
       "      <td>77.412222</td>\n",
       "      <td>76.367778</td>\n",
       "      <td>76.634444</td>\n",
       "      <td>75.932000</td>\n",
       "      <td>77.175556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>75.849000</td>\n",
       "      <td>89.917</td>\n",
       "      <td>96.528000</td>\n",
       "      <td>80.809000</td>\n",
       "      <td>86.667000</td>\n",
       "      <td>87.142000</td>\n",
       "      <td>74.265000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>96.210000</td>\n",
       "      <td>83.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>66.994000</td>\n",
       "      <td>68.252</td>\n",
       "      <td>63.302000</td>\n",
       "      <td>62.267000</td>\n",
       "      <td>58.767000</td>\n",
       "      <td>58.290000</td>\n",
       "      <td>67.287000</td>\n",
       "      <td>56.040000</td>\n",
       "      <td>63.643000</td>\n",
       "      <td>60.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>88.362000</td>\n",
       "      <td>89.665</td>\n",
       "      <td>87.967000</td>\n",
       "      <td>88.360000</td>\n",
       "      <td>87.884000</td>\n",
       "      <td>84.461000</td>\n",
       "      <td>86.634000</td>\n",
       "      <td>82.386000</td>\n",
       "      <td>88.296000</td>\n",
       "      <td>82.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>86.404000</td>\n",
       "      <td>88.365</td>\n",
       "      <td>87.943000</td>\n",
       "      <td>86.882000</td>\n",
       "      <td>88.236000</td>\n",
       "      <td>89.866000</td>\n",
       "      <td>86.355000</td>\n",
       "      <td>88.695000</td>\n",
       "      <td>88.988000</td>\n",
       "      <td>89.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>91.395000</td>\n",
       "      <td>91.386</td>\n",
       "      <td>88.909000</td>\n",
       "      <td>90.656000</td>\n",
       "      <td>88.141000</td>\n",
       "      <td>81.928000</td>\n",
       "      <td>88.442000</td>\n",
       "      <td>81.294000</td>\n",
       "      <td>88.361000</td>\n",
       "      <td>83.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>80.544444</td>\n",
       "      <td>77.416</td>\n",
       "      <td>77.886667</td>\n",
       "      <td>80.355556</td>\n",
       "      <td>79.045556</td>\n",
       "      <td>79.998889</td>\n",
       "      <td>74.887778</td>\n",
       "      <td>78.501111</td>\n",
       "      <td>79.768889</td>\n",
       "      <td>79.021111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>74.182000</td>\n",
       "      <td>81.810</td>\n",
       "      <td>78.044000</td>\n",
       "      <td>74.302000</td>\n",
       "      <td>77.847000</td>\n",
       "      <td>74.741000</td>\n",
       "      <td>77.097000</td>\n",
       "      <td>81.587000</td>\n",
       "      <td>74.120000</td>\n",
       "      <td>77.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>72.608000</td>\n",
       "      <td>75.462</td>\n",
       "      <td>66.569000</td>\n",
       "      <td>71.546000</td>\n",
       "      <td>68.136000</td>\n",
       "      <td>71.046000</td>\n",
       "      <td>65.532000</td>\n",
       "      <td>63.796000</td>\n",
       "      <td>71.508000</td>\n",
       "      <td>67.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>60.002000</td>\n",
       "      <td>60.002</td>\n",
       "      <td>58.335000</td>\n",
       "      <td>75.002500</td>\n",
       "      <td>61.113333</td>\n",
       "      <td>61.113333</td>\n",
       "      <td>61.907143</td>\n",
       "      <td>55.556667</td>\n",
       "      <td>61.113333</td>\n",
       "      <td>61.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0       0          0          0          0          0  \\\n",
       "F1-O     98.007000  98.212  98.062000  98.027000  98.042000  97.853000   \n",
       "P-O      98.120000  98.149  97.658000  97.962000  97.602000  97.095000   \n",
       "R-O      97.924000  98.287  98.495000  98.119000  98.510000  98.664000   \n",
       "F1-MISC  77.532222  76.475  75.846000  77.350000  77.374444  77.412222   \n",
       "P-MISC   75.849000  89.917  96.528000  80.809000  86.667000  87.142000   \n",
       "R-MISC   66.994000  68.252  63.302000  62.267000  58.767000  58.290000   \n",
       "F1-PER   88.362000  89.665  87.967000  88.360000  87.884000  84.461000   \n",
       "P-PER    86.404000  88.365  87.943000  86.882000  88.236000  89.866000   \n",
       "R-PER    91.395000  91.386  88.909000  90.656000  88.141000  81.928000   \n",
       "F1-LOC   80.544444  77.416  77.886667  80.355556  79.045556  79.998889   \n",
       "P-LOC    74.182000  81.810  78.044000  74.302000  77.847000  74.741000   \n",
       "R-LOC    72.608000  75.462  66.569000  71.546000  68.136000  71.046000   \n",
       "F1-ORG   60.002000  60.002  58.335000  75.002500  61.113333  61.113333   \n",
       "P-ORG    25.000000  25.000  20.000000  25.000000  30.000000  30.000000   \n",
       "R-ORG    40.000000  40.000  30.000000  40.000000  50.000000  50.000000   \n",
       "\n",
       "                 0          0          0          0  \n",
       "F1-O     97.841000  97.766000  98.108000  97.851000  \n",
       "P-O      97.764000  96.852000  97.785000  97.281000  \n",
       "R-O      97.966000  98.747000  98.454000  98.496000  \n",
       "F1-MISC  76.367778  76.634444  75.932000  77.175556  \n",
       "P-MISC   74.265000  90.000000  96.210000  83.670000  \n",
       "R-MISC   67.287000  56.040000  63.643000  60.219000  \n",
       "F1-PER   86.634000  82.386000  88.296000  82.130000  \n",
       "P-PER    86.355000  88.695000  88.988000  89.172000  \n",
       "R-PER    88.442000  81.294000  88.361000  83.794000  \n",
       "F1-LOC   74.887778  78.501111  79.768889  79.021111  \n",
       "P-LOC    77.097000  81.587000  74.120000  77.610000  \n",
       "R-LOC    65.532000  63.796000  71.508000  67.859000  \n",
       "F1-ORG   61.907143  55.556667  61.113333  61.113333  \n",
       "P-ORG    35.000000  15.000000  30.000000  30.000000  \n",
       "R-ORG    60.000000  20.000000  50.000000  50.000000  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>76.809967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>86.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>62.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>86.614500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>88.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>87.430600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>78.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>77.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>69.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>61.525864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.976900\n",
       "P-O      97.626800\n",
       "R-O      98.366200\n",
       "F1-MISC  76.809967\n",
       "P-MISC   86.105700\n",
       "R-MISC   62.506100\n",
       "F1-PER   86.614500\n",
       "P-PER    88.090600\n",
       "R-PER    87.430600\n",
       "F1-LOC   78.742600\n",
       "P-LOC    77.134000\n",
       "R-LOC    69.406200\n",
       "F1-ORG   61.525864\n",
       "P-ORG    26.500000\n",
       "R-ORG    43.000000"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.142011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.431592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.282568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>0.638304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>7.609873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>4.173919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>2.672978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>1.198516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>3.763938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>1.701620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>2.882972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>3.607865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>5.087054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>5.797509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>11.595018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O      0.142011\n",
       "P-O       0.431592\n",
       "R-O       0.282568\n",
       "F1-MISC   0.638304\n",
       "P-MISC    7.609873\n",
       "R-MISC    4.173919\n",
       "F1-PER    2.672978\n",
       "P-PER     1.198516\n",
       "R-PER     3.763938\n",
       "F1-LOC    1.701620\n",
       "P-LOC     2.882972\n",
       "R-LOC     3.607865\n",
       "F1-ORG    5.087054\n",
       "P-ORG     5.797509\n",
       "R-ORG    11.595018"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.74800</td>\n",
       "      <td>97.68400</td>\n",
       "      <td>97.7580</td>\n",
       "      <td>97.938000</td>\n",
       "      <td>97.4920</td>\n",
       "      <td>97.6460</td>\n",
       "      <td>97.627000</td>\n",
       "      <td>97.5880</td>\n",
       "      <td>97.569000</td>\n",
       "      <td>97.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.64800</td>\n",
       "      <td>97.52000</td>\n",
       "      <td>97.3160</td>\n",
       "      <td>97.648000</td>\n",
       "      <td>97.2630</td>\n",
       "      <td>96.8660</td>\n",
       "      <td>97.159000</td>\n",
       "      <td>96.6280</td>\n",
       "      <td>97.045000</td>\n",
       "      <td>96.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>97.88300</td>\n",
       "      <td>97.88300</td>\n",
       "      <td>98.2600</td>\n",
       "      <td>98.263000</td>\n",
       "      <td>97.7530</td>\n",
       "      <td>98.5010</td>\n",
       "      <td>98.126000</td>\n",
       "      <td>98.6170</td>\n",
       "      <td>98.131000</td>\n",
       "      <td>98.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>43.33375</td>\n",
       "      <td>39.16750</td>\n",
       "      <td>39.1675</td>\n",
       "      <td>43.333750</td>\n",
       "      <td>39.1675</td>\n",
       "      <td>39.1675</td>\n",
       "      <td>35.833750</td>\n",
       "      <td>39.1675</td>\n",
       "      <td>39.167500</td>\n",
       "      <td>43.333750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>40.00000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>31.66700</td>\n",
       "      <td>31.66700</td>\n",
       "      <td>26.6670</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>26.6670</td>\n",
       "      <td>26.6670</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>26.6670</td>\n",
       "      <td>26.667000</td>\n",
       "      <td>31.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>84.75000</td>\n",
       "      <td>85.50400</td>\n",
       "      <td>83.3620</td>\n",
       "      <td>86.166000</td>\n",
       "      <td>84.8170</td>\n",
       "      <td>88.1600</td>\n",
       "      <td>85.916000</td>\n",
       "      <td>80.3880</td>\n",
       "      <td>83.864000</td>\n",
       "      <td>87.891111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>82.49600</td>\n",
       "      <td>84.05100</td>\n",
       "      <td>83.3840</td>\n",
       "      <td>84.051000</td>\n",
       "      <td>83.5870</td>\n",
       "      <td>82.5360</td>\n",
       "      <td>85.730000</td>\n",
       "      <td>86.3840</td>\n",
       "      <td>83.301000</td>\n",
       "      <td>78.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>88.48800</td>\n",
       "      <td>88.90500</td>\n",
       "      <td>86.0480</td>\n",
       "      <td>90.016000</td>\n",
       "      <td>87.2380</td>\n",
       "      <td>77.9520</td>\n",
       "      <td>87.238000</td>\n",
       "      <td>79.3810</td>\n",
       "      <td>85.809000</td>\n",
       "      <td>81.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>66.51750</td>\n",
       "      <td>62.35125</td>\n",
       "      <td>66.5175</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>58.1850</td>\n",
       "      <td>66.5175</td>\n",
       "      <td>63.095714</td>\n",
       "      <td>58.1850</td>\n",
       "      <td>63.095714</td>\n",
       "      <td>60.208750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>52.50000</td>\n",
       "      <td>52.50000</td>\n",
       "      <td>52.5000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>47.5000</td>\n",
       "      <td>52.5000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>52.5000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>52.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>54.16700</td>\n",
       "      <td>49.16700</td>\n",
       "      <td>54.1670</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>49.1670</td>\n",
       "      <td>54.1670</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>44.1670</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>45.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         0        0          0        0        0          0  \\\n",
       "F1-O     97.74800  97.68400  97.7580  97.938000  97.4920  97.6460  97.627000   \n",
       "P-O      97.64800  97.52000  97.3160  97.648000  97.2630  96.8660  97.159000   \n",
       "R-O      97.88300  97.88300  98.2600  98.263000  97.7530  98.5010  98.126000   \n",
       "F1-MISC  43.33375  39.16750  39.1675  43.333750  39.1675  39.1675  35.833750   \n",
       "P-MISC   40.00000  35.00000  40.0000  40.000000  40.0000  40.0000  32.500000   \n",
       "R-MISC   31.66700  31.66700  26.6670  31.667000  26.6670  26.6670  31.667000   \n",
       "F1-PER   84.75000  85.50400  83.3620  86.166000  84.8170  88.1600  85.916000   \n",
       "P-PER    82.49600  84.05100  83.3840  84.051000  83.5870  82.5360  85.730000   \n",
       "R-PER    88.48800  88.90500  86.0480  90.016000  87.2380  77.9520  87.238000   \n",
       "F1-LOC   66.51750  62.35125  66.5175  67.857143  58.1850  66.5175  63.095714   \n",
       "P-LOC    52.50000  52.50000  52.5000  47.500000  47.5000  52.5000  47.500000   \n",
       "R-LOC    54.16700  49.16700  54.1670  47.500000  49.1670  54.1670  42.500000   \n",
       "F1-ORG    0.00000   0.00000   0.0000  11.111111   0.0000   0.0000   0.000000   \n",
       "P-ORG     0.00000   0.00000   0.0000  10.000000   0.0000   0.0000   0.000000   \n",
       "R-ORG     0.00000   0.00000   0.0000  10.000000   0.0000   0.0000   0.000000   \n",
       "\n",
       "               0          0          0  \n",
       "F1-O     97.5880  97.569000  97.657000  \n",
       "P-O      96.6280  97.045000  96.880000  \n",
       "R-O      98.6170  98.131000  98.512000  \n",
       "F1-MISC  39.1675  39.167500  43.333750  \n",
       "P-MISC   40.0000  40.000000  40.000000  \n",
       "R-MISC   26.6670  26.667000  31.667000  \n",
       "F1-PER   80.3880  83.864000  87.891111  \n",
       "P-PER    86.3840  83.301000  78.051000  \n",
       "R-PER    79.3810  85.809000  81.286000  \n",
       "F1-LOC   58.1850  63.095714  60.208750  \n",
       "P-LOC    52.5000  42.500000  52.500000  \n",
       "R-LOC    44.1670  47.500000  45.833000  \n",
       "F1-ORG    0.0000   0.000000   0.000000  \n",
       "P-ORG     0.0000   0.000000   0.000000  \n",
       "R-ORG     0.0000   0.000000   0.000000  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.670700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.197300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.192900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>40.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>38.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>29.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>85.081811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>83.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>85.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>63.253107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>48.833500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.670700\n",
       "P-O      97.197300\n",
       "R-O      98.192900\n",
       "F1-MISC  40.084000\n",
       "P-MISC   38.750000\n",
       "R-MISC   29.167000\n",
       "F1-PER   85.081811\n",
       "P-PER    83.357100\n",
       "R-PER    85.236100\n",
       "F1-LOC   63.253107\n",
       "P-LOC    50.000000\n",
       "R-LOC    48.833500\n",
       "F1-ORG    1.111111\n",
       "P-ORG     1.000000\n",
       "R-ORG     1.000000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.123399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.347692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.294377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>2.467277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>2.700309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>2.635231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>2.262494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>2.245561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.200917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>3.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>3.535534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>4.216502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>3.513642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-O     0.123399\n",
       "P-O      0.347692\n",
       "R-O      0.294377\n",
       "F1-MISC  2.467277\n",
       "P-MISC   2.700309\n",
       "R-MISC   2.635231\n",
       "F1-PER   2.262494\n",
       "P-PER    2.245561\n",
       "R-PER    4.200917\n",
       "F1-LOC   3.569444\n",
       "P-LOC    3.535534\n",
       "R-LOC    4.216502\n",
       "F1-ORG   3.513642\n",
       "P-ORG    3.162278\n",
       "R-ORG    3.162278"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.1500</td>\n",
       "      <td>43.6825</td>\n",
       "      <td>43.682500</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150</td>\n",
       "      <td>43.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.43100</td>\n",
       "      <td>95.075000</td>\n",
       "      <td>94.737000</td>\n",
       "      <td>94.9000</td>\n",
       "      <td>94.9640</td>\n",
       "      <td>95.227000</td>\n",
       "      <td>94.91800</td>\n",
       "      <td>94.86800</td>\n",
       "      <td>95.157</td>\n",
       "      <td>95.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>8.57625</td>\n",
       "      <td>47.702857</td>\n",
       "      <td>28.391429</td>\n",
       "      <td>32.1575</td>\n",
       "      <td>34.5975</td>\n",
       "      <td>39.691111</td>\n",
       "      <td>34.62875</td>\n",
       "      <td>31.67875</td>\n",
       "      <td>42.050</td>\n",
       "      <td>41.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>70.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.54000</td>\n",
       "      <td>91.146000</td>\n",
       "      <td>90.138000</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>90.7090</td>\n",
       "      <td>91.122000</td>\n",
       "      <td>90.53800</td>\n",
       "      <td>90.38400</td>\n",
       "      <td>91.105</td>\n",
       "      <td>91.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>53.63800</td>\n",
       "      <td>51.554000</td>\n",
       "      <td>57.193000</td>\n",
       "      <td>63.3810</td>\n",
       "      <td>66.7380</td>\n",
       "      <td>77.824000</td>\n",
       "      <td>66.39100</td>\n",
       "      <td>68.14200</td>\n",
       "      <td>66.391</td>\n",
       "      <td>75.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.89000</td>\n",
       "      <td>99.379000</td>\n",
       "      <td>99.835000</td>\n",
       "      <td>99.7590</td>\n",
       "      <td>99.6610</td>\n",
       "      <td>99.725000</td>\n",
       "      <td>99.74800</td>\n",
       "      <td>99.82400</td>\n",
       "      <td>99.608</td>\n",
       "      <td>99.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>19.1250</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17.62500</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>24.375</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        0.1        0.2      0.3      0.4        0.5  \\\n",
       "F1-LOC        NaN        NaN        NaN      NaN      NaN  17.380000   \n",
       "F1-MISC  46.15000  46.150000  46.150000  46.1500  43.6825  43.682500   \n",
       "F1-O     94.43100  95.075000  94.737000  94.9000  94.9640  95.227000   \n",
       "F1-ORG        NaN        NaN        NaN      NaN      NaN        NaN   \n",
       "F1-PER    8.57625  47.702857  28.391429  32.1575  34.5975  39.691111   \n",
       "P-LOC     0.00000   0.000000   0.000000   0.0000   0.0000  60.000000   \n",
       "P-MISC   70.00000  60.000000  60.000000  70.0000  65.0000  65.000000   \n",
       "P-O      89.54000  91.146000  90.138000  90.5000  90.7090  91.122000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "P-PER    53.63800  51.554000  57.193000  63.3810  66.7380  77.824000   \n",
       "R-LOC     0.00000   0.000000   0.000000   0.0000   0.0000   5.712000   \n",
       "R-MISC   21.00000  18.000000  18.000000  21.0000  24.0000  24.000000   \n",
       "R-O      99.89000  99.379000  99.835000  99.7590  99.6610  99.725000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "R-PER     4.00000  25.000000  12.250000  16.7500  19.1250  23.500000   \n",
       "\n",
       "              0.6       0.7     0.8        0.9  \n",
       "F1-LOC        NaN       NaN     NaN  17.380000  \n",
       "F1-MISC  46.15000  46.15000  46.150  43.591111  \n",
       "F1-O     94.91800  94.86800  95.157  95.299000  \n",
       "F1-ORG        NaN       NaN     NaN        NaN  \n",
       "F1-PER   34.62875  31.67875  42.050  41.984444  \n",
       "P-LOC     0.00000   0.00000   0.000  60.000000  \n",
       "P-MISC   60.00000  60.00000  80.000  72.500000  \n",
       "P-O      90.53800  90.38400  91.105  91.426000  \n",
       "P-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "P-PER    66.39100  68.14200  66.391  75.073000  \n",
       "R-LOC     0.00000   0.00000   0.000   5.712000  \n",
       "R-MISC   18.00000  18.00000  24.000  27.000000  \n",
       "R-O      99.74800  99.82400  99.608  99.531000  \n",
       "R-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "R-PER    17.62500  15.75000  24.375  26.875000  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>34.145859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>90.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>64.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>1.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>18.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   17.380000\n",
       "F1-MISC  45.400611\n",
       "F1-O     94.957600\n",
       "F1-ORG         NaN\n",
       "F1-PER   34.145859\n",
       "P-LOC    12.000000\n",
       "P-MISC   66.250000\n",
       "P-O      90.660800\n",
       "P-ORG     0.000000\n",
       "P-PER    64.632500\n",
       "R-LOC     1.142400\n",
       "R-MISC   21.300000\n",
       "R-O      99.696000\n",
       "R-ORG     0.000000\n",
       "R-PER    18.525000"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.206887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>10.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>25.298221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.795628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.565721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>8.529639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.301515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.155470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>6.936167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    0.000000\n",
       "F1-MISC   1.206887\n",
       "F1-O      0.254209\n",
       "F1-ORG         NaN\n",
       "F1-PER   10.728242\n",
       "P-LOC    25.298221\n",
       "P-MISC    6.795628\n",
       "P-O       0.565721\n",
       "P-ORG     0.000000\n",
       "P-PER     8.529639\n",
       "R-LOC     2.408391\n",
       "R-MISC    3.301515\n",
       "R-O       0.155470\n",
       "R-ORG     0.000000\n",
       "R-PER     6.936167"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n",
      "O\tLOC\t4170.0\tSamaria\n",
      "O\tLOC\t4170.0\tOlivet\n",
      "O\tMISC\t4170.0\tSabbath\n",
      "PER\tO\t4170.0\tupper\n",
      "PER\tO\t4170.0\troom\n",
      "PER\tO\t4170.0\twhere\n",
      "PER\tO\t4170.0\tZealot\n",
      "LOC\tO\t4170.0\tso\n",
      "LOC\tO\t4170.0\tlanguage\n",
      "O\tMISC\t4170.0\tPsalms\n",
      "O\tPER\t4170.0\tBarsabbas\n",
      "O\tPER\t4170.0\tJustus\n",
      "O\tMISC\t4170.0\tninth\n",
      "O\tPER\t4170.0\tMoses\n",
      "O\tPER\t4170.0\tSamuel\n",
      "ORG\tO\t4170.0\tcaptain\n",
      "PER\tO\t4170.0\thigh-priestly\n",
      "PER\tO\t4170.0\tfamily\n",
      "O\tPER\t4170.0\tPontius\n",
      "O\tPER\t4170.0\tBarnabas\n",
      "O\tLOC\t4170.0\tCyprus\n",
      "O\tPER\t4170.0\tElijah\n",
      "O\tMISC\t4170.0\tr\n",
      "PER\tO\t4170.0\tJu\n",
      "PER\tO\t4170.0\th\n",
      "O\tLOC\t4170.0\tBabylon\n",
      "O\tPER\t4170.0\tImmanuel\n"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:ner-projection] *",
   "language": "python",
   "name": "conda-env-ner-projection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
