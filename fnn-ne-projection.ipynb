{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 50\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab\n",
    "h1_size = 360\n",
    "h2_size = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                if l[0] not in string.punctuation:\n",
    "                    dataset[\"word\"].append(l[0])\n",
    "                    dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4379</td>\n",
       "      <td>4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>313</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4379   4170\n",
       "unique   904      5\n",
       "top      the      O\n",
       "freq     313   3779"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.3 %\n",
      "MISC % = 2.4 %\n",
      "PER % = 5.59 %\n",
      "LOC % = 0.91 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.16 %\n",
      "MISC % = 1.88 %\n",
      "PER % = 8.96 %\n",
      "LOC % = 1.99 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>O</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of     the    Holy  Spirit      In   first    book  \\\n",
       "0  4170.0   4170.0  4170.0  4170.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4170.0     0.0     0.0  4170.0  4170.0  4170.0   \n",
       "2     0.0      0.0     0.0  1390.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "3     0.0      0.0  4170.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4170.0  2085.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5     0.0      0.0     0.0  4170.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "6  4170.0      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7     0.0      0.0     0.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8     0.0      0.0     0.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9     0.0      0.0  4170.0  1390.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "\n",
       "        O  ...   considered  dream  She  save  fulfill  Immanuel  us)  woke  \\\n",
       "0     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "1  4170.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "2     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "3     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "5     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "6     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "7     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "8     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "9     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "\n",
       "   sleep  knew  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "5    0.0   0.0  \n",
       "6    0.0   0.0  \n",
       "7    0.0   0.0  \n",
       "8    0.0   0.0  \n",
       "9    0.0   0.0  \n",
       "\n",
       "[10 rows x 903 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>'Let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "count    903\n",
       "unique   903\n",
       "top     'Let\n",
       "freq       1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (210, 903) (903,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "883       Eliud\n",
       "884     Eleazar\n",
       "885     Matthan\n",
       "886     husband\n",
       "887    fourteen\n",
       "888   unwilling\n",
       "889       shame\n",
       "890    resolved\n",
       "891     divorce\n",
       "892     quietly\n",
       "893  considered\n",
       "894       dream\n",
       "895         She\n",
       "896        save\n",
       "897     fulfill\n",
       "898    Immanuel\n",
       "899         us)\n",
       "900        woke\n",
       "901       sleep\n",
       "902        knew"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (903,)\n",
      "(903, 210) (903,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (605, 210)\n",
      "y_train.shape = (605, 5)\n",
      "X_val.shape = (298, 210)\n",
      "y_val.shape = (298, 5)\n",
      "O % in training data = 88.6 %\n",
      "O % in validation data = 87.58 %\n",
      "MISC % in training data = 1.49 %\n",
      "MISC % in validation data = 0.67 %\n",
      "PER % in training data = 7.6 %\n",
      "PER % in validation data = 10.4 %\n",
      "LOC % in training data = 2.15 %\n",
      "LOC % in validation data = 1.34 %\n",
      "ORG % in training data = 0.17 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=2, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 84.15 %\n",
      "MISC % = 2.54 %\n",
      "PER % = 6.69 %\n",
      "LOC % = 1.03 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.94 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.3 %\n",
      "LOC % = 1.86 %\n",
      "ORG % = 0.2 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3779</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>209</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   3779   3570\n",
       "unique  1024      5\n",
       "top       \\n      O\n",
       "freq     209   3180"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sÃ²</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sÃ²      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>obÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>yasÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>oyolÃ«ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>bÃ«yole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>AvÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>angavÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>oyÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>anganÃ²á¹…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1003        nlo\n",
       "1004        obÃ«\n",
       "1005      mbara\n",
       "1006    yabyali\n",
       "1007      dzili\n",
       "1008       yasÃ²\n",
       "1009    oyolÃ«ge\n",
       "1010       kode\n",
       "1011       dili\n",
       "1012     atoban\n",
       "1013        sik\n",
       "1014       Ntud\n",
       "1015     bÃ«yole\n",
       "1016   Emmanuel\n",
       "1017      AvÃ«bÃ«\n",
       "1018   angavÃ«bÃ«\n",
       "1019        oyÃ²\n",
       "1020  angabende\n",
       "1021    anganÃ²á¹…\n",
       "1022   angayole"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 210) (1023,)\n",
      "(1023, 210) (1023,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023,) 1023\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 210)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58030, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58030 to 0.44383, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44383 to 0.31782, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31782 to 0.29756, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29756\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15627, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15627\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15627\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10487, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10487\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10487\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17993, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17993 to 0.15250, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15250\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06374, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06374\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06374\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11214, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11214\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11214\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10667, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10667 to 0.09614, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09614\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09614\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06783, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06783\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06783\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08006, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08006\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08006\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12057, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12057\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12057\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39943, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.39943\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39943 to 0.35927, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35927 to 0.32268, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32268 to 0.30283, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30283\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30283\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14054, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14054\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14054\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07359, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07359\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07359\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19877, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19877 to 0.15686, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15686\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15686\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05151, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05151\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05151\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12356, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12356\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12356\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15117, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15117 to 0.07048, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07048\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07048\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05390, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05390\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05390\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11319, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11319 to 0.09027, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09027\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09027\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23794, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23794 to 0.16536, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16536\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16536\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45010, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45010\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45010\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25551, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25551\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25551 to 0.24591, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.24591 to 0.23466, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23466\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23466\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07770, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07770\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07770\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22375, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22375 to 0.18755, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18755\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18755\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11110, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11110 to 0.05957, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05957\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05957\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11644, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11644\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11644\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23435, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23435 to 0.11082, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11082 to 0.08576, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08576\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08576\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06648, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06648 to 0.06168, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06168\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06168\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09321, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09321\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09321\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13468, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13468\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13468\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41756, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41756 to 0.36681, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36681 to 0.33695, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33695 to 0.31437, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31437\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31437 to 0.29405, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29405\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.29405\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79520, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79520 to 0.14652, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14652 to 0.11891, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11891\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11891\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12098, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12098\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12098\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42304, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42304 to 0.17535, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17535\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17535\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05692, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05692 to 0.05310, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05310\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05310\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15733, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15733 to 0.12877, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12877\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12877\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08710, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08710\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08710\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10728, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10728 to 0.07341, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07341 to 0.04969, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04969\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04969\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13315, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13315\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13315 to 0.13194, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13194\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13194\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12241, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12241 to 0.11790, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11790\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11790\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61788, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61788 to 0.43436, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43436 to 0.35657, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35657\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35657 to 0.33753, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33753 to 0.28412, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28412\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28412\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13192, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13192\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13192\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07373, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07373\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07373\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15708, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15708\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15708\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07778, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07778\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07778 to 0.05555, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05555\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09602, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09602\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09602\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09368, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09368\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09368\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11761, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11761 to 0.09120, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09120\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09120\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10740, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10740\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10740\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16390, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16390\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16390\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38194, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38194\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38194\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21785, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21785\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21785\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10747, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10747 to 0.10246, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10246\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10246\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16032, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16032\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16032\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05589, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05589\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05589\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12469, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12469\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12469\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07370, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07370\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08290, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08290 to 0.07272, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07272\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07272 to 0.06332, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06332\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06332\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15873, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15873\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15873\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19993, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19993 to 0.13121, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13121\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13121\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42407, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42407 to 0.37316, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37316 to 0.32105, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32105 to 0.31907, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31907\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31907\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31352, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31352 to 0.14191, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14191 to 0.14141, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14141\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14141\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11275, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11275\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11275\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14785, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14785\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14785\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06565, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06565 to 0.04674, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04674\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04674\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09345, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09345\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09345\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09136, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09136\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09136\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06845, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06845\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06845 to 0.06111, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06111\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06111\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17980, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17980 to 0.13127, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13127\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13127\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15684, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15684\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15684\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48231, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48231 to 0.40404, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.40404\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.40404\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21372, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21372\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21372 to 0.17449, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17449 to 0.16227, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16227\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16227\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07027, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07027\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07027\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10958, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10958\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10958\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10317, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10317\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10317 to 0.09027, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09027\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09027\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15338, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15338\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15338\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07316, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07316 to 0.06355, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06355\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06355\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07680, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07680\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07680\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16141, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16141 to 0.13767, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13767\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13767\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15979, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15979 to 0.14584, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14584\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14584\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 360)               75960     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 640)               231040    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 3205      \n",
      "=================================================================\n",
      "Total params: 310,205\n",
      "Trainable params: 310,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46735, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46735 to 0.38393, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38393\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38393\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37568, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37568 to 0.23628, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23628\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23628 to 0.22359, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22359\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22359\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07720, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07720\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07720\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17692, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17692\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17692 to 0.16787, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16787\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16787\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04160, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04160\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04160\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20977, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20977 to 0.13134, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13134\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13134\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06212, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06212 to 0.06160, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06160\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06160\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-952ca87230b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresultCrossVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainByTagResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestByTagResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewoByTagResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgoCrossVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_ewo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ewo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-132-a93644a930a0>\u001b[0m in \u001b[0;36malgoCrossVal\u001b[0;34m(X, y, X_ewo, y_ewo, k, repeat)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_by_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_by_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewo_by_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgoEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_ewo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ewo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-e4f04157e59d>\u001b[0m in \u001b[0;36malgoEval\u001b[0;34m(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mewo_result_by_tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewo_result_by_tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewo_result_by_tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-d4f0dfd58dd5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbest_model_cp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# saved best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_model_cp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loading the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m    927\u001b[0m                              ' elements.')\n\u001b[1;32m    928\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 196\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 196\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \"\"\"\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_add_should_use_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m   return tf_decorator.make_decorator(\n\u001b[1;32m    120\u001b[0m       \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'should_use_result'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mis_variable_initialized\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0minitialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m   \"\"\"\n\u001b[0;32m-> 1620\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36mis_variable_initialized\u001b[0;34m(ref, name)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \"\"\"\n\u001b[1;32m    188\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_state_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m   \u001b[0;31m# Handle resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"VarHandleOp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36mis_variable_initialized\u001b[0;34m(ref, name)\u001b[0m\n\u001b[1;32m    246\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 248\u001b[0;31m         \"IsVariableInitialized\", ref=ref, name=name)\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3371\u001b[0m     \u001b[0;31m# after removing the trailing '/'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3373\u001b[0;31m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_name_from_scope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3374\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3375\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_name_from_scope_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2741\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_name_from_scope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2742\u001b[0m   \"\"\"Returns the name of an op given the name of its scope.\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
