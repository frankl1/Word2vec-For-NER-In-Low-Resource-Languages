{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 50\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab\n",
    "h1_size = 2000\n",
    "h2_size = 160\n",
    "h3_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                if l[0] not in string.punctuation:\n",
    "                    dataset[\"word\"].append(l[0])\n",
    "                    dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "#     model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "#     model.add(Dense(h3_size, activation='sigmoid', name=\"hidden3\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=2, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4379</td>\n",
       "      <td>4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>313</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4379   4170\n",
       "unique   904      5\n",
       "top      the      O\n",
       "freq     313   3779"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.3 %\n",
      "MISC % = 2.4 %\n",
      "PER % = 5.59 %\n",
      "LOC % = 0.91 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.16 %\n",
      "MISC % = 1.88 %\n",
      "PER % = 8.96 %\n",
      "LOC % = 1.99 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>O</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of     the    Holy  Spirit      In   first    book  \\\n",
       "0  4170.0   4170.0  4170.0  4170.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4170.0     0.0     0.0  4170.0  4170.0  4170.0   \n",
       "2     0.0      0.0     0.0  1390.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "3     0.0      0.0  4170.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4170.0  2085.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5     0.0      0.0     0.0  4170.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "6  4170.0      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7     0.0      0.0     0.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8     0.0      0.0     0.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9     0.0      0.0  4170.0  1390.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "\n",
       "        O  ...   considered  dream  She  save  fulfill  Immanuel  us)  woke  \\\n",
       "0     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "1  4170.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "2     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "3     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "5     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "6     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "7     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "8     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "9     0.0  ...          0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "\n",
       "   sleep  knew  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "5    0.0   0.0  \n",
       "6    0.0   0.0  \n",
       "7    0.0   0.0  \n",
       "8    0.0   0.0  \n",
       "9    0.0   0.0  \n",
       "\n",
       "[10 rows x 903 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>hearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "count      903\n",
       "unique     903\n",
       "top     hearts\n",
       "freq         1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (210, 903) (903,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "883       Eliud\n",
       "884     Eleazar\n",
       "885     Matthan\n",
       "886     husband\n",
       "887    fourteen\n",
       "888   unwilling\n",
       "889       shame\n",
       "890    resolved\n",
       "891     divorce\n",
       "892     quietly\n",
       "893  considered\n",
       "894       dream\n",
       "895         She\n",
       "896        save\n",
       "897     fulfill\n",
       "898    Immanuel\n",
       "899         us)\n",
       "900        woke\n",
       "901       sleep\n",
       "902        knew"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (903,)\n",
      "(903, 210) (903,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (605, 210)\n",
      "y_train.shape = (605, 5)\n",
      "X_val.shape = (298, 210)\n",
      "y_val.shape = (298, 5)\n",
      "O % in training data = 87.93 %\n",
      "O % in validation data = 88.93 %\n",
      "MISC % in training data = 1.49 %\n",
      "MISC % in validation data = 0.67 %\n",
      "PER % in training data = 8.43 %\n",
      "PER % in validation data = 8.72 %\n",
      "LOC % in training data = 1.98 %\n",
      "LOC % in validation data = 1.68 %\n",
      "ORG % in training data = 0.17 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 84.15 %\n",
      "MISC % = 2.54 %\n",
      "PER % = 6.69 %\n",
      "LOC % = 1.03 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.94 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.3 %\n",
      "LOC % = 1.86 %\n",
      "ORG % = 0.2 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3779</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>209</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   3779   3570\n",
       "unique  1024      5\n",
       "top       \\n      O\n",
       "freq     209   3180"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sò</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sò      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>obë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>yasò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>oyolëge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>bëyole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Avëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>angavëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>oyò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>anganòṅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1003        nlo\n",
       "1004        obë\n",
       "1005      mbara\n",
       "1006    yabyali\n",
       "1007      dzili\n",
       "1008       yasò\n",
       "1009    oyolëge\n",
       "1010       kode\n",
       "1011       dili\n",
       "1012     atoban\n",
       "1013        sik\n",
       "1014       Ntud\n",
       "1015     bëyole\n",
       "1016   Emmanuel\n",
       "1017      Avëbë\n",
       "1018   angavëbë\n",
       "1019        oyò\n",
       "1020  angabende\n",
       "1021    anganòṅ\n",
       "1022   angayole"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 210) (1023,)\n",
      "(1023, 210) (1023,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023,) 1023\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 210)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19233, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19233 to 0.18268, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18268\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18268\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15163, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15163\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15163\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13334, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13334\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09095, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09095\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09095\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08375, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08375\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08375\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19500, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19500 to 0.12837, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12837\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12837\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15108, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15108\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16918, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16918\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16918\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04347, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04347\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04347\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09742, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09742\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09742 to 0.08347, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08347\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08347\n",
      "Epoch 00005: early stopping\n",
      "AlgoCrossValIter - 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27384, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27384 to 0.20233, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20233 to 0.19115, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19115\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19115\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12609, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12609\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12609\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12516, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12516 to 0.11593, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11593\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11593\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19593, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19593\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19593 to 0.14447, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14447 to 0.11492, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11492\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11492\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12770, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12770 to 0.12549, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12549 to 0.12165, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12165\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12165\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11994, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11994\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11994\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15755, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15755\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15755\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14187, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14187\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14187\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04484, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04484\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04484\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07870, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07870\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07870\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22504, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22504\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22504\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15093, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15093\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15093\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13855, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13855\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13855\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09887, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09887 to 0.07334, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07334\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07334\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09496, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09496\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09496\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12158, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12158 to 0.10703, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10703\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10703\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11871, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11871\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11871\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19451, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19451 to 0.17919, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17919\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17919\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05958, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05958 to 0.04081, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04081\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04081\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09233, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09233\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09233\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18368, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18368\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18368\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16226, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16226\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16226\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09703, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09703\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09703\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20542, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20542 to 0.12955, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12955\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12955\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08975, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08975\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08975\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12841, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12841 to 0.11250, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11250\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24672, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24672 to 0.18795, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18795\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18795\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18576, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18576\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18576\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03682, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03682\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03682\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04962, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04962\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04962\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45406, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45406 to 0.24659, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24659\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24659\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20421, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20421\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20421 to 0.18109, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18109\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18109\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14062, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14062 to 0.11210, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11210\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11210\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09550, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09550\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09550\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10668, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10668\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12279, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12279\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12279\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18084, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18084 to 0.14276, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14276\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18777, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18777\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18777\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04779, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04779 to 0.04513, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04513\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04513 to 0.04365, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04365\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04365\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13764, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13764 to 0.08614, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08614\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08614\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31763, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31763 to 0.21849, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21849\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21849\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13883, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13883\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13883\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11854, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11854 to 0.11792, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11792\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11792\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09075, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09075\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09075\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06918, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06918\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06918\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13400, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13400\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16248, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16248\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16248\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22339, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22339\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22339 to 0.18047, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18047\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18047\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04771, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04771 to 0.03830, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03830\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03830\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05675, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05675\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05675\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25760, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25760 to 0.19865, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19865\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19865\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17380, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17380 to 0.15399, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15399\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12770, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12770\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12770\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18527, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18527 to 0.14884, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14884 to 0.13488, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13488\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13488\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09953, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09953\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09953\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11989, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11989\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11989\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13277, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13277\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13277\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14351, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14351\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14351\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04491, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04491\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04491\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14604, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14604 to 0.08694, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08694\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08694\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23033, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23033\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23033\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14631, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14631\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14631\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15644, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15644\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15644\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09251, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09251\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09251\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11229, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11229\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11229\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09813, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09813\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09813\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12461, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12461\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12461\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18376, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18376 to 0.13900, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13900\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02092, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02092\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10902, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10902 to 0.10528, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10528\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10528\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33239, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33239 to 0.22696, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22696\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22696 to 0.21330, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21330\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21330\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13516, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13516\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13516\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10814, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10814\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10814\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18227, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18227 to 0.08614, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08614\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08614\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10031, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10031\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10031\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07284, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07284\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07284\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10804, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10804\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10804\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17219, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17219\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17219\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12750, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12750 to 0.04618, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04618\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04618\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12012, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12012 to 0.09995, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09995\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09995 to 0.08581, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08581\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08581\n",
      "Epoch 00006: early stopping\n",
      "AlgoCrossValIter - 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 2000)              422000    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 10005     \n",
      "=================================================================\n",
      "Total params: 432,005\n",
      "Trainable params: 432,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29316, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29316 to 0.23414, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23414\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23414\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13577, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13577\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13577\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08941, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08941\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08941\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09980, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09980\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09980\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10988, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10988 to 0.10174, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10174\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10174\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11392, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11392\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11392\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13588, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13588\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13588\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17964, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17964\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17964\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03018, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03018\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03018\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06455, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06455\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06455\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>78.958000</td>\n",
       "      <td>86.115</td>\n",
       "      <td>79.292000</td>\n",
       "      <td>82.784</td>\n",
       "      <td>81.459</td>\n",
       "      <td>82.014</td>\n",
       "      <td>81.474</td>\n",
       "      <td>79.185000</td>\n",
       "      <td>79.741</td>\n",
       "      <td>86.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>88.356000</td>\n",
       "      <td>90.424</td>\n",
       "      <td>87.340000</td>\n",
       "      <td>88.582</td>\n",
       "      <td>87.356</td>\n",
       "      <td>87.135</td>\n",
       "      <td>87.650</td>\n",
       "      <td>87.949000</td>\n",
       "      <td>85.028</td>\n",
       "      <td>88.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>77.601000</td>\n",
       "      <td>80.524</td>\n",
       "      <td>75.420000</td>\n",
       "      <td>80.313</td>\n",
       "      <td>73.014</td>\n",
       "      <td>78.148</td>\n",
       "      <td>77.306</td>\n",
       "      <td>79.368000</td>\n",
       "      <td>74.377</td>\n",
       "      <td>79.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>65.888000</td>\n",
       "      <td>70.151</td>\n",
       "      <td>71.130000</td>\n",
       "      <td>73.850</td>\n",
       "      <td>75.553</td>\n",
       "      <td>75.463</td>\n",
       "      <td>70.867</td>\n",
       "      <td>69.904000</td>\n",
       "      <td>77.350</td>\n",
       "      <td>69.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>80.593000</td>\n",
       "      <td>79.066</td>\n",
       "      <td>80.103000</td>\n",
       "      <td>79.841</td>\n",
       "      <td>82.741</td>\n",
       "      <td>83.451</td>\n",
       "      <td>80.987</td>\n",
       "      <td>79.664000</td>\n",
       "      <td>87.019</td>\n",
       "      <td>79.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>63.150000</td>\n",
       "      <td>61.759</td>\n",
       "      <td>63.888000</td>\n",
       "      <td>62.593</td>\n",
       "      <td>65.927</td>\n",
       "      <td>65.278</td>\n",
       "      <td>63.611</td>\n",
       "      <td>64.074000</td>\n",
       "      <td>68.610</td>\n",
       "      <td>62.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>75.997778</td>\n",
       "      <td>75.894</td>\n",
       "      <td>82.024444</td>\n",
       "      <td>76.215</td>\n",
       "      <td>74.545</td>\n",
       "      <td>77.870</td>\n",
       "      <td>74.697</td>\n",
       "      <td>81.103333</td>\n",
       "      <td>77.609</td>\n",
       "      <td>72.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>83.629000</td>\n",
       "      <td>83.520</td>\n",
       "      <td>83.092000</td>\n",
       "      <td>83.027</td>\n",
       "      <td>84.291</td>\n",
       "      <td>85.063</td>\n",
       "      <td>83.829</td>\n",
       "      <td>82.796000</td>\n",
       "      <td>85.697</td>\n",
       "      <td>82.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>68.851000</td>\n",
       "      <td>68.618</td>\n",
       "      <td>68.670000</td>\n",
       "      <td>69.173</td>\n",
       "      <td>68.326</td>\n",
       "      <td>70.849</td>\n",
       "      <td>68.849</td>\n",
       "      <td>69.739000</td>\n",
       "      <td>70.565</td>\n",
       "      <td>68.987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       0          0       0       0       0       0  \\\n",
       "P_test    78.958000  86.115  79.292000  82.784  81.459  82.014  81.474   \n",
       "P_train   88.356000  90.424  87.340000  88.582  87.356  87.135  87.650   \n",
       "P_ewo     77.601000  80.524  75.420000  80.313  73.014  78.148  77.306   \n",
       "R_test    65.888000  70.151  71.130000  73.850  75.553  75.463  70.867   \n",
       "R_train   80.593000  79.066  80.103000  79.841  82.741  83.451  80.987   \n",
       "R_ewo     63.150000  61.759  63.888000  62.593  65.927  65.278  63.611   \n",
       "F1-test   75.997778  75.894  82.024444  76.215  74.545  77.870  74.697   \n",
       "F1-train  83.629000  83.520  83.092000  83.027  84.291  85.063  83.829   \n",
       "F1-ewo    68.851000  68.618  68.670000  69.173  68.326  70.849  68.849   \n",
       "\n",
       "                  0       0       0  \n",
       "P_test    79.185000  79.741  86.355  \n",
       "P_train   87.949000  85.028  88.171  \n",
       "P_ewo     79.368000  74.377  79.978  \n",
       "R_test    69.904000  77.350  69.504  \n",
       "R_train   79.664000  87.019  79.663  \n",
       "R_ewo     64.074000  68.610  62.963  \n",
       "F1-test   81.103333  77.609  72.011  \n",
       "F1-train  82.796000  85.697  82.669  \n",
       "F1-ewo    69.739000  70.565  68.987  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>81.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>87.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>77.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>71.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>81.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>64.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>76.796656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>83.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>69.262700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "P_test    81.737700\n",
       "P_train   87.799100\n",
       "P_ewo     77.604900\n",
       "R_test    71.966000\n",
       "R_train   81.312800\n",
       "R_ewo     64.185300\n",
       "F1-test   76.796656\n",
       "F1-train  83.761300\n",
       "F1-ewo    69.262700"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>2.708213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>1.354963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>2.608722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>3.497440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>2.447560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>1.978335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>3.015912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>0.995229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>0.850375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "P_test    2.708213\n",
       "P_train   1.354963\n",
       "P_ewo     2.608722\n",
       "R_test    3.497440\n",
       "R_train   2.447560\n",
       "R_ewo     1.978335\n",
       "F1-test   3.015912\n",
       "F1-train  0.995229\n",
       "F1-ewo    0.850375"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.971000</td>\n",
       "      <td>98.011000</td>\n",
       "      <td>97.945000</td>\n",
       "      <td>97.982000</td>\n",
       "      <td>98.057</td>\n",
       "      <td>98.1160</td>\n",
       "      <td>98.009000</td>\n",
       "      <td>97.961000</td>\n",
       "      <td>98.141000</td>\n",
       "      <td>97.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.460000</td>\n",
       "      <td>97.282000</td>\n",
       "      <td>97.429000</td>\n",
       "      <td>97.436000</td>\n",
       "      <td>97.785</td>\n",
       "      <td>97.8570</td>\n",
       "      <td>97.582000</td>\n",
       "      <td>97.416000</td>\n",
       "      <td>98.345000</td>\n",
       "      <td>97.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.511000</td>\n",
       "      <td>98.778000</td>\n",
       "      <td>98.483000</td>\n",
       "      <td>98.565000</td>\n",
       "      <td>98.357</td>\n",
       "      <td>98.3850</td>\n",
       "      <td>98.455000</td>\n",
       "      <td>98.539000</td>\n",
       "      <td>97.956000</td>\n",
       "      <td>98.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>76.652000</td>\n",
       "      <td>75.492000</td>\n",
       "      <td>77.461111</td>\n",
       "      <td>72.115000</td>\n",
       "      <td>75.247</td>\n",
       "      <td>76.6810</td>\n",
       "      <td>76.907000</td>\n",
       "      <td>75.026667</td>\n",
       "      <td>77.983000</td>\n",
       "      <td>75.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>81.883000</td>\n",
       "      <td>90.586000</td>\n",
       "      <td>87.460000</td>\n",
       "      <td>93.056000</td>\n",
       "      <td>95.238</td>\n",
       "      <td>94.3060</td>\n",
       "      <td>96.889000</td>\n",
       "      <td>79.778000</td>\n",
       "      <td>96.389000</td>\n",
       "      <td>87.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>75.926000</td>\n",
       "      <td>68.951000</td>\n",
       "      <td>58.482000</td>\n",
       "      <td>63.181000</td>\n",
       "      <td>64.340</td>\n",
       "      <td>65.9080</td>\n",
       "      <td>64.888000</td>\n",
       "      <td>61.982000</td>\n",
       "      <td>66.525000</td>\n",
       "      <td>71.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>87.321000</td>\n",
       "      <td>86.763000</td>\n",
       "      <td>87.422000</td>\n",
       "      <td>87.147000</td>\n",
       "      <td>87.954</td>\n",
       "      <td>88.6660</td>\n",
       "      <td>86.764000</td>\n",
       "      <td>87.028000</td>\n",
       "      <td>88.951000</td>\n",
       "      <td>85.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>89.798000</td>\n",
       "      <td>92.016000</td>\n",
       "      <td>89.289000</td>\n",
       "      <td>90.547000</td>\n",
       "      <td>87.027</td>\n",
       "      <td>89.5280</td>\n",
       "      <td>89.510000</td>\n",
       "      <td>89.339000</td>\n",
       "      <td>87.423000</td>\n",
       "      <td>89.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>86.029000</td>\n",
       "      <td>83.474000</td>\n",
       "      <td>86.354000</td>\n",
       "      <td>85.008000</td>\n",
       "      <td>89.852</td>\n",
       "      <td>88.3790</td>\n",
       "      <td>85.439000</td>\n",
       "      <td>86.025000</td>\n",
       "      <td>91.159000</td>\n",
       "      <td>83.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>71.852000</td>\n",
       "      <td>75.148000</td>\n",
       "      <td>70.149000</td>\n",
       "      <td>77.351111</td>\n",
       "      <td>72.621</td>\n",
       "      <td>75.5470</td>\n",
       "      <td>76.232000</td>\n",
       "      <td>78.068889</td>\n",
       "      <td>77.835000</td>\n",
       "      <td>74.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>92.729000</td>\n",
       "      <td>88.013000</td>\n",
       "      <td>83.432000</td>\n",
       "      <td>72.699000</td>\n",
       "      <td>91.615</td>\n",
       "      <td>79.6060</td>\n",
       "      <td>83.961000</td>\n",
       "      <td>80.033000</td>\n",
       "      <td>76.682000</td>\n",
       "      <td>88.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>62.425000</td>\n",
       "      <td>69.829000</td>\n",
       "      <td>70.670000</td>\n",
       "      <td>69.818000</td>\n",
       "      <td>65.134</td>\n",
       "      <td>75.4890</td>\n",
       "      <td>73.098000</td>\n",
       "      <td>65.642000</td>\n",
       "      <td>82.970000</td>\n",
       "      <td>69.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>44.446667</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>53.336000</td>\n",
       "      <td>53.336</td>\n",
       "      <td>50.0025</td>\n",
       "      <td>55.558333</td>\n",
       "      <td>53.336000</td>\n",
       "      <td>57.145714</td>\n",
       "      <td>53.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0          0          0       0        0  \\\n",
       "F1-O     97.971000  98.011000  97.945000  97.982000  98.057  98.1160   \n",
       "P-O      97.460000  97.282000  97.429000  97.436000  97.785  97.8570   \n",
       "R-O      98.511000  98.778000  98.483000  98.565000  98.357  98.3850   \n",
       "F1-MISC  76.652000  75.492000  77.461111  72.115000  75.247  76.6810   \n",
       "P-MISC   81.883000  90.586000  87.460000  93.056000  95.238  94.3060   \n",
       "R-MISC   75.926000  68.951000  58.482000  63.181000  64.340  65.9080   \n",
       "F1-PER   87.321000  86.763000  87.422000  87.147000  87.954  88.6660   \n",
       "P-PER    89.798000  92.016000  89.289000  90.547000  87.027  89.5280   \n",
       "R-PER    86.029000  83.474000  86.354000  85.008000  89.852  88.3790   \n",
       "F1-LOC   71.852000  75.148000  70.149000  77.351111  72.621  75.5470   \n",
       "P-LOC    92.729000  88.013000  83.432000  72.699000  91.615  79.6060   \n",
       "R-LOC    62.425000  69.829000  70.670000  69.818000  65.134  75.4890   \n",
       "F1-ORG   44.446667  44.446667  44.446667  53.336000  53.336  50.0025   \n",
       "P-ORG    10.000000  10.000000  10.000000  20.000000  20.000  15.0000   \n",
       "R-ORG    20.000000  20.000000  20.000000  40.000000  40.000  30.0000   \n",
       "\n",
       "                 0          0          0       0  \n",
       "F1-O     98.009000  97.961000  98.141000  97.869  \n",
       "P-O      97.582000  97.416000  98.345000  97.340  \n",
       "R-O      98.455000  98.539000  97.956000  98.443  \n",
       "F1-MISC  76.907000  75.026667  77.983000  75.231  \n",
       "P-MISC   96.889000  79.778000  96.389000  87.778  \n",
       "R-MISC   64.888000  61.982000  66.525000  71.150  \n",
       "F1-PER   86.764000  87.028000  88.951000  85.866  \n",
       "P-PER    89.510000  89.339000  87.423000  89.836  \n",
       "R-PER    85.439000  86.025000  91.159000  83.674  \n",
       "F1-LOC   76.232000  78.068889  77.835000  74.838  \n",
       "P-LOC    83.961000  80.033000  76.682000  88.515  \n",
       "R-LOC    73.098000  65.642000  82.970000  69.660  \n",
       "F1-ORG   55.558333  53.336000  57.145714  53.336  \n",
       "P-ORG    25.000000  20.000000  30.000000  20.000  \n",
       "R-ORG    50.000000  40.000000  60.000000  40.000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>98.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.447200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>75.879578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>90.336300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>66.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>87.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>89.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>86.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>74.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>83.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>70.473500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>50.939055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     98.006200\n",
       "P-O      97.593200\n",
       "R-O      98.447200\n",
       "F1-MISC  75.879578\n",
       "P-MISC   90.336300\n",
       "R-MISC   66.133300\n",
       "F1-PER   87.388200\n",
       "P-PER    89.431300\n",
       "R-PER    86.539300\n",
       "F1-LOC   74.964200\n",
       "P-LOC    83.728500\n",
       "R-LOC    70.473500\n",
       "F1-ORG   50.939055\n",
       "P-ORG    18.000000\n",
       "R-ORG    36.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.081155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.322055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.669686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.005288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>4.926869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>0.924146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>1.417429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>2.525886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>2.665357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>6.553796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>5.834602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>4.832439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>6.749486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>13.498971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O      0.081155\n",
       "P-O       0.322055\n",
       "R-O       0.208285\n",
       "F1-MISC   1.669686\n",
       "P-MISC    6.005288\n",
       "R-MISC    4.926869\n",
       "F1-PER    0.924146\n",
       "P-PER     1.417429\n",
       "R-PER     2.525886\n",
       "F1-LOC    2.665357\n",
       "P-LOC     6.553796\n",
       "R-LOC     5.834602\n",
       "F1-ORG    4.832439\n",
       "P-ORG     6.749486\n",
       "R-ORG    13.498971"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.450000</td>\n",
       "      <td>97.62500</td>\n",
       "      <td>97.622000</td>\n",
       "      <td>97.558000</td>\n",
       "      <td>97.483000</td>\n",
       "      <td>97.816000</td>\n",
       "      <td>97.29800</td>\n",
       "      <td>97.568000</td>\n",
       "      <td>97.924000</td>\n",
       "      <td>97.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.849000</td>\n",
       "      <td>96.83500</td>\n",
       "      <td>97.064000</td>\n",
       "      <td>97.173000</td>\n",
       "      <td>97.549000</td>\n",
       "      <td>97.546000</td>\n",
       "      <td>96.65100</td>\n",
       "      <td>96.830000</td>\n",
       "      <td>98.024000</td>\n",
       "      <td>96.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.100000</td>\n",
       "      <td>98.46100</td>\n",
       "      <td>98.215000</td>\n",
       "      <td>97.978000</td>\n",
       "      <td>97.482000</td>\n",
       "      <td>98.102000</td>\n",
       "      <td>97.98900</td>\n",
       "      <td>98.351000</td>\n",
       "      <td>97.835000</td>\n",
       "      <td>97.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>54.445000</td>\n",
       "      <td>42.50000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>40.83375</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>51.428571</td>\n",
       "      <td>42.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>31.667000</td>\n",
       "      <td>33.33400</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>31.66700</td>\n",
       "      <td>33.334000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>33.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.66700</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.66700</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>36.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>80.036667</td>\n",
       "      <td>79.39200</td>\n",
       "      <td>85.981111</td>\n",
       "      <td>80.007000</td>\n",
       "      <td>78.583000</td>\n",
       "      <td>81.552000</td>\n",
       "      <td>77.74000</td>\n",
       "      <td>86.816667</td>\n",
       "      <td>82.480000</td>\n",
       "      <td>76.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>80.470000</td>\n",
       "      <td>87.76800</td>\n",
       "      <td>80.083000</td>\n",
       "      <td>86.528000</td>\n",
       "      <td>82.832000</td>\n",
       "      <td>83.291000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>81.855000</td>\n",
       "      <td>85.768000</td>\n",
       "      <td>88.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>70.234000</td>\n",
       "      <td>75.07500</td>\n",
       "      <td>76.003000</td>\n",
       "      <td>78.114000</td>\n",
       "      <td>81.753000</td>\n",
       "      <td>80.662000</td>\n",
       "      <td>74.79600</td>\n",
       "      <td>76.734000</td>\n",
       "      <td>81.750000</td>\n",
       "      <td>73.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>71.853333</td>\n",
       "      <td>68.63125</td>\n",
       "      <td>72.778889</td>\n",
       "      <td>74.322222</td>\n",
       "      <td>68.413333</td>\n",
       "      <td>73.704444</td>\n",
       "      <td>71.04250</td>\n",
       "      <td>66.251250</td>\n",
       "      <td>75.001111</td>\n",
       "      <td>70.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.333000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>59.16700</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>64.167000</td>\n",
       "      <td>60.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>61.667000</td>\n",
       "      <td>54.16700</td>\n",
       "      <td>64.167000</td>\n",
       "      <td>71.667000</td>\n",
       "      <td>64.167000</td>\n",
       "      <td>66.667000</td>\n",
       "      <td>59.16700</td>\n",
       "      <td>51.667000</td>\n",
       "      <td>74.167000</td>\n",
       "      <td>59.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         0          0          0          0          0  \\\n",
       "F1-O     97.450000  97.62500  97.622000  97.558000  97.483000  97.816000   \n",
       "P-O      96.849000  96.83500  97.064000  97.173000  97.549000  97.546000   \n",
       "R-O      98.100000  98.46100  98.215000  97.978000  97.482000  98.102000   \n",
       "F1-MISC  54.445000  42.50000  45.000000  45.000000  45.000000  45.000000   \n",
       "P-MISC   31.667000  33.33400  36.667000  36.667000  36.667000  36.667000   \n",
       "R-MISC   36.667000  36.66700  36.667000  36.667000  36.667000  36.667000   \n",
       "F1-PER   80.036667  79.39200  85.981111  80.007000  78.583000  81.552000   \n",
       "P-PER    80.470000  87.76800  80.083000  86.528000  82.832000  83.291000   \n",
       "R-PER    70.234000  75.07500  76.003000  78.114000  81.753000  80.662000   \n",
       "F1-LOC   71.853333  68.63125  72.778889  74.322222  68.413333  73.704444   \n",
       "P-LOC    75.000000  60.00000  72.500000  68.000000  68.333000  70.000000   \n",
       "R-LOC    61.667000  54.16700  64.167000  71.667000  64.167000  66.667000   \n",
       "F1-ORG    0.000000   0.00000   0.000000   0.000000   0.000000   0.000000   \n",
       "P-ORG     0.000000   0.00000   0.000000   0.000000   0.000000   0.000000   \n",
       "R-ORG     0.000000   0.00000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "                0          0          0       0  \n",
       "F1-O     97.29800  97.568000  97.924000  97.431  \n",
       "P-O      96.65100  96.830000  98.024000  96.948  \n",
       "R-O      97.98900  98.351000  97.835000  97.953  \n",
       "F1-MISC  40.83375  42.500000  51.428571  42.500  \n",
       "P-MISC   31.66700  33.334000  36.667000  33.334  \n",
       "R-MISC   36.66700  36.667000  36.667000  36.667  \n",
       "F1-PER   77.74000  86.816667  82.480000  76.137  \n",
       "P-PER    84.00000  81.855000  85.768000  88.611  \n",
       "R-PER    74.79600  76.734000  81.750000  73.932  \n",
       "F1-LOC   71.04250  66.251250  75.001111  70.715  \n",
       "P-LOC    59.16700  60.000000  64.167000  60.000  \n",
       "R-LOC    59.16700  51.667000  74.167000  59.167  \n",
       "F1-ORG    0.00000   0.000000   0.000000   0.000  \n",
       "P-ORG     0.00000   0.000000   0.000000   0.000  \n",
       "R-ORG     0.00000   0.000000   0.000000   0.000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.420732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>34.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>36.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>80.872544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>84.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>76.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>71.271333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>65.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>62.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.577500\n",
       "P-O      97.146900\n",
       "R-O      98.046600\n",
       "F1-MISC  45.420732\n",
       "P-MISC   34.667100\n",
       "R-MISC   36.667000\n",
       "F1-PER   80.872544\n",
       "P-PER    84.120600\n",
       "R-PER    76.905300\n",
       "F1-LOC   71.271333\n",
       "P-LOC    65.716700\n",
       "R-LOC    62.667000\n",
       "F1-ORG    0.000000\n",
       "P-ORG     0.000000\n",
       "R-ORG     0.000000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>1.845175e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>4.307297e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>2.746712e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>4.280084e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>2.194201e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>7.489778e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>3.425326e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>2.964644e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>3.719834e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>2.837290e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>5.830381e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>7.090682e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "F1-O     1.845175e-01\n",
       "P-O      4.307297e-01\n",
       "R-O      2.746712e-01\n",
       "F1-MISC  4.280084e+00\n",
       "P-MISC   2.194201e+00\n",
       "R-MISC   7.489778e-15\n",
       "F1-PER   3.425326e+00\n",
       "P-PER    2.964644e+00\n",
       "R-PER    3.719834e+00\n",
       "F1-LOC   2.837290e+00\n",
       "P-LOC    5.830381e+00\n",
       "R-LOC    7.090682e+00\n",
       "F1-ORG   0.000000e+00\n",
       "P-ORG    0.000000e+00\n",
       "R-ORG    0.000000e+00"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.1500</td>\n",
       "      <td>43.6825</td>\n",
       "      <td>43.682500</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150</td>\n",
       "      <td>43.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.43100</td>\n",
       "      <td>95.075000</td>\n",
       "      <td>94.737000</td>\n",
       "      <td>94.9000</td>\n",
       "      <td>94.9640</td>\n",
       "      <td>95.227000</td>\n",
       "      <td>94.91800</td>\n",
       "      <td>94.86800</td>\n",
       "      <td>95.157</td>\n",
       "      <td>95.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>8.57625</td>\n",
       "      <td>47.702857</td>\n",
       "      <td>28.391429</td>\n",
       "      <td>32.1575</td>\n",
       "      <td>34.5975</td>\n",
       "      <td>39.691111</td>\n",
       "      <td>34.62875</td>\n",
       "      <td>31.67875</td>\n",
       "      <td>42.050</td>\n",
       "      <td>41.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>70.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.54000</td>\n",
       "      <td>91.146000</td>\n",
       "      <td>90.138000</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>90.7090</td>\n",
       "      <td>91.122000</td>\n",
       "      <td>90.53800</td>\n",
       "      <td>90.38400</td>\n",
       "      <td>91.105</td>\n",
       "      <td>91.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>53.63800</td>\n",
       "      <td>51.554000</td>\n",
       "      <td>57.193000</td>\n",
       "      <td>63.3810</td>\n",
       "      <td>66.7380</td>\n",
       "      <td>77.824000</td>\n",
       "      <td>66.39100</td>\n",
       "      <td>68.14200</td>\n",
       "      <td>66.391</td>\n",
       "      <td>75.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.89000</td>\n",
       "      <td>99.379000</td>\n",
       "      <td>99.835000</td>\n",
       "      <td>99.7590</td>\n",
       "      <td>99.6610</td>\n",
       "      <td>99.725000</td>\n",
       "      <td>99.74800</td>\n",
       "      <td>99.82400</td>\n",
       "      <td>99.608</td>\n",
       "      <td>99.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>19.1250</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17.62500</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>24.375</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        0.1        0.2      0.3      0.4        0.5  \\\n",
       "F1-LOC        NaN        NaN        NaN      NaN      NaN  17.380000   \n",
       "F1-MISC  46.15000  46.150000  46.150000  46.1500  43.6825  43.682500   \n",
       "F1-O     94.43100  95.075000  94.737000  94.9000  94.9640  95.227000   \n",
       "F1-ORG        NaN        NaN        NaN      NaN      NaN        NaN   \n",
       "F1-PER    8.57625  47.702857  28.391429  32.1575  34.5975  39.691111   \n",
       "P-LOC     0.00000   0.000000   0.000000   0.0000   0.0000  60.000000   \n",
       "P-MISC   70.00000  60.000000  60.000000  70.0000  65.0000  65.000000   \n",
       "P-O      89.54000  91.146000  90.138000  90.5000  90.7090  91.122000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "P-PER    53.63800  51.554000  57.193000  63.3810  66.7380  77.824000   \n",
       "R-LOC     0.00000   0.000000   0.000000   0.0000   0.0000   5.712000   \n",
       "R-MISC   21.00000  18.000000  18.000000  21.0000  24.0000  24.000000   \n",
       "R-O      99.89000  99.379000  99.835000  99.7590  99.6610  99.725000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "R-PER     4.00000  25.000000  12.250000  16.7500  19.1250  23.500000   \n",
       "\n",
       "              0.6       0.7     0.8        0.9  \n",
       "F1-LOC        NaN       NaN     NaN  17.380000  \n",
       "F1-MISC  46.15000  46.15000  46.150  43.591111  \n",
       "F1-O     94.91800  94.86800  95.157  95.299000  \n",
       "F1-ORG        NaN       NaN     NaN        NaN  \n",
       "F1-PER   34.62875  31.67875  42.050  41.984444  \n",
       "P-LOC     0.00000   0.00000   0.000  60.000000  \n",
       "P-MISC   60.00000  60.00000  80.000  72.500000  \n",
       "P-O      90.53800  90.38400  91.105  91.426000  \n",
       "P-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "P-PER    66.39100  68.14200  66.391  75.073000  \n",
       "R-LOC     0.00000   0.00000   0.000   5.712000  \n",
       "R-MISC   18.00000  18.00000  24.000  27.000000  \n",
       "R-O      99.74800  99.82400  99.608  99.531000  \n",
       "R-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "R-PER    17.62500  15.75000  24.375  26.875000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>34.145859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>90.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>64.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>1.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>18.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   17.380000\n",
       "F1-MISC  45.400611\n",
       "F1-O     94.957600\n",
       "F1-ORG         NaN\n",
       "F1-PER   34.145859\n",
       "P-LOC    12.000000\n",
       "P-MISC   66.250000\n",
       "P-O      90.660800\n",
       "P-ORG     0.000000\n",
       "P-PER    64.632500\n",
       "R-LOC     1.142400\n",
       "R-MISC   21.300000\n",
       "R-O      99.696000\n",
       "R-ORG     0.000000\n",
       "R-PER    18.525000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.206887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>10.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>25.298221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.795628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.565721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>8.529639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.301515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.155470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>6.936167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    0.000000\n",
       "F1-MISC   1.206887\n",
       "F1-O      0.254209\n",
       "F1-ORG         NaN\n",
       "F1-PER   10.728242\n",
       "P-LOC    25.298221\n",
       "P-MISC    6.795628\n",
       "P-O       0.565721\n",
       "P-ORG     0.000000\n",
       "P-PER     8.529639\n",
       "R-LOC     2.408391\n",
       "R-MISC    3.301515\n",
       "R-O       0.155470\n",
       "R-ORG     0.000000\n",
       "R-PER     6.936167"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-4a85ba04e569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_fingerprints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreal_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ne-tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                              'argument.')\n\u001b[1;32m   1151\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
