{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "# if we are doeing binary classification. That means say if a token is a named entity or not\n",
    "BINARY = False\n",
    "\n",
    "# number of epochs for training\n",
    "epochs = 10 \n",
    "\n",
    "# the english side of the corpus\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "\n",
    "# the ewondo side of the corpus\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "\n",
    "# name of the file to same the model \n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "\n",
    "# The maximal number of phrases to use\n",
    "max_nb_of_phrases =  -1\n",
    "\n",
    "# the maximal number of duplicates for each word in the corpus\n",
    "duplication = 1\n",
    "\n",
    "# wether we are using only the vocabulary, ro redundancy\n",
    "is_only_vocab = True\n",
    "\n",
    "# if word should be shuffle or not\n",
    "shuffle = is_only_vocab\n",
    "\n",
    "# the number of neurons in the first layer\n",
    "h1_size = 640\n",
    "\n",
    "# number of neurons in the second layer\n",
    "h2_size = 160  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    \"\"\"\n",
    "        convert a string to a tag\n",
    "    \"\"\"\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    \"\"\"\n",
    "    Load a corpus stored in a file\n",
    "    Input:\n",
    "        - file: the name of the file of the corpus\n",
    "        - max_nb_of_phases: maximal number of phrases to load\n",
    "    \n",
    "    Return:\n",
    "        - a DataFrame representing the corpus\n",
    "        - the number of phrases in the corpus\n",
    "    \"\"\"\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                if l[0] not in string.punctuation:\n",
    "                    dataset[\"word\"].append(l[0])\n",
    "                    dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    \"\"\"\n",
    "    Create the distributionnal signature of each word in the corpus\n",
    "    Input:\n",
    "        -aDataFrame: the corpus DataFrame\n",
    "        -nb_of_biphrases: number of phrases in the corpus\n",
    "    Return:\n",
    "        a DataFrame: corpus fingerprint, the columns are the words in the corpus\n",
    "    \"\"\"\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    \"\"\"\n",
    "    Convert corpus to training data => numpy array\n",
    "    \n",
    "    Input:\n",
    "        -aDataFrame: Corpus dataframe\n",
    "        -fingerprintsDataFrame: distributionnal signature of words in the corpus\n",
    "    Return:\n",
    "        (X, y): X is the array of words (signature) in the corpus and y is the corresponding labels (NE tags)\n",
    "    \"\"\"\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "# A utility function to convert NE tags\n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    \"\"\"\n",
    "    Return the precision, recall, f1-score, accuracy and a dataframe comparing model predictions to ground truth\n",
    "    \"\"\"\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    # stop learning if the error is the same between two consecutive epochs\n",
    "    early_stop = EarlyStopping(patience=20, verbose=2)\n",
    "    \n",
    "    # saving best model\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    \n",
    "    #loading and returning the best model\n",
    "    return keras.models.load_model(best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    \"\"\"\n",
    "    Train a model on (X, y) and validate on (X_val, y_val) then project on (X_ewo)\n",
    "    \"\"\"\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    \"\"\"\n",
    "    Traing a model with k-fold cross validation\n",
    "    \"\"\"\n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Sadducees</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word ne-tag\n",
       "1335  Sadducees    ORG"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head()\n",
    "en_corpus.loc[en_corpus['ne-tag'] == 'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4379</td>\n",
       "      <td>4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>313</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4379   4170\n",
       "unique   904      5\n",
       "top      the      O\n",
       "freq     313   3779"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.3 %\n",
      "MISC % = 2.4 %\n",
      "PER % = 5.59 %\n",
      "LOC % = 0.91 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.16 %\n",
      "MISC % = 1.88 %\n",
      "PER % = 8.96 %\n",
      "LOC % = 1.99 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>O</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of     the    Holy  Spirit      In   first    book  \\\n",
       "0  4170.0   4170.0  4170.0  4170.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4170.0     0.0     0.0  4170.0  4170.0  4170.0   \n",
       "2     0.0      0.0     0.0  1390.0  4170.0  4170.0     0.0     0.0     0.0   \n",
       "3     0.0      0.0  4170.0  4170.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4170.0  2085.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        O  ...  considered  dream  She  save  fulfill  Immanuel  us)  woke  \\\n",
       "0     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "1  4170.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "2     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "3     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4     0.0  ...         0.0    0.0  0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "\n",
       "   sleep  knew  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "\n",
       "[5 rows x 903 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>rather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "count      903\n",
       "unique     903\n",
       "top     rather\n",
       "freq         1"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (210, 903) (903,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle_data(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "883       Eliud\n",
       "884     Eleazar\n",
       "885     Matthan\n",
       "886     husband\n",
       "887    fourteen\n",
       "888   unwilling\n",
       "889       shame\n",
       "890    resolved\n",
       "891     divorce\n",
       "892     quietly\n",
       "893  considered\n",
       "894       dream\n",
       "895         She\n",
       "896        save\n",
       "897     fulfill\n",
       "898    Immanuel\n",
       "899         us)\n",
       "900        woke\n",
       "901       sleep\n",
       "902        knew"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle:\n",
    "    X, target = shuffle_data(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 5)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def visualize(X, y):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_embeded = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(X_embeded[:, 0], X_embeded[:, 1], c=y)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (605, 210)\n",
      "y_train.shape = (605, 5)\n",
      "X_val.shape = (298, 210)\n",
      "y_val.shape = (298, 5)\n",
      "O % in training data = 86.28 %\n",
      "O % in validation data = 92.28 %\n",
      "MISC % in training data = 1.49 %\n",
      "MISC % in validation data = 0.67 %\n",
      "PER % in training data = 9.75 %\n",
      "PER % in validation data = 6.04 %\n",
      "LOC % in training data = 2.31 %\n",
      "LOC % in validation data = 1.01 %\n",
      "ORG % in training data = 0.17 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teofil</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Yohannes</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>Maria</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>Emmanuel</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>Yosef</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>Yesus</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word ne-tag\n",
       "6       Teofil    PER\n",
       "15       Yesus    PER\n",
       "86    Yohannes    PER\n",
       "104      Yesus    PER\n",
       "230      Yesus    PER\n",
       "...        ...    ...\n",
       "3676     Maria    PER\n",
       "3697     Yesus    PER\n",
       "3740  Emmanuel    PER\n",
       "3750     Yosef    PER\n",
       "3778     Yesus    PER\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.loc[ewo_corpus['ne-tag'] == 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 84.15 %\n",
      "MISC % = 2.54 %\n",
      "PER % = 6.69 %\n",
      "LOC % = 1.03 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.94 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.3 %\n",
      "LOC % = 1.86 %\n",
      "ORG % = 0.2 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3779</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>209</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   3779   3570\n",
       "unique  1024      5\n",
       "top       \\n      O\n",
       "freq     209   3180"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sò</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sò      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle_data(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>bëyole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Avëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>angavëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>oyò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>anganòṅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1013        sik\n",
       "1014       Ntud\n",
       "1015     bëyole\n",
       "1016   Emmanuel\n",
       "1017      Avëbë\n",
       "1018   angavëbë\n",
       "1019        oyò\n",
       "1020  angabende\n",
       "1021    anganòṅ\n",
       "1022   angayole"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle:\n",
    "    X_ewo, ewo_target = shuffle_data(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023,) 1023\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 210)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55556, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55556 to 0.54094, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54094 to 0.44100, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.44100 to 0.43581, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.43581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15547, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15547 to 0.07253, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07253\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07330, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07330\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12933, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12933\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05774, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05774\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06496, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06496 to 0.06457, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06457\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03705, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03705 to 0.03108, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03108\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07891, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07891 to 0.04582, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04582\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11610, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11610\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10420, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10420\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10420\n",
      "AlgoCrossValIter - 2\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52364, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52364 to 0.49317, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.49317 to 0.48681, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.48681\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48681\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48681\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48681 to 0.46988, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.46988 to 0.45156, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45156\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07788, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07788\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07788\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07788 to 0.07625, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07625\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07625\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07625\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07625\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07625\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08130, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08130\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13400, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13400\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06349, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06349\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08019, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08019 to 0.05703, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05703\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03460, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03460\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03460\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03460\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03460\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03460\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03460\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03460 to 0.02971, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02971\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02971\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04019, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04019\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11626, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11626\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09598, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09598\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09598\n",
      "AlgoCrossValIter - 3\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56296, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56296 to 0.53120, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53120 to 0.48237, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.48237 to 0.45145, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45145\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45145\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45145\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45145\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45145\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07657, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07657\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06115, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06115\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12084, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12084\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04899, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04899\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06382, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06382\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04395, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04395 to 0.03103, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03103\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04511, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04511\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12163, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12163\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09053, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09053\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 4\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57408, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.57408\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57408 to 0.49558, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49558 to 0.44804, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44804\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44804\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44804\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44804\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44804\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10512, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10512\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10512\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10512 to 0.10138, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10138\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10138\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10138\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10138\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10138\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06598, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06598\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16399, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16399\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16399 to 0.15565, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15565\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15565\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15565\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15565\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15565\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15565\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05626, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05715, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05715\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03333, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03333\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03333 to 0.03209, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03209\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03209\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03209\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03209\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03209\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03209\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04646, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04646\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13988, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13988\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09761, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09761\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09761\n",
      "AlgoCrossValIter - 5\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55311, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.55311\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55311 to 0.48042, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.48042\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48042 to 0.45271, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45271 to 0.44748, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44748\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44748\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08157, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08157\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08157 to 0.08059, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08059\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08059\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08059\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08059\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08059\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08059\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07634, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07634\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10627, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10627\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07735, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07735 to 0.06628, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06628\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06131, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06131\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03007, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03007 to 0.02753, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02753\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04730, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04730\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14343, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14343\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14343 to 0.13549, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13549\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09717, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09717\n",
      "AlgoCrossValIter - 6\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56517, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.56517\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56517 to 0.51985, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.51985 to 0.49947, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.49947\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49947 to 0.49605, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.49605\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.49605\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.49605\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.49605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09396, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09396\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13781, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13781 to 0.07376, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07376\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12217, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12217\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05437, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05437\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05405, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03359, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03359\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04751, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04751\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13229, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13229 to 0.12772, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12772\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10008, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10008\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10008\n",
      "AlgoCrossValIter - 7\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49760, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49760\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.49760 to 0.49463, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49463 to 0.45955, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45955\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45955 to 0.45238, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45238\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45238\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45238\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12230, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12230\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12230 to 0.07619, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07619\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07619\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07619\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07619\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07619\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07619\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09037, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09037 to 0.07728, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07728\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10668, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10668\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05447, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05447 to 0.05057, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05057\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05304, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05304\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05965, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05965 to 0.02985, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02985\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04543, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04543\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14782, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14782 to 0.12997, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12997\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09606, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09606\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09606\n",
      "AlgoCrossValIter - 8\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62010, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62010 to 0.54922, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54922 to 0.50249, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50249 to 0.45881, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.45881 to 0.42877, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.42877\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42877\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42877\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42877\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10559, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10559 to 0.09334, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09334\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09334\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09334\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09334\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09334 to 0.09312, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09312\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06828, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06828\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13733, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13733\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05391, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05391\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06785, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06785 to 0.06337, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06337\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03067, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03067\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04653, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04653 to 0.04650, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04650\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12052, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10111, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10111\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10111\n",
      "AlgoCrossValIter - 9\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52763, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52763 to 0.47396, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.47396 to 0.47219, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47219\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.47219 to 0.45901, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45901\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45901\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45901\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45901\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10499, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10499 to 0.08099, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08099\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09576, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09576\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09576 to 0.08727, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08727\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08727\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08727\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08727\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08727\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08727\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13175, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13175\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04905, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05744, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05744\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04646, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04646 to 0.04440, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04440\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04440\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04440 to 0.03430, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03430\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03430\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03430 to 0.03221, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03221\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03221\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04529, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04529\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12814, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12814\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10030, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10030 to 0.09945, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09945\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 10\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55145, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55145 to 0.52563, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52563 to 0.46404, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46404\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46404\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.46404\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.46404\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46404\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.46404\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06947, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06947\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07766, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07766\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11629, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11629\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05708, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05708\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05512, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05512\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03393, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03393\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03393 to 0.03216, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frankl1/miniconda3/envs/ner-projection/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04104, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04104\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13144, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13144\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09049, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09049\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09049\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>83.983</td>\n",
       "      <td>86.314</td>\n",
       "      <td>85.726</td>\n",
       "      <td>84.397</td>\n",
       "      <td>81.651</td>\n",
       "      <td>81.777</td>\n",
       "      <td>84.974</td>\n",
       "      <td>84.606</td>\n",
       "      <td>87.226</td>\n",
       "      <td>88.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>87.141</td>\n",
       "      <td>88.337</td>\n",
       "      <td>87.095</td>\n",
       "      <td>87.909</td>\n",
       "      <td>86.844</td>\n",
       "      <td>86.702</td>\n",
       "      <td>87.013</td>\n",
       "      <td>86.044</td>\n",
       "      <td>89.351</td>\n",
       "      <td>88.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>75.261</td>\n",
       "      <td>78.601</td>\n",
       "      <td>78.183</td>\n",
       "      <td>79.672</td>\n",
       "      <td>75.381</td>\n",
       "      <td>77.582</td>\n",
       "      <td>75.684</td>\n",
       "      <td>74.492</td>\n",
       "      <td>80.787</td>\n",
       "      <td>79.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>82.775</td>\n",
       "      <td>80.235</td>\n",
       "      <td>81.410</td>\n",
       "      <td>76.419</td>\n",
       "      <td>81.941</td>\n",
       "      <td>83.394</td>\n",
       "      <td>83.219</td>\n",
       "      <td>81.234</td>\n",
       "      <td>79.783</td>\n",
       "      <td>80.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>85.551</td>\n",
       "      <td>83.570</td>\n",
       "      <td>83.113</td>\n",
       "      <td>84.083</td>\n",
       "      <td>87.043</td>\n",
       "      <td>86.650</td>\n",
       "      <td>85.972</td>\n",
       "      <td>86.951</td>\n",
       "      <td>82.226</td>\n",
       "      <td>83.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>71.018</td>\n",
       "      <td>66.296</td>\n",
       "      <td>65.648</td>\n",
       "      <td>66.759</td>\n",
       "      <td>72.315</td>\n",
       "      <td>71.389</td>\n",
       "      <td>68.982</td>\n",
       "      <td>69.630</td>\n",
       "      <td>65.184</td>\n",
       "      <td>67.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>82.038</td>\n",
       "      <td>82.064</td>\n",
       "      <td>80.977</td>\n",
       "      <td>77.433</td>\n",
       "      <td>81.372</td>\n",
       "      <td>81.006</td>\n",
       "      <td>82.372</td>\n",
       "      <td>80.480</td>\n",
       "      <td>80.848</td>\n",
       "      <td>82.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>85.272</td>\n",
       "      <td>85.607</td>\n",
       "      <td>84.763</td>\n",
       "      <td>85.800</td>\n",
       "      <td>86.566</td>\n",
       "      <td>86.569</td>\n",
       "      <td>86.224</td>\n",
       "      <td>86.287</td>\n",
       "      <td>85.254</td>\n",
       "      <td>85.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>71.817</td>\n",
       "      <td>71.536</td>\n",
       "      <td>70.906</td>\n",
       "      <td>72.356</td>\n",
       "      <td>73.322</td>\n",
       "      <td>74.109</td>\n",
       "      <td>71.821</td>\n",
       "      <td>71.406</td>\n",
       "      <td>71.504</td>\n",
       "      <td>72.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       0       0       0       0       0       0       0  \\\n",
       "P_test    83.983  86.314  85.726  84.397  81.651  81.777  84.974  84.606   \n",
       "P_train   87.141  88.337  87.095  87.909  86.844  86.702  87.013  86.044   \n",
       "P_ewo     75.261  78.601  78.183  79.672  75.381  77.582  75.684  74.492   \n",
       "R_test    82.775  80.235  81.410  76.419  81.941  83.394  83.219  81.234   \n",
       "R_train   85.551  83.570  83.113  84.083  87.043  86.650  85.972  86.951   \n",
       "R_ewo     71.018  66.296  65.648  66.759  72.315  71.389  68.982  69.630   \n",
       "F1-test   82.038  82.064  80.977  77.433  81.372  81.006  82.372  80.480   \n",
       "F1-train  85.272  85.607  84.763  85.800  86.566  86.569  86.224  86.287   \n",
       "F1-ewo    71.817  71.536  70.906  72.356  73.322  74.109  71.821  71.406   \n",
       "\n",
       "               0       0  \n",
       "P_test    87.226  88.068  \n",
       "P_train   89.351  88.108  \n",
       "P_ewo     80.787  79.831  \n",
       "R_test    79.783  80.909  \n",
       "R_train   82.226  83.363  \n",
       "R_ewo     65.184  67.407  \n",
       "F1-test   80.848  82.035  \n",
       "F1-train  85.254  85.413  \n",
       "F1-ewo    71.504  72.756  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results.csv\")\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>84.8722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>87.4544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>77.5474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>81.1319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>84.8522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>68.4628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>81.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>85.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>72.1533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "P_test    84.8722\n",
       "P_train   87.4544\n",
       "P_ewo     77.5474\n",
       "R_test    81.1319\n",
       "R_train   84.8522\n",
       "R_ewo     68.4628\n",
       "F1-test   81.0625\n",
       "F1-train  85.7755\n",
       "F1-ewo    72.1533"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>2.098025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>0.963793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>2.222803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>2.049399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>1.781201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>2.559283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>1.425172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>0.617193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>0.985187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "P_test    2.098025\n",
       "P_train   0.963793\n",
       "P_ewo     2.222803\n",
       "R_test    2.049399\n",
       "R_train   1.781201\n",
       "R_ewo     2.559283\n",
       "F1-test   1.425172\n",
       "F1-train  0.617193\n",
       "F1-ewo    0.985187"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>98.154</td>\n",
       "      <td>98.181</td>\n",
       "      <td>98.091</td>\n",
       "      <td>98.182</td>\n",
       "      <td>98.2220</td>\n",
       "      <td>98.221</td>\n",
       "      <td>98.217</td>\n",
       "      <td>98.2070</td>\n",
       "      <td>98.156</td>\n",
       "      <td>98.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>98.118</td>\n",
       "      <td>97.863</td>\n",
       "      <td>97.825</td>\n",
       "      <td>97.919</td>\n",
       "      <td>98.2840</td>\n",
       "      <td>98.235</td>\n",
       "      <td>98.174</td>\n",
       "      <td>98.3030</td>\n",
       "      <td>97.682</td>\n",
       "      <td>97.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.217</td>\n",
       "      <td>98.510</td>\n",
       "      <td>98.369</td>\n",
       "      <td>98.452</td>\n",
       "      <td>98.1750</td>\n",
       "      <td>98.214</td>\n",
       "      <td>98.273</td>\n",
       "      <td>98.1200</td>\n",
       "      <td>98.651</td>\n",
       "      <td>98.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>78.788</td>\n",
       "      <td>76.051</td>\n",
       "      <td>75.208</td>\n",
       "      <td>74.990</td>\n",
       "      <td>79.8660</td>\n",
       "      <td>79.339</td>\n",
       "      <td>77.192</td>\n",
       "      <td>77.5650</td>\n",
       "      <td>77.207</td>\n",
       "      <td>77.628889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>92.071</td>\n",
       "      <td>95.278</td>\n",
       "      <td>89.167</td>\n",
       "      <td>95.139</td>\n",
       "      <td>93.0560</td>\n",
       "      <td>90.556</td>\n",
       "      <td>94.571</td>\n",
       "      <td>92.4120</td>\n",
       "      <td>92.511</td>\n",
       "      <td>85.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>70.769</td>\n",
       "      <td>64.304</td>\n",
       "      <td>69.031</td>\n",
       "      <td>63.193</td>\n",
       "      <td>70.7690</td>\n",
       "      <td>71.769</td>\n",
       "      <td>66.416</td>\n",
       "      <td>68.4360</td>\n",
       "      <td>67.547</td>\n",
       "      <td>59.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>88.301</td>\n",
       "      <td>88.690</td>\n",
       "      <td>88.206</td>\n",
       "      <td>89.271</td>\n",
       "      <td>89.7230</td>\n",
       "      <td>89.650</td>\n",
       "      <td>89.573</td>\n",
       "      <td>89.7100</td>\n",
       "      <td>88.427</td>\n",
       "      <td>89.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>87.691</td>\n",
       "      <td>89.124</td>\n",
       "      <td>88.131</td>\n",
       "      <td>88.780</td>\n",
       "      <td>87.9510</td>\n",
       "      <td>88.041</td>\n",
       "      <td>87.579</td>\n",
       "      <td>87.2090</td>\n",
       "      <td>89.904</td>\n",
       "      <td>88.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>90.658</td>\n",
       "      <td>89.006</td>\n",
       "      <td>88.775</td>\n",
       "      <td>89.878</td>\n",
       "      <td>92.0750</td>\n",
       "      <td>91.530</td>\n",
       "      <td>91.912</td>\n",
       "      <td>92.5240</td>\n",
       "      <td>87.756</td>\n",
       "      <td>90.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>75.785</td>\n",
       "      <td>77.576</td>\n",
       "      <td>74.936</td>\n",
       "      <td>75.775</td>\n",
       "      <td>77.3870</td>\n",
       "      <td>77.735</td>\n",
       "      <td>76.186</td>\n",
       "      <td>76.9530</td>\n",
       "      <td>75.426</td>\n",
       "      <td>78.441111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>85.962</td>\n",
       "      <td>85.578</td>\n",
       "      <td>84.793</td>\n",
       "      <td>81.605</td>\n",
       "      <td>82.8170</td>\n",
       "      <td>80.963</td>\n",
       "      <td>85.064</td>\n",
       "      <td>82.6250</td>\n",
       "      <td>88.105</td>\n",
       "      <td>77.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>73.807</td>\n",
       "      <td>73.193</td>\n",
       "      <td>69.403</td>\n",
       "      <td>73.032</td>\n",
       "      <td>77.7100</td>\n",
       "      <td>75.914</td>\n",
       "      <td>73.073</td>\n",
       "      <td>76.2200</td>\n",
       "      <td>68.746</td>\n",
       "      <td>65.762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>73.336</td>\n",
       "      <td>66.670</td>\n",
       "      <td>66.670</td>\n",
       "      <td>60.002</td>\n",
       "      <td>75.0025</td>\n",
       "      <td>73.336</td>\n",
       "      <td>72.225</td>\n",
       "      <td>75.0025</td>\n",
       "      <td>60.002</td>\n",
       "      <td>75.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>30.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>50.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       0       0       0        0       0       0        0  \\\n",
       "F1-O     98.154  98.181  98.091  98.182  98.2220  98.221  98.217  98.2070   \n",
       "P-O      98.118  97.863  97.825  97.919  98.2840  98.235  98.174  98.3030   \n",
       "R-O      98.217  98.510  98.369  98.452  98.1750  98.214  98.273  98.1200   \n",
       "F1-MISC  78.788  76.051  75.208  74.990  79.8660  79.339  77.192  77.5650   \n",
       "P-MISC   92.071  95.278  89.167  95.139  93.0560  90.556  94.571  92.4120   \n",
       "R-MISC   70.769  64.304  69.031  63.193  70.7690  71.769  66.416  68.4360   \n",
       "F1-PER   88.301  88.690  88.206  89.271  89.7230  89.650  89.573  89.7100   \n",
       "P-PER    87.691  89.124  88.131  88.780  87.9510  88.041  87.579  87.2090   \n",
       "R-PER    90.658  89.006  88.775  89.878  92.0750  91.530  91.912  92.5240   \n",
       "F1-LOC   75.785  77.576  74.936  75.775  77.3870  77.735  76.186  76.9530   \n",
       "P-LOC    85.962  85.578  84.793  81.605  82.8170  80.963  85.064  82.6250   \n",
       "R-LOC    73.807  73.193  69.403  73.032  77.7100  75.914  73.073  76.2200   \n",
       "F1-ORG   73.336  66.670  66.670  60.002  75.0025  73.336  72.225  75.0025   \n",
       "P-ORG    30.000  20.000  10.000  25.000  25.0000  30.000  35.000  25.0000   \n",
       "R-ORG    50.000  40.000  20.000  40.000  40.0000  50.000  60.000  40.0000   \n",
       "\n",
       "              0          0  \n",
       "F1-O     98.156  98.155000  \n",
       "P-O      97.682  97.829000  \n",
       "R-O      98.651  98.494000  \n",
       "F1-MISC  77.207  77.628889  \n",
       "P-MISC   92.511  85.417000  \n",
       "R-MISC   67.547  59.880000  \n",
       "F1-PER   88.427  89.566000  \n",
       "P-PER    89.904  88.466000  \n",
       "R-PER    87.756  90.896000  \n",
       "F1-LOC   75.426  78.441111  \n",
       "P-LOC    88.105  77.803000  \n",
       "R-LOC    68.746  65.762000  \n",
       "F1-ORG   60.002  75.002500  \n",
       "P-ORG    25.000  25.000000  \n",
       "R-ORG    40.000  40.000000  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag.csv\")\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>98.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>98.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.347500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>77.383489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>92.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>67.211400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>89.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>88.287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>90.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>76.620011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>83.531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>72.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>69.724850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     98.178600\n",
       "P-O      98.023200\n",
       "R-O      98.347500\n",
       "F1-MISC  77.383489\n",
       "P-MISC   92.017800\n",
       "R-MISC   67.211400\n",
       "F1-PER   89.111700\n",
       "P-PER    88.287600\n",
       "R-PER    90.501000\n",
       "F1-LOC   76.620011\n",
       "P-LOC    83.531500\n",
       "R-LOC    72.686000\n",
       "F1-ORG   69.724850\n",
       "P-ORG    25.000000\n",
       "R-ORG    42.000000"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.041267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.224308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.174253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.645114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>3.022204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.800447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>0.631590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.803233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>1.596444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>1.156330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>2.970389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>3.714482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>5.996519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>10.327956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O      0.041267\n",
       "P-O       0.224308\n",
       "R-O       0.174253\n",
       "F1-MISC   1.645114\n",
       "P-MISC    3.022204\n",
       "R-MISC    3.800447\n",
       "F1-PER    0.631590\n",
       "P-PER     0.803233\n",
       "R-PER     1.596444\n",
       "F1-LOC    1.156330\n",
       "P-LOC     2.970389\n",
       "R-LOC     3.714482\n",
       "F1-ORG    5.996519\n",
       "P-ORG     6.666667\n",
       "R-ORG    10.327956"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.725000</td>\n",
       "      <td>97.859000</td>\n",
       "      <td>97.672000</td>\n",
       "      <td>97.30500</td>\n",
       "      <td>97.851000</td>\n",
       "      <td>97.602000</td>\n",
       "      <td>97.792000</td>\n",
       "      <td>97.610000</td>\n",
       "      <td>97.748000</td>\n",
       "      <td>97.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.651000</td>\n",
       "      <td>97.401000</td>\n",
       "      <td>97.436000</td>\n",
       "      <td>96.70800</td>\n",
       "      <td>97.736000</td>\n",
       "      <td>97.656000</td>\n",
       "      <td>97.655000</td>\n",
       "      <td>97.431000</td>\n",
       "      <td>97.203000</td>\n",
       "      <td>97.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>97.855000</td>\n",
       "      <td>98.365000</td>\n",
       "      <td>97.993000</td>\n",
       "      <td>97.99500</td>\n",
       "      <td>97.988000</td>\n",
       "      <td>97.611000</td>\n",
       "      <td>97.991000</td>\n",
       "      <td>97.867000</td>\n",
       "      <td>98.376000</td>\n",
       "      <td>98.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>68.333750</td>\n",
       "      <td>66.667143</td>\n",
       "      <td>68.333750</td>\n",
       "      <td>63.81000</td>\n",
       "      <td>63.810000</td>\n",
       "      <td>68.333750</td>\n",
       "      <td>63.810000</td>\n",
       "      <td>63.810000</td>\n",
       "      <td>63.810000</td>\n",
       "      <td>68.333750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>56.667000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.667000</td>\n",
       "      <td>46.66700</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>56.667000</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>56.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>87.184000</td>\n",
       "      <td>85.395000</td>\n",
       "      <td>87.124000</td>\n",
       "      <td>83.55000</td>\n",
       "      <td>86.384000</td>\n",
       "      <td>85.619000</td>\n",
       "      <td>88.442000</td>\n",
       "      <td>86.024000</td>\n",
       "      <td>86.374000</td>\n",
       "      <td>86.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>87.259000</td>\n",
       "      <td>86.890000</td>\n",
       "      <td>88.954000</td>\n",
       "      <td>87.60300</td>\n",
       "      <td>84.708000</td>\n",
       "      <td>83.954000</td>\n",
       "      <td>87.825000</td>\n",
       "      <td>88.065000</td>\n",
       "      <td>88.954000</td>\n",
       "      <td>88.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>88.342000</td>\n",
       "      <td>85.644000</td>\n",
       "      <td>87.548000</td>\n",
       "      <td>82.74600</td>\n",
       "      <td>88.659000</td>\n",
       "      <td>88.659000</td>\n",
       "      <td>90.365000</td>\n",
       "      <td>86.437000</td>\n",
       "      <td>86.437000</td>\n",
       "      <td>85.603000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>49.630000</td>\n",
       "      <td>54.815556</td>\n",
       "      <td>44.075556</td>\n",
       "      <td>49.58375</td>\n",
       "      <td>55.185556</td>\n",
       "      <td>49.630000</td>\n",
       "      <td>51.482222</td>\n",
       "      <td>49.731111</td>\n",
       "      <td>55.185556</td>\n",
       "      <td>56.173333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>46.333000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>36.33300</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>46.333000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>45.833000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>51.333000</td>\n",
       "      <td>54.667000</td>\n",
       "      <td>46.333000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>51.333000</td>\n",
       "      <td>51.333000</td>\n",
       "      <td>51.333000</td>\n",
       "      <td>53.333000</td>\n",
       "      <td>51.333000</td>\n",
       "      <td>51.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>11.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0          0         0          0          0  \\\n",
       "F1-O     97.725000  97.859000  97.672000  97.30500  97.851000  97.602000   \n",
       "P-O      97.651000  97.401000  97.436000  96.70800  97.736000  97.656000   \n",
       "R-O      97.855000  98.365000  97.993000  97.99500  97.988000  97.611000   \n",
       "F1-MISC  68.333750  66.667143  68.333750  63.81000  63.810000  68.333750   \n",
       "P-MISC   56.667000  50.000000  56.667000  46.66700  46.667000  56.667000   \n",
       "R-MISC   55.000000  45.000000  55.000000  45.00000  45.000000  55.000000   \n",
       "F1-PER   87.184000  85.395000  87.124000  83.55000  86.384000  85.619000   \n",
       "P-PER    87.259000  86.890000  88.954000  87.60300  84.708000  83.954000   \n",
       "R-PER    88.342000  85.644000  87.548000  82.74600  88.659000  88.659000   \n",
       "F1-LOC   49.630000  54.815556  44.075556  49.58375  55.185556  49.630000   \n",
       "P-LOC    46.333000  48.000000  43.000000  36.33300  53.000000  46.333000   \n",
       "R-LOC    51.333000  54.667000  46.333000  48.00000  51.333000  51.333000   \n",
       "F1-ORG   11.111111  10.000000  10.000000   0.00000  11.111111  11.111111   \n",
       "P-ORG    10.000000  10.000000  10.000000   0.00000  10.000000  10.000000   \n",
       "R-ORG    10.000000  10.000000  10.000000   0.00000  10.000000  10.000000   \n",
       "\n",
       "                 0          0          0          0  \n",
       "F1-O     97.792000  97.610000  97.748000  97.871000  \n",
       "P-O      97.655000  97.431000  97.203000  97.316000  \n",
       "R-O      97.991000  97.867000  98.376000  98.505000  \n",
       "F1-MISC  63.810000  63.810000  63.810000  68.333750  \n",
       "P-MISC   46.667000  46.667000  46.667000  56.667000  \n",
       "R-MISC   45.000000  45.000000  45.000000  55.000000  \n",
       "F1-PER   88.442000  86.024000  86.374000  86.072000  \n",
       "P-PER    87.825000  88.065000  88.954000  88.714000  \n",
       "R-PER    90.365000  86.437000  86.437000  85.603000  \n",
       "F1-LOC   51.482222  49.731111  55.185556  56.173333  \n",
       "P-LOC    48.000000  45.833000  53.000000  55.000000  \n",
       "R-LOC    51.333000  53.333000  51.333000  51.333000  \n",
       "F1-ORG   11.111111  11.111111   0.000000  11.111111  \n",
       "P-ORG    10.000000  10.000000   0.000000  10.000000  \n",
       "R-ORG    10.000000  10.000000   0.000000  10.000000  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag.csv\")\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.703500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.419300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>65.905214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>51.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>86.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>87.292600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>87.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>51.549264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>47.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>51.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.703500\n",
       "P-O      97.419300\n",
       "R-O      98.054600\n",
       "F1-MISC  65.905214\n",
       "P-MISC   51.000300\n",
       "R-MISC   49.000000\n",
       "F1-PER   86.216800\n",
       "P-PER    87.292600\n",
       "R-PER    87.044000\n",
       "F1-LOC   51.549264\n",
       "P-LOC    47.483200\n",
       "R-LOC    51.033100\n",
       "F1-ORG    8.666667\n",
       "P-ORG     8.000000\n",
       "R-ORG     8.000000"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.170980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.303630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.276917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>2.263755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>4.981454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>5.163978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>1.289503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>1.716162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>2.145551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>3.784365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>5.453864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.364672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>4.590202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>4.216370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>4.216370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-O     0.170980\n",
       "P-O      0.303630\n",
       "R-O      0.276917\n",
       "F1-MISC  2.263755\n",
       "P-MISC   4.981454\n",
       "R-MISC   5.163978\n",
       "F1-PER   1.289503\n",
       "P-PER    1.716162\n",
       "R-PER    2.145551\n",
       "F1-LOC   3.784365\n",
       "P-LOC    5.453864\n",
       "R-LOC    2.364672\n",
       "F1-ORG   4.590202\n",
       "P-ORG    4.216370\n",
       "R-ORG    4.216370"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>96.964</td>\n",
       "      <td>97.085</td>\n",
       "      <td>97.091</td>\n",
       "      <td>97.207000</td>\n",
       "      <td>97.133</td>\n",
       "      <td>97.209</td>\n",
       "      <td>97.069</td>\n",
       "      <td>96.931</td>\n",
       "      <td>97.177</td>\n",
       "      <td>97.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.787</td>\n",
       "      <td>96.262</td>\n",
       "      <td>96.244</td>\n",
       "      <td>96.319000</td>\n",
       "      <td>96.984</td>\n",
       "      <td>96.790</td>\n",
       "      <td>96.613</td>\n",
       "      <td>96.661</td>\n",
       "      <td>96.164</td>\n",
       "      <td>96.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>97.170</td>\n",
       "      <td>97.934</td>\n",
       "      <td>97.968</td>\n",
       "      <td>98.119000</td>\n",
       "      <td>97.301</td>\n",
       "      <td>97.638</td>\n",
       "      <td>97.542</td>\n",
       "      <td>97.222</td>\n",
       "      <td>98.229</td>\n",
       "      <td>98.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>54.962</td>\n",
       "      <td>44.672</td>\n",
       "      <td>48.090</td>\n",
       "      <td>48.963333</td>\n",
       "      <td>54.337</td>\n",
       "      <td>54.311</td>\n",
       "      <td>48.283</td>\n",
       "      <td>54.123</td>\n",
       "      <td>49.950</td>\n",
       "      <td>47.904444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.569</td>\n",
       "      <td>66.670</td>\n",
       "      <td>53.891</td>\n",
       "      <td>60.479000</td>\n",
       "      <td>67.621</td>\n",
       "      <td>65.914</td>\n",
       "      <td>66.392</td>\n",
       "      <td>68.176</td>\n",
       "      <td>66.035</td>\n",
       "      <td>60.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>50.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>47.500</td>\n",
       "      <td>47.500</td>\n",
       "      <td>40.000</td>\n",
       "      <td>47.500</td>\n",
       "      <td>42.500</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>76.721</td>\n",
       "      <td>77.371</td>\n",
       "      <td>77.546</td>\n",
       "      <td>78.554000</td>\n",
       "      <td>78.980</td>\n",
       "      <td>79.702</td>\n",
       "      <td>77.941</td>\n",
       "      <td>77.106</td>\n",
       "      <td>77.695</td>\n",
       "      <td>79.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>75.977</td>\n",
       "      <td>79.470</td>\n",
       "      <td>79.470</td>\n",
       "      <td>81.036000</td>\n",
       "      <td>76.863</td>\n",
       "      <td>79.103</td>\n",
       "      <td>77.467</td>\n",
       "      <td>76.261</td>\n",
       "      <td>81.903</td>\n",
       "      <td>80.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>79.875</td>\n",
       "      <td>76.375</td>\n",
       "      <td>76.375</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>80.750</td>\n",
       "      <td>78.875</td>\n",
       "      <td>78.625</td>\n",
       "      <td>75.000</td>\n",
       "      <td>78.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>56.972</td>\n",
       "      <td>54.187</td>\n",
       "      <td>49.397</td>\n",
       "      <td>54.305000</td>\n",
       "      <td>54.962</td>\n",
       "      <td>57.919</td>\n",
       "      <td>52.717</td>\n",
       "      <td>53.245</td>\n",
       "      <td>50.198</td>\n",
       "      <td>55.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>88.483</td>\n",
       "      <td>93.253</td>\n",
       "      <td>92.778</td>\n",
       "      <td>88.587000</td>\n",
       "      <td>79.088</td>\n",
       "      <td>88.190</td>\n",
       "      <td>84.074</td>\n",
       "      <td>82.997</td>\n",
       "      <td>93.546</td>\n",
       "      <td>84.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>45.557</td>\n",
       "      <td>39.999</td>\n",
       "      <td>34.999</td>\n",
       "      <td>42.222000</td>\n",
       "      <td>45.557</td>\n",
       "      <td>45.001</td>\n",
       "      <td>41.666</td>\n",
       "      <td>44.443</td>\n",
       "      <td>36.666</td>\n",
       "      <td>36.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330</td>\n",
       "      <td>33.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>15.000</td>\n",
       "      <td>12.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.500</td>\n",
       "      <td>15.000</td>\n",
       "      <td>17.500</td>\n",
       "      <td>12.500</td>\n",
       "      <td>10.000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>30.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     0.1     0.2        0.3     0.4     0.5     0.6     0.7  \\\n",
       "F1-O     96.964  97.085  97.091  97.207000  97.133  97.209  97.069  96.931   \n",
       "P-O      96.787  96.262  96.244  96.319000  96.984  96.790  96.613  96.661   \n",
       "R-O      97.170  97.934  97.968  98.119000  97.301  97.638  97.542  97.222   \n",
       "F1-MISC  54.962  44.672  48.090  48.963333  54.337  54.311  48.283  54.123   \n",
       "P-MISC   66.569  66.670  53.891  60.479000  67.621  65.914  66.392  68.176   \n",
       "R-MISC   50.000  35.000  40.000  36.250000  47.500  47.500  40.000  47.500   \n",
       "F1-PER   76.721  77.371  77.546  78.554000  78.980  79.702  77.941  77.106   \n",
       "P-PER    75.977  79.470  79.470  81.036000  76.863  79.103  77.467  76.261   \n",
       "R-PER    79.875  76.375  76.375  76.500000  82.000  80.750  78.875  78.625   \n",
       "F1-LOC   56.972  54.187  49.397  54.305000  54.962  57.919  52.717  53.245   \n",
       "P-LOC    88.483  93.253  92.778  88.587000  79.088  88.190  84.074  82.997   \n",
       "R-LOC    45.557  39.999  34.999  42.222000  45.557  45.001  41.666  44.443   \n",
       "F1-ORG   33.330  33.330  33.330  33.330000  33.330  33.330  33.330  33.330   \n",
       "P-ORG    15.000  12.500   7.500  10.000000  12.500  15.000  17.500  12.500   \n",
       "R-ORG    30.000  25.000  15.000  20.000000  25.000  30.000  35.000  25.000   \n",
       "\n",
       "            0.8        0.9  \n",
       "F1-O     97.177  97.228000  \n",
       "P-O      96.164  96.382000  \n",
       "R-O      98.229  98.100000  \n",
       "F1-MISC  49.950  47.904444  \n",
       "P-MISC   66.035  60.003000  \n",
       "R-MISC   42.500  35.000000  \n",
       "F1-PER   77.695  79.490000  \n",
       "P-PER    81.903  80.557000  \n",
       "R-PER    75.000  78.750000  \n",
       "F1-LOC   50.198  55.371111  \n",
       "P-LOC    93.546  84.515000  \n",
       "R-LOC    36.666  36.111000  \n",
       "F1-ORG   33.330  33.330000  \n",
       "P-ORG    10.000  12.500000  \n",
       "R-ORG    20.000  25.000000  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag.csv\", index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>97.722300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>50.559578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>64.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>42.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>78.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>78.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>78.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>53.927311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>87.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>41.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>33.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.109400\n",
       "P-O      96.520600\n",
       "R-O      97.722300\n",
       "F1-MISC  50.559578\n",
       "P-MISC   64.175000\n",
       "R-MISC   42.125000\n",
       "F1-PER   78.110600\n",
       "P-PER    78.810700\n",
       "R-PER    78.312500\n",
       "F1-LOC   53.927311\n",
       "P-LOC    87.551100\n",
       "R-LOC    41.222100\n",
       "F1-ORG   33.330000\n",
       "P-ORG    12.500000\n",
       "R-ORG    25.000000"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>1.022917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>2.822395e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>3.992218e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>3.595304e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>4.571222e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>5.714565e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>1.021722e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>2.072265e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>2.219899e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>2.685989e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>4.851033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>4.089800e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>4.102320e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>2.886751e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>5.773503e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "F1-O     1.022917e-01\n",
       "P-O      2.822395e-01\n",
       "R-O      3.992218e-01\n",
       "F1-MISC  3.595304e+00\n",
       "P-MISC   4.571222e+00\n",
       "R-MISC   5.714565e+00\n",
       "F1-PER   1.021722e+00\n",
       "P-PER    2.072265e+00\n",
       "R-PER    2.219899e+00\n",
       "F1-LOC   2.685989e+00\n",
       "P-LOC    4.851033e+00\n",
       "R-LOC    4.089800e+00\n",
       "F1-ORG   4.102320e-15\n",
       "P-ORG    2.886751e+00\n",
       "R-ORG    5.773503e+00"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n",
      "O\tLOC\t4170.0\tSamaria\n",
      "O\tLOC\t4170.0\tOlivet\n",
      "O\tMISC\t4170.0\tSabbath\n",
      "PER\tO\t4170.0\tupper\n",
      "PER\tO\t4170.0\troom\n",
      "PER\tO\t4170.0\twhere\n",
      "PER\tO\t4170.0\tZealot\n",
      "LOC\tO\t4170.0\tso\n",
      "LOC\tO\t4170.0\tlanguage\n",
      "O\tMISC\t4170.0\tPsalms\n",
      "PER\tO\t4170.0\tforward\n",
      "MISC\tO\t4170.0\tgoing\n",
      "O\tPER\t4170.0\tMoses\n",
      "PER\tO\t4170.0\tproclaimed\n",
      "ORG\tO\t4170.0\tcaptain\n",
      "PER\tO\t4170.0\thigh-priestly\n",
      "PER\tO\t4170.0\tfamily\n",
      "O\tPER\t4170.0\tPontius\n",
      "O\tPER\t4170.0\tBarnabas\n",
      "O\tLOC\t4170.0\tCyprus\n",
      "O\tPER\t4170.0\tElijah\n",
      "O\tMISC\t4170.0\tr\n",
      "PER\tO\t4170.0\tJu\n",
      "PER\tO\t4170.0\th\n",
      "LOC\tO\t4170.0\tdeportation\n",
      "PER\tO\t4170.0\tus)\n"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:ner-projection] *",
   "language": "python",
   "name": "conda-env-ner-projection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
