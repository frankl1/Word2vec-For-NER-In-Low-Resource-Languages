{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 10\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab\n",
    "h1_size = 320\n",
    "h2_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                dataset[\"word\"].append(l[0])\n",
    "                dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4962</td>\n",
       "      <td>4753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>913</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>343</td>\n",
       "      <td>4362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4962   4753\n",
       "unique   913      5\n",
       "top        ,      O\n",
       "freq     343   4362"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 87.91 %\n",
      "MISC % = 2.12 %\n",
      "PER % = 4.94 %\n",
      "LOC % = 0.81 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.27 %\n",
      "MISC % = 1.86 %\n",
      "PER % = 8.87 %\n",
      "LOC % = 1.97 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>2376.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2376.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 912 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of          the    Holy  Spirit      In   first  \\\n",
       "0  4753.0   4753.0  4753.0  4753.000000  4753.0  4753.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4753.000000     0.0     0.0  4753.0  4753.0   \n",
       "2     0.0      0.0     0.0  1584.333374  4753.0  4753.0     0.0     0.0   \n",
       "3     0.0      0.0  4753.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4753.0  2376.500000     0.0     0.0     0.0     0.0   \n",
       "5     0.0      0.0     0.0  4753.000000  4753.0  4753.0     0.0     0.0   \n",
       "6  4753.0      0.0     0.0     0.000000     0.0     0.0     0.0     0.0   \n",
       "7     0.0      0.0     0.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "8     0.0      0.0     0.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "9     0.0      0.0  4753.0  1584.333374  4753.0  4753.0     0.0     0.0   \n",
       "\n",
       "     book            ,  ...   considered  dream  She  save  fulfill  Immanuel  \\\n",
       "0     0.0     0.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "1  4753.0  1584.333374  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "2     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "3     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "4     0.0  1188.250000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "5     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "6     0.0     0.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "7     0.0  1584.333374  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "8     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "9     0.0  2376.500000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "\n",
       "   us)  woke  sleep  knew  \n",
       "0  0.0   0.0    0.0   0.0  \n",
       "1  0.0   0.0    0.0   0.0  \n",
       "2  0.0   0.0    0.0   0.0  \n",
       "3  0.0   0.0    0.0   0.0  \n",
       "4  0.0   0.0    0.0   0.0  \n",
       "5  0.0   0.0    0.0   0.0  \n",
       "6  0.0   0.0    0.0   0.0  \n",
       "7  0.0   0.0    0.0   0.0  \n",
       "8  0.0   0.0    0.0   0.0  \n",
       "9  0.0   0.0    0.0   0.0  \n",
       "\n",
       "[10 rows x 912 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 2)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>robes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "count     912\n",
       "unique    912\n",
       "top     robes\n",
       "freq        1"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (210, 912) (912,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "892       Eliud\n",
       "893     Eleazar\n",
       "894     Matthan\n",
       "895     husband\n",
       "896    fourteen\n",
       "897   unwilling\n",
       "898       shame\n",
       "899    resolved\n",
       "900     divorce\n",
       "901     quietly\n",
       "902  considered\n",
       "903       dream\n",
       "904         She\n",
       "905        save\n",
       "906     fulfill\n",
       "907    Immanuel\n",
       "908         us)\n",
       "909        woke\n",
       "910       sleep\n",
       "911        knew"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (912,)\n",
      "(912, 210) (912,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912, 5)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (611, 210)\n",
      "y_train.shape = (611, 5)\n",
      "X_val.shape = (301, 210)\n",
      "y_val.shape = (301, 5)\n",
      "O % in training data = 88.05 %\n",
      "O % in validation data = 89.04 %\n",
      "MISC % in training data = 1.15 %\n",
      "MISC % in validation data = 1.33 %\n",
      "PER % in training data = 9.0 %\n",
      "PER % in validation data = 7.31 %\n",
      "LOC % in training data = 1.64 %\n",
      "LOC % in validation data = 2.33 %\n",
      "ORG % in training data = 0.16 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=2, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.37 %\n",
      "MISC % = 2.18 %\n",
      "PER % = 5.76 %\n",
      "LOC % = 0.89 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 90.0 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.25 %\n",
      "LOC % = 1.84 %\n",
      "ORG % = 0.19 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4394</td>\n",
       "      <td>4185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1030</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>413</td>\n",
       "      <td>3795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4394   4185\n",
       "unique  1030      5\n",
       "top        ,      O\n",
       "freq     413   3795"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sò</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sò      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>obë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>yasò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>oyolëge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>bëyole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Avëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>angavëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>oyò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>anganòṅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1009        nlo\n",
       "1010        obë\n",
       "1011      mbara\n",
       "1012    yabyali\n",
       "1013      dzili\n",
       "1014       yasò\n",
       "1015    oyolëge\n",
       "1016       kode\n",
       "1017       dili\n",
       "1018     atoban\n",
       "1019        sik\n",
       "1020       Ntud\n",
       "1021     bëyole\n",
       "1022   Emmanuel\n",
       "1023      Avëbë\n",
       "1024   angavëbë\n",
       "1025        oyò\n",
       "1026  angabende\n",
       "1027    anganòṅ\n",
       "1028   angayole"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 210) (1029,)\n",
      "(1029, 210) (1029,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029,) 1029\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 210)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57132, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57132 to 0.55648, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.55648\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55648 to 0.52631, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52631 to 0.49648, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.49648\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.49648\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22229, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22229 to 0.19053, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19053 to 0.16683, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16683\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16683\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15732, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15732\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15732\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17291, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17291\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17291\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08691, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08691\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08691\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09678, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09678\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09678\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05230, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05230\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05230\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13521, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13521 to 0.12974, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12974\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12974\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07332, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07332\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07332\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09802, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09802\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09802\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64081, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64081 to 0.54882, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54882 to 0.50220, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50220 to 0.47746, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47746\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47746\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24223, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24223 to 0.21010, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21010\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21010\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17090, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17090\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17090\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16189, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16189\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16189\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11830, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11830 to 0.08601, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08601\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08601\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08010, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08010\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08010\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05387, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05387 to 0.04034, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04034\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04034 to 0.03586, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03586\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03586\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11864, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11864\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11864\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11263, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11263 to 0.06575, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06575 to 0.05620, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05620\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05620\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09155, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09155\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09155\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68541, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68541 to 0.55263, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.55263\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.55263\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23671, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23671 to 0.19688, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19688\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19688\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18174, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18174\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18174\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20154, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20154\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20154\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09319, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09319\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09319\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12574, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12574\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12574\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05181, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05181\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05181\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11558, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11558\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11558\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06378, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06378 to 0.05834, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05834\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05834\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07882, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07882\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07882\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67420, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67420 to 0.64259, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.64259\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.64259\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20117, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20117\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20117\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22705, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22705 to 0.22504, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22504\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22504\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20831, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20831\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20831\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10794, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10794 to 0.09251, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09251\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09251\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12793, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12793\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12793\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06253, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06253 to 0.05005, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05005 to 0.04499, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04499\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04499\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12544, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12544\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12544\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06340, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06340\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06340 to 0.06173, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06173\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06173\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08935, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08935\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08935\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55794, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55794 to 0.52120, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.52120\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.52120 to 0.47830, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47830\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47830\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17065, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17065\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17065\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18462, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18462\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18462\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20871, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20871\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20871\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08981, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08981\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08981\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13108, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13108\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03661, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03661\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03661\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13582, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13582\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13582\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04867, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04867\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04867\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09879, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09879\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09879\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63728, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63728 to 0.63059, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63059 to 0.53260, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53260\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53260 to 0.47502, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47502 to 0.45327, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45327\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45327\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17610, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17610\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17610\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19372, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19372\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19372\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15790, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15790\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15790\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07097, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07097\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07097\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11341, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11341\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11341 to 0.09132, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09132\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09132\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03855, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03855\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03855\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15185, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15185 to 0.12879, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12879\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12879\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05815, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05815 to 0.05354, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05354\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05354\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08173, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08173\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08173\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64574, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64574 to 0.55500, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.55500\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.55500\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24130, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24130 to 0.18989, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18989\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18989\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22313, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22313 to 0.20194, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20194\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20194\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16537, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16537\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16537\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11152, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11152\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11152 to 0.09512, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09512\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09512\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11451, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11451\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11451\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06153, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06153 to 0.03680, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03680\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03680\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14920, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14920\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14920\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07522, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07522 to 0.06865, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06865\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06865\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10318, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10318\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56775, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.56775\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56775 to 0.56257, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56257 to 0.56117, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56117 to 0.54422, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.54422\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.54422 to 0.53713, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.53713\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53713 to 0.50132, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.50132 to 0.47037, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14187, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14187\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14187\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16438, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16438\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16438\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14617, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14617\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14617\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09632, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09632 to 0.09439, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09439 to 0.08721, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08721\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08721\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07877, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07877\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07877\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05881, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05881 to 0.04877, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04877\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04877\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12230, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12230\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12230\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04905, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04905\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04905\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10363, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10363\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10363\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58200, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58200 to 0.54393, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.54393\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.54393\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20434, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20434\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20434\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23027, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23027\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23027\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19947, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19947\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19947\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11942, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11942\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11942\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10383, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10383\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10383\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04671, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04671 to 0.03714, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03714\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03714\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14988, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14988 to 0.13814, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13814\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13814\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13802, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13802 to 0.08107, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08107 to 0.07910, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07910 to 0.06238, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06238\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06238\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11173, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11173\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11173\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 320)               67520     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 119,685\n",
      "Trainable params: 119,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60921, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.60921\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60921 to 0.59616, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59616 to 0.54240, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.54240\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54240 to 0.47925, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47925\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.47925\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16464, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16464 to 0.14288, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14288\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14288\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15712, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15712\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15712\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15343, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15343\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15343\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10725, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10725 to 0.08620, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08620\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08620\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08505, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08505\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08505\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05436, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05436\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05436 to 0.04198, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04198\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04198\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12884, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12884\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12884\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04793, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04793\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04793\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08388, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08388\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08388\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>82.284</td>\n",
       "      <td>84.177</td>\n",
       "      <td>73.203000</td>\n",
       "      <td>73.984000</td>\n",
       "      <td>84.210</td>\n",
       "      <td>83.671</td>\n",
       "      <td>77.319000</td>\n",
       "      <td>82.155</td>\n",
       "      <td>70.10800</td>\n",
       "      <td>81.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>87.694</td>\n",
       "      <td>89.827</td>\n",
       "      <td>86.166000</td>\n",
       "      <td>79.699000</td>\n",
       "      <td>86.829</td>\n",
       "      <td>86.804</td>\n",
       "      <td>85.376000</td>\n",
       "      <td>89.758</td>\n",
       "      <td>87.12200</td>\n",
       "      <td>88.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>75.466</td>\n",
       "      <td>85.041</td>\n",
       "      <td>76.699000</td>\n",
       "      <td>71.190000</td>\n",
       "      <td>78.624</td>\n",
       "      <td>77.296</td>\n",
       "      <td>74.030000</td>\n",
       "      <td>79.414</td>\n",
       "      <td>76.64300</td>\n",
       "      <td>76.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>67.495</td>\n",
       "      <td>66.135</td>\n",
       "      <td>64.091000</td>\n",
       "      <td>56.254000</td>\n",
       "      <td>65.787</td>\n",
       "      <td>71.883</td>\n",
       "      <td>62.322000</td>\n",
       "      <td>69.508</td>\n",
       "      <td>62.49500</td>\n",
       "      <td>73.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>73.581</td>\n",
       "      <td>69.436</td>\n",
       "      <td>67.860000</td>\n",
       "      <td>62.262000</td>\n",
       "      <td>69.856</td>\n",
       "      <td>74.079</td>\n",
       "      <td>65.645000</td>\n",
       "      <td>73.758</td>\n",
       "      <td>62.71900</td>\n",
       "      <td>74.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>58.798</td>\n",
       "      <td>55.463</td>\n",
       "      <td>53.798000</td>\n",
       "      <td>50.648000</td>\n",
       "      <td>56.666</td>\n",
       "      <td>60.278</td>\n",
       "      <td>53.240000</td>\n",
       "      <td>58.889</td>\n",
       "      <td>51.94500</td>\n",
       "      <td>60.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>70.617</td>\n",
       "      <td>70.841</td>\n",
       "      <td>74.772222</td>\n",
       "      <td>70.220000</td>\n",
       "      <td>71.050</td>\n",
       "      <td>74.953</td>\n",
       "      <td>72.832222</td>\n",
       "      <td>73.800</td>\n",
       "      <td>82.09625</td>\n",
       "      <td>75.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>79.355</td>\n",
       "      <td>77.230</td>\n",
       "      <td>73.879000</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>76.294</td>\n",
       "      <td>79.152</td>\n",
       "      <td>71.751000</td>\n",
       "      <td>80.137</td>\n",
       "      <td>69.88500</td>\n",
       "      <td>79.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>65.061</td>\n",
       "      <td>66.066</td>\n",
       "      <td>61.319000</td>\n",
       "      <td>64.375556</td>\n",
       "      <td>64.453</td>\n",
       "      <td>66.897</td>\n",
       "      <td>59.854000</td>\n",
       "      <td>66.624</td>\n",
       "      <td>59.18000</td>\n",
       "      <td>65.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       0          0          0       0       0          0  \\\n",
       "P_test    82.284  84.177  73.203000  73.984000  84.210  83.671  77.319000   \n",
       "P_train   87.694  89.827  86.166000  79.699000  86.829  86.804  85.376000   \n",
       "P_ewo     75.466  85.041  76.699000  71.190000  78.624  77.296  74.030000   \n",
       "R_test    67.495  66.135  64.091000  56.254000  65.787  71.883  62.322000   \n",
       "R_train   73.581  69.436  67.860000  62.262000  69.856  74.079  65.645000   \n",
       "R_ewo     58.798  55.463  53.798000  50.648000  56.666  60.278  53.240000   \n",
       "F1-test   70.617  70.841  74.772222  70.220000  71.050  74.953  72.832222   \n",
       "F1-train  79.355  77.230  73.879000  76.500000  76.294  79.152  71.751000   \n",
       "F1-ewo    65.061  66.066  61.319000  64.375556  64.453  66.897  59.854000   \n",
       "\n",
       "               0         0       0  \n",
       "P_test    82.155  70.10800  81.818  \n",
       "P_train   89.758  87.12200  88.597  \n",
       "P_ewo     79.414  76.64300  76.212  \n",
       "R_test    69.508  62.49500  73.071  \n",
       "R_train   73.758  62.71900  74.576  \n",
       "R_ewo     58.889  51.94500  60.186  \n",
       "F1-test   73.800  82.09625  75.084  \n",
       "F1-train  80.137  69.88500  79.898  \n",
       "F1-ewo    66.624  59.18000  65.707  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>79.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>86.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>77.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>65.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>69.377200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>55.991100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>73.626569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>76.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>63.953656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "P_test    79.292900\n",
       "P_train   86.787200\n",
       "P_ewo     77.061500\n",
       "R_test    65.904100\n",
       "R_train   69.377200\n",
       "R_ewo     55.991100\n",
       "F1-test   73.626569\n",
       "F1-train  76.408100\n",
       "F1-ewo    63.953656"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>5.209441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>2.884783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>3.635342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>4.984007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>4.683534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>3.500531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>3.537936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>3.553247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>2.818986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "P_test    5.209441\n",
       "P_train   2.884783\n",
       "P_ewo     3.635342\n",
       "R_test    4.984007\n",
       "R_train   4.683534\n",
       "R_ewo     3.500531\n",
       "F1-test   3.537936\n",
       "F1-train  3.553247\n",
       "F1-ewo    2.818986"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.631000</td>\n",
       "      <td>97.465000</td>\n",
       "      <td>97.307000</td>\n",
       "      <td>97.067000</td>\n",
       "      <td>97.351000</td>\n",
       "      <td>97.583000</td>\n",
       "      <td>97.191000</td>\n",
       "      <td>97.734000</td>\n",
       "      <td>97.030000</td>\n",
       "      <td>97.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.668000</td>\n",
       "      <td>96.125000</td>\n",
       "      <td>96.006000</td>\n",
       "      <td>95.377000</td>\n",
       "      <td>96.211000</td>\n",
       "      <td>96.705000</td>\n",
       "      <td>95.739000</td>\n",
       "      <td>96.684000</td>\n",
       "      <td>95.397000</td>\n",
       "      <td>96.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.638000</td>\n",
       "      <td>98.871000</td>\n",
       "      <td>98.690000</td>\n",
       "      <td>98.885000</td>\n",
       "      <td>98.553000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>98.746000</td>\n",
       "      <td>98.829000</td>\n",
       "      <td>98.790000</td>\n",
       "      <td>98.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>69.001000</td>\n",
       "      <td>68.970000</td>\n",
       "      <td>67.847778</td>\n",
       "      <td>62.895556</td>\n",
       "      <td>65.251111</td>\n",
       "      <td>61.713000</td>\n",
       "      <td>73.396250</td>\n",
       "      <td>71.902000</td>\n",
       "      <td>66.847500</td>\n",
       "      <td>71.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>95.778000</td>\n",
       "      <td>88.889000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>93.671000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>98.889000</td>\n",
       "      <td>75.139000</td>\n",
       "      <td>93.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>56.411000</td>\n",
       "      <td>50.684000</td>\n",
       "      <td>47.775000</td>\n",
       "      <td>45.663000</td>\n",
       "      <td>46.684000</td>\n",
       "      <td>51.800000</td>\n",
       "      <td>49.482000</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>44.093000</td>\n",
       "      <td>60.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>83.994000</td>\n",
       "      <td>83.077000</td>\n",
       "      <td>79.422000</td>\n",
       "      <td>82.670000</td>\n",
       "      <td>81.563000</td>\n",
       "      <td>85.207000</td>\n",
       "      <td>76.932000</td>\n",
       "      <td>84.372000</td>\n",
       "      <td>76.386000</td>\n",
       "      <td>83.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>86.985000</td>\n",
       "      <td>90.445000</td>\n",
       "      <td>87.469000</td>\n",
       "      <td>80.725000</td>\n",
       "      <td>86.897000</td>\n",
       "      <td>86.622000</td>\n",
       "      <td>85.265000</td>\n",
       "      <td>90.121000</td>\n",
       "      <td>87.569000</td>\n",
       "      <td>89.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>82.214000</td>\n",
       "      <td>78.533000</td>\n",
       "      <td>75.316000</td>\n",
       "      <td>70.218000</td>\n",
       "      <td>78.459000</td>\n",
       "      <td>84.726000</td>\n",
       "      <td>73.958000</td>\n",
       "      <td>81.153000</td>\n",
       "      <td>71.893000</td>\n",
       "      <td>81.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>59.363000</td>\n",
       "      <td>68.687143</td>\n",
       "      <td>66.807500</td>\n",
       "      <td>60.864286</td>\n",
       "      <td>62.154444</td>\n",
       "      <td>57.903333</td>\n",
       "      <td>57.072222</td>\n",
       "      <td>63.151000</td>\n",
       "      <td>58.682857</td>\n",
       "      <td>68.965556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>92.772000</td>\n",
       "      <td>57.731000</td>\n",
       "      <td>60.462000</td>\n",
       "      <td>57.737000</td>\n",
       "      <td>77.154000</td>\n",
       "      <td>81.488000</td>\n",
       "      <td>78.778000</td>\n",
       "      <td>86.228000</td>\n",
       "      <td>60.404000</td>\n",
       "      <td>77.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>48.200000</td>\n",
       "      <td>43.227000</td>\n",
       "      <td>50.524000</td>\n",
       "      <td>39.918000</td>\n",
       "      <td>49.007000</td>\n",
       "      <td>43.158000</td>\n",
       "      <td>41.412000</td>\n",
       "      <td>53.206000</td>\n",
       "      <td>36.433000</td>\n",
       "      <td>55.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>55.556667</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.335000</td>\n",
       "      <td>33.335000</td>\n",
       "      <td>58.335000</td>\n",
       "      <td>33.335000</td>\n",
       "      <td>55.556667</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0          0          0          0          0  \\\n",
       "F1-O     97.631000  97.465000  97.307000  97.067000  97.351000  97.583000   \n",
       "P-O      96.668000  96.125000  96.006000  95.377000  96.211000  96.705000   \n",
       "R-O      98.638000  98.871000  98.690000  98.885000  98.553000  98.500000   \n",
       "F1-MISC  69.001000  68.970000  67.847778  62.895556  65.251111  61.713000   \n",
       "P-MISC   95.778000  88.889000  90.000000  87.500000  87.500000  93.671000   \n",
       "R-MISC   56.411000  50.684000  47.775000  45.663000  46.684000  51.800000   \n",
       "F1-PER   83.994000  83.077000  79.422000  82.670000  81.563000  85.207000   \n",
       "P-PER    86.985000  90.445000  87.469000  80.725000  86.897000  86.622000   \n",
       "R-PER    82.214000  78.533000  75.316000  70.218000  78.459000  84.726000   \n",
       "F1-LOC   59.363000  68.687143  66.807500  60.864286  62.154444  57.903333   \n",
       "P-LOC    92.772000  57.731000  60.462000  57.737000  77.154000  81.488000   \n",
       "R-LOC    48.200000  43.227000  50.524000  39.918000  49.007000  43.158000   \n",
       "F1-ORG   55.556667  50.000000   0.000000  33.335000  33.335000  58.335000   \n",
       "P-ORG    15.000000  10.000000   0.000000   5.000000   5.000000  20.000000   \n",
       "R-ORG    20.000000  10.000000   0.000000  10.000000  10.000000  30.000000   \n",
       "\n",
       "                 0          0          0          0  \n",
       "F1-O     97.191000  97.734000  97.030000  97.706000  \n",
       "P-O      95.739000  96.684000  95.397000  96.820000  \n",
       "R-O      98.746000  98.829000  98.790000  98.638000  \n",
       "F1-MISC  73.396250  71.902000  66.847500  71.756000  \n",
       "P-MISC   77.500000  98.889000  75.139000  93.778000  \n",
       "R-MISC   49.482000  57.340000  44.093000  60.745000  \n",
       "F1-PER   76.932000  84.372000  76.386000  83.984000  \n",
       "P-PER    85.265000  90.121000  87.569000  89.144000  \n",
       "R-PER    73.958000  81.153000  71.893000  81.532000  \n",
       "F1-LOC   57.072222  63.151000  58.682857  68.965556  \n",
       "P-LOC    78.778000  86.228000  60.404000  77.813000  \n",
       "R-LOC    41.412000  53.206000  36.433000  55.427000  \n",
       "F1-ORG   33.335000  55.556667  50.000000  50.000000  \n",
       "P-ORG     5.000000  15.000000  10.000000  10.000000  \n",
       "R-ORG    10.000000  20.000000  10.000000  10.000000  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>67.958019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>88.864400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>51.067700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>81.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>87.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>77.800200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>62.365134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>73.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>46.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>41.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.406500\n",
       "P-O      96.173200\n",
       "R-O      98.714000\n",
       "F1-MISC  67.958019\n",
       "P-MISC   88.864400\n",
       "R-MISC   51.067700\n",
       "F1-PER   81.760700\n",
       "P-PER    87.124200\n",
       "R-PER    77.800200\n",
       "F1-LOC   62.365134\n",
       "P-LOC    73.056700\n",
       "R-LOC    46.051200\n",
       "F1-ORG   41.945333\n",
       "P-ORG     9.500000\n",
       "R-ORG    13.000000"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.257847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.544014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.132397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>3.871082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>7.587174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>5.504105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>3.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>2.771571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.794736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>4.430664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.882780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>6.150444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>17.687458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>5.986095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>8.232726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O      0.257847\n",
       "P-O       0.544014\n",
       "R-O       0.132397\n",
       "F1-MISC   3.871082\n",
       "P-MISC    7.587174\n",
       "R-MISC    5.504105\n",
       "F1-PER    3.142865\n",
       "P-PER     2.771571\n",
       "R-PER     4.794736\n",
       "F1-LOC    4.430664\n",
       "P-LOC    12.882780\n",
       "R-LOC     6.150444\n",
       "F1-ORG   17.687458\n",
       "P-ORG     5.986095\n",
       "R-ORG     8.232726"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.065000</td>\n",
       "      <td>97.067000</td>\n",
       "      <td>96.838</td>\n",
       "      <td>96.545000</td>\n",
       "      <td>97.050000</td>\n",
       "      <td>97.292</td>\n",
       "      <td>96.833000</td>\n",
       "      <td>96.913000</td>\n",
       "      <td>96.9630</td>\n",
       "      <td>97.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>95.891000</td>\n",
       "      <td>95.648000</td>\n",
       "      <td>95.246</td>\n",
       "      <td>94.435000</td>\n",
       "      <td>95.626000</td>\n",
       "      <td>96.306</td>\n",
       "      <td>95.257000</td>\n",
       "      <td>95.684000</td>\n",
       "      <td>95.2590</td>\n",
       "      <td>96.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.399000</td>\n",
       "      <td>98.649000</td>\n",
       "      <td>98.646</td>\n",
       "      <td>98.887000</td>\n",
       "      <td>98.630000</td>\n",
       "      <td>98.399</td>\n",
       "      <td>98.631000</td>\n",
       "      <td>98.261000</td>\n",
       "      <td>98.8840</td>\n",
       "      <td>98.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>52.381429</td>\n",
       "      <td>50.340000</td>\n",
       "      <td>50.340</td>\n",
       "      <td>39.048571</td>\n",
       "      <td>52.381429</td>\n",
       "      <td>50.340</td>\n",
       "      <td>36.508333</td>\n",
       "      <td>55.101429</td>\n",
       "      <td>44.4450</td>\n",
       "      <td>55.101429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>32.500</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>37.500</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>80.342222</td>\n",
       "      <td>80.508889</td>\n",
       "      <td>85.865</td>\n",
       "      <td>79.097500</td>\n",
       "      <td>78.561111</td>\n",
       "      <td>79.930</td>\n",
       "      <td>84.031250</td>\n",
       "      <td>75.415000</td>\n",
       "      <td>85.9725</td>\n",
       "      <td>78.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>79.667000</td>\n",
       "      <td>83.369000</td>\n",
       "      <td>70.528</td>\n",
       "      <td>75.071000</td>\n",
       "      <td>79.488000</td>\n",
       "      <td>82.674</td>\n",
       "      <td>67.766000</td>\n",
       "      <td>81.071000</td>\n",
       "      <td>72.8890</td>\n",
       "      <td>81.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>71.516000</td>\n",
       "      <td>68.536000</td>\n",
       "      <td>68.309</td>\n",
       "      <td>57.678000</td>\n",
       "      <td>67.753000</td>\n",
       "      <td>84.369</td>\n",
       "      <td>67.690000</td>\n",
       "      <td>76.857000</td>\n",
       "      <td>65.7460</td>\n",
       "      <td>82.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>55.556667</td>\n",
       "      <td>53.142000</td>\n",
       "      <td>63.095</td>\n",
       "      <td>53.142000</td>\n",
       "      <td>48.730000</td>\n",
       "      <td>58.730</td>\n",
       "      <td>51.111667</td>\n",
       "      <td>59.048571</td>\n",
       "      <td>49.3340</td>\n",
       "      <td>58.333750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>26.667000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>26.667000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>26.6670</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>22.500</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>32.500</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0       0          0          0       0  \\\n",
       "F1-O     97.065000  97.067000  96.838  96.545000  97.050000  97.292   \n",
       "P-O      95.891000  95.648000  95.246  94.435000  95.626000  96.306   \n",
       "R-O      98.399000  98.649000  98.646  98.887000  98.630000  98.399   \n",
       "F1-MISC  52.381429  50.340000  50.340  39.048571  52.381429  50.340   \n",
       "P-MISC   35.000000  35.000000  40.000  35.000000  40.000000  35.000   \n",
       "R-MISC   40.000000  37.500000  32.500  27.500000  35.000000  37.500   \n",
       "F1-PER   80.342222  80.508889  85.865  79.097500  78.561111  79.930   \n",
       "P-PER    79.667000  83.369000  70.528  75.071000  79.488000  82.674   \n",
       "R-PER    71.516000  68.536000  68.309  57.678000  67.753000  84.369   \n",
       "F1-LOC   55.556667  53.142000  63.095  53.142000  48.730000  58.730   \n",
       "P-LOC    40.000000  26.667000  30.000  26.667000  40.000000  40.000   \n",
       "R-LOC    30.000000  27.500000  22.500  27.500000  25.000000  32.500   \n",
       "F1-ORG    0.000000   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "P-ORG     0.000000   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "R-ORG     0.000000   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "\n",
       "                 0          0        0          0  \n",
       "F1-O     96.833000  96.913000  96.9630  97.165000  \n",
       "P-O      95.257000  95.684000  95.2590  96.324000  \n",
       "R-O      98.631000  98.261000  98.8840  98.144000  \n",
       "F1-MISC  36.508333  55.101429  44.4450  55.101429  \n",
       "P-MISC   25.000000  40.000000  25.0000  40.000000  \n",
       "R-MISC   22.500000  37.500000  30.0000  37.500000  \n",
       "F1-PER   84.031250  75.415000  85.9725  78.539000  \n",
       "P-PER    67.766000  81.071000  72.8890  81.662000  \n",
       "R-PER    67.690000  76.857000  65.7460  82.412000  \n",
       "F1-LOC   51.111667  59.048571  49.3340  58.333750  \n",
       "P-LOC    40.000000  46.667000  26.6670  50.000000  \n",
       "R-LOC    27.500000  40.000000  25.0000  47.500000  \n",
       "F1-ORG    0.000000   0.000000   0.0000   0.000000  \n",
       "P-ORG     0.000000   0.000000   0.0000   0.000000  \n",
       "R-ORG     0.000000   0.000000   0.0000   0.000000  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>96.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>95.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>48.598762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>33.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>80.826247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>77.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>71.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>55.022365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>36.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     96.973100\n",
       "P-O      95.567600\n",
       "R-O      98.553000\n",
       "F1-MISC  48.598762\n",
       "P-MISC   35.000000\n",
       "R-MISC   33.750000\n",
       "F1-PER   80.826247\n",
       "P-PER    77.418500\n",
       "R-PER    71.086600\n",
       "F1-LOC   55.022365\n",
       "P-LOC    36.666800\n",
       "R-LOC    30.500000\n",
       "F1-ORG    0.000000\n",
       "P-ORG     0.000000\n",
       "R-ORG     0.000000"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.207247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.560090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.247425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>6.471481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>5.773503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>5.559027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>3.430513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>5.481203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>8.050892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>4.722188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>8.606544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>7.710022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-O     0.207247\n",
       "P-O      0.560090\n",
       "R-O      0.247425\n",
       "F1-MISC  6.471481\n",
       "P-MISC   5.773503\n",
       "R-MISC   5.559027\n",
       "F1-PER   3.430513\n",
       "P-PER    5.481203\n",
       "R-PER    8.050892\n",
       "F1-LOC   4.722188\n",
       "P-LOC    8.606544\n",
       "R-LOC    7.710022\n",
       "F1-ORG   0.000000\n",
       "P-ORG    0.000000\n",
       "R-ORG    0.000000"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.1500</td>\n",
       "      <td>43.6825</td>\n",
       "      <td>43.682500</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150</td>\n",
       "      <td>43.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.43100</td>\n",
       "      <td>95.075000</td>\n",
       "      <td>94.737000</td>\n",
       "      <td>94.9000</td>\n",
       "      <td>94.9640</td>\n",
       "      <td>95.227000</td>\n",
       "      <td>94.91800</td>\n",
       "      <td>94.86800</td>\n",
       "      <td>95.157</td>\n",
       "      <td>95.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>8.57625</td>\n",
       "      <td>47.702857</td>\n",
       "      <td>28.391429</td>\n",
       "      <td>32.1575</td>\n",
       "      <td>34.5975</td>\n",
       "      <td>39.691111</td>\n",
       "      <td>34.62875</td>\n",
       "      <td>31.67875</td>\n",
       "      <td>42.050</td>\n",
       "      <td>41.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>70.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.54000</td>\n",
       "      <td>91.146000</td>\n",
       "      <td>90.138000</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>90.7090</td>\n",
       "      <td>91.122000</td>\n",
       "      <td>90.53800</td>\n",
       "      <td>90.38400</td>\n",
       "      <td>91.105</td>\n",
       "      <td>91.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>53.63800</td>\n",
       "      <td>51.554000</td>\n",
       "      <td>57.193000</td>\n",
       "      <td>63.3810</td>\n",
       "      <td>66.7380</td>\n",
       "      <td>77.824000</td>\n",
       "      <td>66.39100</td>\n",
       "      <td>68.14200</td>\n",
       "      <td>66.391</td>\n",
       "      <td>75.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.89000</td>\n",
       "      <td>99.379000</td>\n",
       "      <td>99.835000</td>\n",
       "      <td>99.7590</td>\n",
       "      <td>99.6610</td>\n",
       "      <td>99.725000</td>\n",
       "      <td>99.74800</td>\n",
       "      <td>99.82400</td>\n",
       "      <td>99.608</td>\n",
       "      <td>99.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>19.1250</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17.62500</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>24.375</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        0.1        0.2      0.3      0.4        0.5  \\\n",
       "F1-LOC        NaN        NaN        NaN      NaN      NaN  17.380000   \n",
       "F1-MISC  46.15000  46.150000  46.150000  46.1500  43.6825  43.682500   \n",
       "F1-O     94.43100  95.075000  94.737000  94.9000  94.9640  95.227000   \n",
       "F1-ORG        NaN        NaN        NaN      NaN      NaN        NaN   \n",
       "F1-PER    8.57625  47.702857  28.391429  32.1575  34.5975  39.691111   \n",
       "P-LOC     0.00000   0.000000   0.000000   0.0000   0.0000  60.000000   \n",
       "P-MISC   70.00000  60.000000  60.000000  70.0000  65.0000  65.000000   \n",
       "P-O      89.54000  91.146000  90.138000  90.5000  90.7090  91.122000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "P-PER    53.63800  51.554000  57.193000  63.3810  66.7380  77.824000   \n",
       "R-LOC     0.00000   0.000000   0.000000   0.0000   0.0000   5.712000   \n",
       "R-MISC   21.00000  18.000000  18.000000  21.0000  24.0000  24.000000   \n",
       "R-O      99.89000  99.379000  99.835000  99.7590  99.6610  99.725000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "R-PER     4.00000  25.000000  12.250000  16.7500  19.1250  23.500000   \n",
       "\n",
       "              0.6       0.7     0.8        0.9  \n",
       "F1-LOC        NaN       NaN     NaN  17.380000  \n",
       "F1-MISC  46.15000  46.15000  46.150  43.591111  \n",
       "F1-O     94.91800  94.86800  95.157  95.299000  \n",
       "F1-ORG        NaN       NaN     NaN        NaN  \n",
       "F1-PER   34.62875  31.67875  42.050  41.984444  \n",
       "P-LOC     0.00000   0.00000   0.000  60.000000  \n",
       "P-MISC   60.00000  60.00000  80.000  72.500000  \n",
       "P-O      90.53800  90.38400  91.105  91.426000  \n",
       "P-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "P-PER    66.39100  68.14200  66.391  75.073000  \n",
       "R-LOC     0.00000   0.00000   0.000   5.712000  \n",
       "R-MISC   18.00000  18.00000  24.000  27.000000  \n",
       "R-O      99.74800  99.82400  99.608  99.531000  \n",
       "R-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "R-PER    17.62500  15.75000  24.375  26.875000  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>34.145859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>90.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>64.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>1.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>18.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   17.380000\n",
       "F1-MISC  45.400611\n",
       "F1-O     94.957600\n",
       "F1-ORG         NaN\n",
       "F1-PER   34.145859\n",
       "P-LOC    12.000000\n",
       "P-MISC   66.250000\n",
       "P-O      90.660800\n",
       "P-ORG     0.000000\n",
       "P-PER    64.632500\n",
       "R-LOC     1.142400\n",
       "R-MISC   21.300000\n",
       "R-O      99.696000\n",
       "R-ORG     0.000000\n",
       "R-PER    18.525000"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.206887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>10.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>25.298221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.795628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.565721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>8.529639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.301515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.155470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>6.936167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    0.000000\n",
       "F1-MISC   1.206887\n",
       "F1-O      0.254209\n",
       "F1-ORG         NaN\n",
       "F1-PER   10.728242\n",
       "P-LOC    25.298221\n",
       "P-MISC    6.795628\n",
       "P-O       0.565721\n",
       "P-ORG     0.000000\n",
       "P-PER     8.529639\n",
       "R-LOC     2.408391\n",
       "R-MISC    3.301515\n",
       "R-O       0.155470\n",
       "R-ORG     0.000000\n",
       "R-PER     6.936167"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-371-4a85ba04e569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_fingerprints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreal_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ne-tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                              'argument.')\n\u001b[1;32m   1151\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
