{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 50\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab\n",
    "h1_size = 640\n",
    "h2_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                if l[0] not in string.punctuation:\n",
    "                    dataset[\"word\"].append(l[0])\n",
    "                    dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4170</td>\n",
       "      <td>4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3779</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ne-tag  word\n",
       "count    4170  4379\n",
       "unique      5   904\n",
       "top         O   the\n",
       "freq     3779   313"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>Promise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Holy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Spirit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O</td>\n",
       "      <td>In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ne-tag     word\n",
       "0      O      The\n",
       "1      O  Promise\n",
       "2      O       of\n",
       "3      O      the\n",
       "4   MISC     Holy\n",
       "5   MISC   Spirit\n",
       "6   None       \\n\n",
       "7      O       In\n",
       "8      O      the\n",
       "9      O    first"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.3 %\n",
      "MISC % = 2.4 %\n",
      "PER % = 5.59 %\n",
      "LOC % = 0.91 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.16 %\n",
      "MISC % = 1.88 %\n",
      "PER % = 8.96 %\n",
      "LOC % = 1.99 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'And</th>\n",
       "      <th>'Let</th>\n",
       "      <th>'May</th>\n",
       "      <th>'The</th>\n",
       "      <th>'Why</th>\n",
       "      <th>(Now</th>\n",
       "      <th>(the</th>\n",
       "      <th>(which</th>\n",
       "      <th>120)</th>\n",
       "      <th>Aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>would</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrote</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'And  'Let  'May  'The  'Why  (Now  (the  (which  120)  Aaron  ...   word  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   0.0    0.0  ...    0.0   \n",
       "\n",
       "   words  would  write  writing  written  wrote  years     you  your  \n",
       "0    0.0    0.0    0.0      0.0      0.0    0.0    0.0     0.0   0.0  \n",
       "1    0.0    0.0    0.0      0.0      0.0    0.0    0.0     0.0   0.0  \n",
       "2    0.0    0.0    0.0      0.0      0.0    0.0    0.0     0.0   0.0  \n",
       "3    0.0    0.0    0.0      0.0      0.0    0.0    0.0     0.0   0.0  \n",
       "4    0.0    0.0    0.0      0.0      0.0    0.0    0.0  4170.0   0.0  \n",
       "5    0.0    0.0    0.0      0.0      0.0    0.0    0.0  4170.0   0.0  \n",
       "6    0.0    0.0    0.0      0.0      0.0    0.0    0.0     0.0   0.0  \n",
       "7    0.0    0.0    0.0      0.0      0.0    0.0    0.0  4170.0   0.0  \n",
       "8    0.0    0.0    0.0      0.0      0.0    0.0    0.0  4170.0   0.0  \n",
       "9    0.0    0.0    0.0      0.0      0.0    0.0    0.0  1390.0   0.0  \n",
       "\n",
       "[10 rows x 903 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "count    903\n",
       "unique   903\n",
       "top     fear\n",
       "freq       1"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (210, 903) (903,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "883       Eliud\n",
       "884     Eleazar\n",
       "885     Matthan\n",
       "886     husband\n",
       "887    fourteen\n",
       "888   unwilling\n",
       "889       shame\n",
       "890    resolved\n",
       "891     divorce\n",
       "892     quietly\n",
       "893  considered\n",
       "894       dream\n",
       "895         She\n",
       "896        save\n",
       "897     fulfill\n",
       "898    Immanuel\n",
       "899         us)\n",
       "900        woke\n",
       "901       sleep\n",
       "902        knew"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903, 210) (903,)\n",
      "(903, 210) (903,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 5)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (605, 210)\n",
      "y_train.shape = (605, 5)\n",
      "X_val.shape = (298, 210)\n",
      "y_val.shape = (298, 5)\n",
      "O % in training data = 88.76 %\n",
      "O % in validation data = 87.25 %\n",
      "MISC % in training data = 1.32 %\n",
      "MISC % in validation data = 1.01 %\n",
      "PER % in training data = 7.77 %\n",
      "PER % in validation data = 10.07 %\n",
      "LOC % in training data = 2.15 %\n",
      "LOC % in validation data = 1.34 %\n",
      "ORG % in training data = 0.0 %\n",
      "ORG % in validation data = 0.34 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=2, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 84.15 %\n",
      "MISC % = 2.54 %\n",
      "PER % = 6.69 %\n",
      "LOC % = 1.03 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.94 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.3 %\n",
      "LOC % = 1.86 %\n",
      "ORG % = 0.2 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3570</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>O</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3180</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ne-tag  word\n",
       "count    3570  3779\n",
       "unique      5  1024\n",
       "top         O    \\n\n",
       "freq     3180   209"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Mfufub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Nsisim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>ayi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>sÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ne-tag    word\n",
       "0   MISC  Mfufub\n",
       "1   MISC  Nsisim\n",
       "2      O     ayi\n",
       "3      O      sÃ²\n",
       "4   None      \\n"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>obÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>yasÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>oyolÃ«ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>bÃ«yole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>AvÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>angavÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>oyÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>anganÃ²á¹…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1003        nlo\n",
       "1004        obÃ«\n",
       "1005      mbara\n",
       "1006    yabyali\n",
       "1007      dzili\n",
       "1008       yasÃ²\n",
       "1009    oyolÃ«ge\n",
       "1010       kode\n",
       "1011       dili\n",
       "1012     atoban\n",
       "1013        sik\n",
       "1014       Ntud\n",
       "1015     bÃ«yole\n",
       "1016   Emmanuel\n",
       "1017      AvÃ«bÃ«\n",
       "1018   angavÃ«bÃ«\n",
       "1019        oyÃ²\n",
       "1020  angabende\n",
       "1021    anganÃ²á¹…\n",
       "1022   angayole"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 210) (1023,)\n",
      "(1023, 210) (1023,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023,) 1023\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 210)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.54100, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.54100 to 0.43521, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.43521 to 0.40635, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss improved from 0.40635 to 0.38309, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss improved from 0.38309 to 0.36380, saving model to best-model-conll.hdfs\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00007: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.17841, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.06947, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.06947 to 0.05492, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.06675, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.06675 to 0.03767, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11771, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.11771 to 0.06046, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss improved from 0.06046 to 0.04429, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.08257, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10555, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12805, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.07781, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.07781 to 0.06030, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.14074, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.14074 to 0.13829, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.53545, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.53545 to 0.44786, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.44786 to 0.38386, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss improved from 0.38386 to 0.37630, saving model to best-model-conll.hdfs\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00007: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.22283, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04831, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.04831 to 0.04592, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04721, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.02624, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12929, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.12929 to 0.09867, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10352, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.13134, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10233, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12015, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.55166, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.55166 to 0.52626, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.52626 to 0.49683, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss improved from 0.49683 to 0.40753, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss improved from 0.40753 to 0.37962, saving model to best-model-conll.hdfs\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss improved from 0.37962 to 0.36954, saving model to best-model-conll.hdfs\n",
      "Epoch 00008: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00009: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.18834, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04713, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.03942, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.03275, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11846, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.11846 to 0.09855, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.07916, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12049, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11100, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.11100 to 0.06894, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.14237, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.14237 to 0.12976, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.51066, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.51066 to 0.46903, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.46903 to 0.39978, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.25345, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.06227, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.06371, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.06371 to 0.04100, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04440, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.09857, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10297, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12150, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.14714, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.14714 to 0.13757, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.13757 to 0.06437, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12804, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.50574, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.50574 to 0.50202, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.50202 to 0.42652, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss improved from 0.42652 to 0.37283, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00006: val_loss improved from 0.37283 to 0.35682, saving model to best-model-conll.hdfs\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00008: val_loss improved from 0.35682 to 0.33932, saving model to best-model-conll.hdfs\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 00010: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.17822, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05304, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.05304 to 0.05189, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.03961, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.03961 to 0.03388, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04150, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.04150 to 0.04134, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.04134 to 0.02986, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10098, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.08634, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10322, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.08226, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.08226 to 0.05886, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10928, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.10928 to 0.10852, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.54843, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.54843 to 0.49642, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss improved from 0.49642 to 0.37467, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.21819, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.07959, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.07959 to 0.06021, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04500, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.04500 to 0.03912, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05869, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.05869 to 0.05082, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.05082 to 0.05071, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss improved from 0.05071 to 0.04473, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss improved from 0.04473 to 0.03987, saving model to best-model-conll.hdfs\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00007: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.09105, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.09105 to 0.08973, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.08720, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.13339, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.07001, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.14034, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.14034 to 0.12926, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.60053, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.60053 to 0.47808, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss improved from 0.47808 to 0.39464, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss improved from 0.39464 to 0.38735, saving model to best-model-conll.hdfs\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss improved from 0.38735 to 0.38326, saving model to best-model-conll.hdfs\n",
      "Epoch 00008: val_loss improved from 0.38326 to 0.36962, saving model to best-model-conll.hdfs\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 00010: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.16904, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.07320, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.07320 to 0.05184, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.05184 to 0.04469, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04049, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05353, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.14173, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.14173 to 0.09840, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.09600, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11771, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11548, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.11548 to 0.05133, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.16716, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.16716 to 0.16697, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.16697 to 0.13571, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "AlgoCrossValIter - 8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.53078, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.53078 to 0.47619, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.47619 to 0.42615, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.26732, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05644, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05389, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.05389 to 0.04860, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss improved from 0.04860 to 0.04218, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10312, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.10312 to 0.05153, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.05153 to 0.04005, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.07946, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.09250, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12855, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11019, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.10149, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.58269, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.58269 to 0.44077, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss improved from 0.44077 to 0.43802, saving model to best-model-conll.hdfs\n",
      "Epoch 00005: val_loss improved from 0.43802 to 0.37351, saving model to best-model-conll.hdfs\n",
      "Epoch 00006: val_loss improved from 0.37351 to 0.36477, saving model to best-model-conll.hdfs\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 00008: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.18275, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05060, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04066, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.03941, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.03941 to 0.03189, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.12577, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.12577 to 0.11594, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.18488, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.18488 to 0.11188, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11452, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.08082, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.08082 to 0.07354, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.16908, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.16908 to 0.13590, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 00001: val_loss improved from inf to 0.55419, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.55419 to 0.45841, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.45841 to 0.40709, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.26255, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.26255 to 0.25618, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.06010, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss improved from 0.06010 to 0.05937, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.05778, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.04652, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.04652 to 0.03045, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.08720, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.09232, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.11173, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.14374, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss improved from 0.14374 to 0.14251, saving model to best-model-conll.hdfs\n",
      "Epoch 00003: val_loss improved from 0.14251 to 0.08993, saving model to best-model-conll.hdfs\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "Epoch 00001: val_loss improved from inf to 0.09090, saving model to best-model-conll.hdfs\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>70.931</td>\n",
       "      <td>68.972</td>\n",
       "      <td>71.205</td>\n",
       "      <td>65.211</td>\n",
       "      <td>71.920</td>\n",
       "      <td>69.447</td>\n",
       "      <td>69.533</td>\n",
       "      <td>69.780</td>\n",
       "      <td>70.942</td>\n",
       "      <td>68.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>78.094</td>\n",
       "      <td>80.950</td>\n",
       "      <td>82.098</td>\n",
       "      <td>77.588</td>\n",
       "      <td>82.185</td>\n",
       "      <td>77.646</td>\n",
       "      <td>81.185</td>\n",
       "      <td>81.531</td>\n",
       "      <td>80.715</td>\n",
       "      <td>77.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>83.808</td>\n",
       "      <td>83.480</td>\n",
       "      <td>85.419</td>\n",
       "      <td>78.398</td>\n",
       "      <td>86.461</td>\n",
       "      <td>83.548</td>\n",
       "      <td>84.376</td>\n",
       "      <td>81.526</td>\n",
       "      <td>84.897</td>\n",
       "      <td>81.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>81.039</td>\n",
       "      <td>78.039</td>\n",
       "      <td>76.718</td>\n",
       "      <td>83.650</td>\n",
       "      <td>80.761</td>\n",
       "      <td>79.206</td>\n",
       "      <td>78.462</td>\n",
       "      <td>79.611</td>\n",
       "      <td>78.228</td>\n",
       "      <td>77.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>85.411</td>\n",
       "      <td>87.977</td>\n",
       "      <td>84.065</td>\n",
       "      <td>90.253</td>\n",
       "      <td>85.809</td>\n",
       "      <td>82.646</td>\n",
       "      <td>83.042</td>\n",
       "      <td>87.224</td>\n",
       "      <td>83.313</td>\n",
       "      <td>87.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>89.314</td>\n",
       "      <td>87.979</td>\n",
       "      <td>87.343</td>\n",
       "      <td>90.533</td>\n",
       "      <td>89.546</td>\n",
       "      <td>89.607</td>\n",
       "      <td>88.857</td>\n",
       "      <td>87.167</td>\n",
       "      <td>87.777</td>\n",
       "      <td>87.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>64.630</td>\n",
       "      <td>63.334</td>\n",
       "      <td>67.223</td>\n",
       "      <td>55.370</td>\n",
       "      <td>65.093</td>\n",
       "      <td>63.056</td>\n",
       "      <td>63.981</td>\n",
       "      <td>63.889</td>\n",
       "      <td>66.205</td>\n",
       "      <td>62.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>76.921</td>\n",
       "      <td>78.993</td>\n",
       "      <td>83.800</td>\n",
       "      <td>71.120</td>\n",
       "      <td>81.843</td>\n",
       "      <td>77.070</td>\n",
       "      <td>80.588</td>\n",
       "      <td>80.948</td>\n",
       "      <td>80.301</td>\n",
       "      <td>74.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>80.183</td>\n",
       "      <td>80.546</td>\n",
       "      <td>84.010</td>\n",
       "      <td>71.184</td>\n",
       "      <td>83.789</td>\n",
       "      <td>79.025</td>\n",
       "      <td>81.784</td>\n",
       "      <td>78.041</td>\n",
       "      <td>82.941</td>\n",
       "      <td>78.946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       0       0       0       0       0       0       0  \\\n",
       "F1-ewo    70.931  68.972  71.205  65.211  71.920  69.447  69.533  69.780   \n",
       "F1-test   78.094  80.950  82.098  77.588  82.185  77.646  81.185  81.531   \n",
       "F1-train  83.808  83.480  85.419  78.398  86.461  83.548  84.376  81.526   \n",
       "P_ewo     81.039  78.039  76.718  83.650  80.761  79.206  78.462  79.611   \n",
       "P_test    85.411  87.977  84.065  90.253  85.809  82.646  83.042  87.224   \n",
       "P_train   89.314  87.979  87.343  90.533  89.546  89.607  88.857  87.167   \n",
       "R_ewo     64.630  63.334  67.223  55.370  65.093  63.056  63.981  63.889   \n",
       "R_test    76.921  78.993  83.800  71.120  81.843  77.070  80.588  80.948   \n",
       "R_train   80.183  80.546  84.010  71.184  83.789  79.025  81.784  78.041   \n",
       "\n",
       "               0       0  \n",
       "F1-ewo    70.942  68.314  \n",
       "F1-test   80.715  77.030  \n",
       "F1-train  84.897  81.605  \n",
       "P_ewo     78.228  77.845  \n",
       "P_test    83.313  87.324  \n",
       "P_train   87.777  87.421  \n",
       "R_ewo     66.205  62.872  \n",
       "R_test    80.301  74.889  \n",
       "R_train   82.941  78.946  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>69.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>79.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>83.3518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>79.3559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>85.7064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>88.5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>63.5653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>78.6473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>80.0449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-ewo    69.6255\n",
       "F1-test   79.9022\n",
       "F1-train  83.3518\n",
       "P_ewo     79.3559\n",
       "P_test    85.7064\n",
       "P_train   88.5544\n",
       "R_ewo     63.5653\n",
       "R_test    78.6473\n",
       "R_train   80.0449"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>1.911842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>2.056288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>2.322956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>2.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>2.488470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>1.168430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>3.198061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>3.725731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>3.744645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-ewo    1.911842\n",
       "F1-test   2.056288\n",
       "F1-train  2.322956\n",
       "P_ewo     2.010549\n",
       "P_test    2.488470\n",
       "P_train   1.168430\n",
       "R_ewo     3.198061\n",
       "R_test    3.725731\n",
       "R_train   3.744645"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>70.725556</td>\n",
       "      <td>73.768889</td>\n",
       "      <td>74.913</td>\n",
       "      <td>67.653333</td>\n",
       "      <td>78.771</td>\n",
       "      <td>70.567000</td>\n",
       "      <td>74.488000</td>\n",
       "      <td>72.430000</td>\n",
       "      <td>70.292</td>\n",
       "      <td>74.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>76.858000</td>\n",
       "      <td>72.330000</td>\n",
       "      <td>76.801</td>\n",
       "      <td>70.236000</td>\n",
       "      <td>74.949</td>\n",
       "      <td>71.784000</td>\n",
       "      <td>78.661000</td>\n",
       "      <td>71.054444</td>\n",
       "      <td>76.148</td>\n",
       "      <td>72.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>98.029000</td>\n",
       "      <td>97.968000</td>\n",
       "      <td>98.147</td>\n",
       "      <td>97.616000</td>\n",
       "      <td>98.263</td>\n",
       "      <td>97.996000</td>\n",
       "      <td>98.052000</td>\n",
       "      <td>97.819000</td>\n",
       "      <td>98.077</td>\n",
       "      <td>97.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>60.002</td>\n",
       "      <td>33.335000</td>\n",
       "      <td>58.335</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>50.002500</td>\n",
       "      <td>33.335</td>\n",
       "      <td>44.446667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>88.074000</td>\n",
       "      <td>87.653000</td>\n",
       "      <td>88.880</td>\n",
       "      <td>82.577000</td>\n",
       "      <td>89.608</td>\n",
       "      <td>87.493000</td>\n",
       "      <td>87.302000</td>\n",
       "      <td>86.277000</td>\n",
       "      <td>88.562</td>\n",
       "      <td>85.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>80.088000</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>79.379</td>\n",
       "      <td>79.950000</td>\n",
       "      <td>89.923</td>\n",
       "      <td>88.647000</td>\n",
       "      <td>84.809000</td>\n",
       "      <td>71.883000</td>\n",
       "      <td>84.856</td>\n",
       "      <td>73.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>93.460000</td>\n",
       "      <td>93.639000</td>\n",
       "      <td>98.889</td>\n",
       "      <td>94.750000</td>\n",
       "      <td>98.889</td>\n",
       "      <td>96.528000</td>\n",
       "      <td>94.960000</td>\n",
       "      <td>87.639000</td>\n",
       "      <td>96.528</td>\n",
       "      <td>95.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.456000</td>\n",
       "      <td>97.515000</td>\n",
       "      <td>97.917</td>\n",
       "      <td>96.359000</td>\n",
       "      <td>97.861</td>\n",
       "      <td>97.274000</td>\n",
       "      <td>97.639000</td>\n",
       "      <td>97.215000</td>\n",
       "      <td>97.759</td>\n",
       "      <td>97.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>89.658000</td>\n",
       "      <td>87.908000</td>\n",
       "      <td>88.384</td>\n",
       "      <td>90.948000</td>\n",
       "      <td>89.066</td>\n",
       "      <td>89.668000</td>\n",
       "      <td>89.617000</td>\n",
       "      <td>88.798000</td>\n",
       "      <td>87.946</td>\n",
       "      <td>88.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>60.122000</td>\n",
       "      <td>60.497000</td>\n",
       "      <td>73.502</td>\n",
       "      <td>53.252000</td>\n",
       "      <td>71.656</td>\n",
       "      <td>62.813000</td>\n",
       "      <td>72.013000</td>\n",
       "      <td>65.357000</td>\n",
       "      <td>66.581</td>\n",
       "      <td>67.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>67.648000</td>\n",
       "      <td>62.001000</td>\n",
       "      <td>63.537</td>\n",
       "      <td>59.072000</td>\n",
       "      <td>61.335</td>\n",
       "      <td>59.890000</td>\n",
       "      <td>67.871000</td>\n",
       "      <td>51.940000</td>\n",
       "      <td>64.335</td>\n",
       "      <td>61.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.634000</td>\n",
       "      <td>98.452000</td>\n",
       "      <td>98.385</td>\n",
       "      <td>98.941000</td>\n",
       "      <td>98.674</td>\n",
       "      <td>98.745000</td>\n",
       "      <td>98.496000</td>\n",
       "      <td>98.455000</td>\n",
       "      <td>98.411</td>\n",
       "      <td>98.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>87.297000</td>\n",
       "      <td>88.152000</td>\n",
       "      <td>89.664</td>\n",
       "      <td>77.617000</td>\n",
       "      <td>90.372</td>\n",
       "      <td>85.997000</td>\n",
       "      <td>86.643000</td>\n",
       "      <td>85.039000</td>\n",
       "      <td>89.960</td>\n",
       "      <td>84.814000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0       0          0       0          0  \\\n",
       "F1-LOC   70.725556  73.768889  74.913  67.653333  78.771  70.567000   \n",
       "F1-MISC  76.858000  72.330000  76.801  70.236000  74.949  71.784000   \n",
       "F1-O     98.029000  97.968000  98.147  97.616000  98.263  97.996000   \n",
       "F1-ORG         NaN  44.446667  60.002  33.335000  58.335  44.446667   \n",
       "F1-PER   88.074000  87.653000  88.880  82.577000  89.608  87.493000   \n",
       "P-LOC    80.088000  80.750000  79.379  79.950000  89.923  88.647000   \n",
       "P-MISC   93.460000  93.639000  98.889  94.750000  98.889  96.528000   \n",
       "P-O      97.456000  97.515000  97.917  96.359000  97.861  97.274000   \n",
       "P-ORG     0.000000  10.000000  25.000   5.000000  20.000  10.000000   \n",
       "P-PER    89.658000  87.908000  88.384  90.948000  89.066  89.668000   \n",
       "R-LOC    60.122000  60.497000  73.502  53.252000  71.656  62.813000   \n",
       "R-MISC   67.648000  62.001000  63.537  59.072000  61.335  59.890000   \n",
       "R-O      98.634000  98.452000  98.385  98.941000  98.674  98.745000   \n",
       "R-ORG     0.000000  20.000000  40.000  10.000000  30.000  20.000000   \n",
       "R-PER    87.297000  88.152000  89.664  77.617000  90.372  85.997000   \n",
       "\n",
       "                 0          0       0          0  \n",
       "F1-LOC   74.488000  72.430000  70.292  74.930000  \n",
       "F1-MISC  78.661000  71.054444  76.148  72.724000  \n",
       "F1-O     98.052000  97.819000  98.077  97.870000  \n",
       "F1-ORG   44.446667  50.002500  33.335  44.446667  \n",
       "F1-PER   87.302000  86.277000  88.562  85.624000  \n",
       "P-LOC    84.809000  71.883000  84.856  73.073000  \n",
       "P-MISC   94.960000  87.639000  96.528  95.051000  \n",
       "P-O      97.639000  97.215000  97.759  97.329000  \n",
       "P-ORG    10.000000  15.000000   5.000  10.000000  \n",
       "P-PER    89.617000  88.798000  87.946  88.655000  \n",
       "R-LOC    72.013000  65.357000  66.581  67.165000  \n",
       "R-MISC   67.871000  51.940000  64.335  61.112000  \n",
       "R-O      98.496000  98.455000  98.411  98.453000  \n",
       "R-ORG    20.000000  30.000000  10.000  20.000000  \n",
       "R-PER    86.643000  85.039000  89.960  84.814000  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>72.853878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>74.154544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.983700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>45.866241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>87.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>81.335800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>95.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>89.064800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>65.295800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>61.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.564600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>86.555500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   72.853878\n",
       "F1-MISC  74.154544\n",
       "F1-O     97.983700\n",
       "F1-ORG   45.866241\n",
       "F1-PER   87.205000\n",
       "P-LOC    81.335800\n",
       "P-MISC   95.033300\n",
       "P-O      97.432400\n",
       "P-ORG    11.000000\n",
       "P-PER    89.064800\n",
       "R-LOC    65.295800\n",
       "R-MISC   61.874100\n",
       "R-O      98.564600\n",
       "R-ORG    20.000000\n",
       "R-PER    86.555500"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>3.173122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>2.890330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.181277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>9.317477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>2.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>5.934153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>3.221147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.448516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>7.378648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.934500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>6.316452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>4.588443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.179105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>11.547005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>3.718821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    3.173122\n",
       "F1-MISC   2.890330\n",
       "F1-O      0.181277\n",
       "F1-ORG    9.317477\n",
       "F1-PER    2.006900\n",
       "P-LOC     5.934153\n",
       "P-MISC    3.221147\n",
       "P-O       0.448516\n",
       "P-ORG     7.378648\n",
       "P-PER     0.934500\n",
       "R-LOC     6.316452\n",
       "R-MISC    4.588443\n",
       "R-O       0.179105\n",
       "R-ORG    11.547005\n",
       "R-PER     3.718821"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>86.111667</td>\n",
       "      <td>84.285714</td>\n",
       "      <td>81.852222</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>91.6675</td>\n",
       "      <td>74.445</td>\n",
       "      <td>82.976250</td>\n",
       "      <td>85.238571</td>\n",
       "      <td>80.83375</td>\n",
       "      <td>86.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.833750</td>\n",
       "      <td>54.167500</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>54.167500</td>\n",
       "      <td>56.2500</td>\n",
       "      <td>50.000</td>\n",
       "      <td>51.852222</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>56.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.299000</td>\n",
       "      <td>97.621000</td>\n",
       "      <td>97.519000</td>\n",
       "      <td>97.511000</td>\n",
       "      <td>97.6670</td>\n",
       "      <td>97.163</td>\n",
       "      <td>97.590000</td>\n",
       "      <td>97.603000</td>\n",
       "      <td>97.40500</td>\n",
       "      <td>97.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>84.768000</td>\n",
       "      <td>87.511000</td>\n",
       "      <td>87.407000</td>\n",
       "      <td>83.176000</td>\n",
       "      <td>86.3090</td>\n",
       "      <td>84.212</td>\n",
       "      <td>85.673000</td>\n",
       "      <td>88.415000</td>\n",
       "      <td>86.10300</td>\n",
       "      <td>82.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>56.667000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>83.334000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>76.6670</td>\n",
       "      <td>51.667</td>\n",
       "      <td>68.334000</td>\n",
       "      <td>63.334000</td>\n",
       "      <td>71.66700</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>33.333000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.333000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>38.333</td>\n",
       "      <td>48.333000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.33300</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.730000</td>\n",
       "      <td>96.844000</td>\n",
       "      <td>97.526000</td>\n",
       "      <td>96.124000</td>\n",
       "      <td>97.2890</td>\n",
       "      <td>96.831</td>\n",
       "      <td>97.378000</td>\n",
       "      <td>97.196000</td>\n",
       "      <td>97.14500</td>\n",
       "      <td>96.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>88.317000</td>\n",
       "      <td>89.845000</td>\n",
       "      <td>86.717000</td>\n",
       "      <td>90.333000</td>\n",
       "      <td>87.1460</td>\n",
       "      <td>84.820</td>\n",
       "      <td>86.241000</td>\n",
       "      <td>90.480000</td>\n",
       "      <td>86.16700</td>\n",
       "      <td>89.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.666000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>36.666000</td>\n",
       "      <td>71.6670</td>\n",
       "      <td>42.500</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>62.50000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>97.972000</td>\n",
       "      <td>98.495000</td>\n",
       "      <td>97.584000</td>\n",
       "      <td>98.998000</td>\n",
       "      <td>98.1030</td>\n",
       "      <td>97.587</td>\n",
       "      <td>97.842000</td>\n",
       "      <td>98.101000</td>\n",
       "      <td>97.71300</td>\n",
       "      <td>98.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>83.830000</td>\n",
       "      <td>87.005000</td>\n",
       "      <td>90.020000</td>\n",
       "      <td>79.687000</td>\n",
       "      <td>87.1630</td>\n",
       "      <td>85.480</td>\n",
       "      <td>86.227000</td>\n",
       "      <td>88.020000</td>\n",
       "      <td>87.02000</td>\n",
       "      <td>80.718000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0          0          0        0       0  \\\n",
       "F1-LOC   86.111667  84.285714  81.852222  66.666667  91.6675  74.445   \n",
       "F1-MISC  45.833750  54.167500  50.000000  54.167500  56.2500  50.000   \n",
       "F1-O     97.299000  97.621000  97.519000  97.511000  97.6670  97.163   \n",
       "F1-ORG   10.000000   0.000000   0.000000   0.000000   0.0000   0.000   \n",
       "F1-PER   84.768000  87.511000  87.407000  83.176000  86.3090  84.212   \n",
       "P-LOC    56.667000  65.000000  83.334000  50.000000  76.6670  51.667   \n",
       "P-MISC   33.333000  45.000000  38.333000  45.000000  45.0000  38.333   \n",
       "P-O      96.730000  96.844000  97.526000  96.124000  97.2890  96.831   \n",
       "P-ORG    10.000000   0.000000   0.000000   0.000000   0.0000   0.000   \n",
       "P-PER    88.317000  89.845000  86.717000  90.333000  87.1460  84.820   \n",
       "R-LOC    50.000000  56.666000  72.500000  36.666000  71.6670  42.500   \n",
       "R-MISC   45.000000  45.000000  45.000000  45.000000  45.0000  45.000   \n",
       "R-O      97.972000  98.495000  97.584000  98.998000  98.1030  97.587   \n",
       "R-ORG    10.000000   0.000000   0.000000   0.000000   0.0000   0.000   \n",
       "R-PER    83.830000  87.005000  90.020000  79.687000  87.1630  85.480   \n",
       "\n",
       "                 0          0         0          0  \n",
       "F1-LOC   82.976250  85.238571  80.83375  86.666667  \n",
       "F1-MISC  51.852222  56.250000  50.00000  56.250000  \n",
       "F1-O     97.590000  97.603000  97.40500  97.390000  \n",
       "F1-ORG    0.000000   0.000000   0.00000   0.000000  \n",
       "F1-PER   85.673000  88.415000  86.10300  82.336000  \n",
       "P-LOC    68.334000  63.334000  71.66700  55.000000  \n",
       "P-MISC   48.333000  45.000000  38.33300  45.000000  \n",
       "P-O      97.378000  97.196000  97.14500  96.418000  \n",
       "P-ORG     0.000000   0.000000   0.00000   0.000000  \n",
       "P-PER    86.241000  90.480000  86.16700  89.230000  \n",
       "R-LOC    65.000000  60.000000  62.50000  50.000000  \n",
       "R-MISC   50.000000  45.000000  45.00000  45.000000  \n",
       "R-O      97.842000  98.101000  97.71300  98.488000  \n",
       "R-ORG     0.000000   0.000000   0.00000   0.000000  \n",
       "R-PER    86.227000  88.020000  87.02000  80.718000  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>82.074401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>52.477097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.476800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>85.591000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>64.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>42.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>87.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>56.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>45.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>85.517000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   82.074401\n",
       "F1-MISC  52.477097\n",
       "F1-O     97.476800\n",
       "F1-ORG    1.000000\n",
       "F1-PER   85.591000\n",
       "P-LOC    64.167000\n",
       "P-MISC   42.166500\n",
       "P-O      96.948100\n",
       "P-ORG     1.000000\n",
       "P-PER    87.929600\n",
       "R-LOC    56.749900\n",
       "R-MISC   45.500000\n",
       "R-O      98.088300\n",
       "R-ORG     1.000000\n",
       "R-PER    85.517000"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>7.010514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>3.517447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.160358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>1.964967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>11.034609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>4.717429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.443156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>1.986144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>11.924897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.456284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>3.233423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    7.010514\n",
       "F1-MISC   3.517447\n",
       "F1-O      0.160358\n",
       "F1-ORG    3.162278\n",
       "F1-PER    1.964967\n",
       "P-LOC    11.034609\n",
       "P-MISC    4.717429\n",
       "P-O       0.443156\n",
       "P-ORG     3.162278\n",
       "P-PER     1.986144\n",
       "R-LOC    11.924897\n",
       "R-MISC    1.581139\n",
       "R-O       0.456284\n",
       "R-ORG     3.162278\n",
       "R-PER     3.233423"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.1500</td>\n",
       "      <td>43.6825</td>\n",
       "      <td>43.682500</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150</td>\n",
       "      <td>43.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.43100</td>\n",
       "      <td>95.075000</td>\n",
       "      <td>94.737000</td>\n",
       "      <td>94.9000</td>\n",
       "      <td>94.9640</td>\n",
       "      <td>95.227000</td>\n",
       "      <td>94.91800</td>\n",
       "      <td>94.86800</td>\n",
       "      <td>95.157</td>\n",
       "      <td>95.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>8.57625</td>\n",
       "      <td>47.702857</td>\n",
       "      <td>28.391429</td>\n",
       "      <td>32.1575</td>\n",
       "      <td>34.5975</td>\n",
       "      <td>39.691111</td>\n",
       "      <td>34.62875</td>\n",
       "      <td>31.67875</td>\n",
       "      <td>42.050</td>\n",
       "      <td>41.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>70.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.54000</td>\n",
       "      <td>91.146000</td>\n",
       "      <td>90.138000</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>90.7090</td>\n",
       "      <td>91.122000</td>\n",
       "      <td>90.53800</td>\n",
       "      <td>90.38400</td>\n",
       "      <td>91.105</td>\n",
       "      <td>91.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>53.63800</td>\n",
       "      <td>51.554000</td>\n",
       "      <td>57.193000</td>\n",
       "      <td>63.3810</td>\n",
       "      <td>66.7380</td>\n",
       "      <td>77.824000</td>\n",
       "      <td>66.39100</td>\n",
       "      <td>68.14200</td>\n",
       "      <td>66.391</td>\n",
       "      <td>75.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.89000</td>\n",
       "      <td>99.379000</td>\n",
       "      <td>99.835000</td>\n",
       "      <td>99.7590</td>\n",
       "      <td>99.6610</td>\n",
       "      <td>99.725000</td>\n",
       "      <td>99.74800</td>\n",
       "      <td>99.82400</td>\n",
       "      <td>99.608</td>\n",
       "      <td>99.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>19.1250</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17.62500</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>24.375</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        0.1        0.2      0.3      0.4        0.5  \\\n",
       "F1-LOC        NaN        NaN        NaN      NaN      NaN  17.380000   \n",
       "F1-MISC  46.15000  46.150000  46.150000  46.1500  43.6825  43.682500   \n",
       "F1-O     94.43100  95.075000  94.737000  94.9000  94.9640  95.227000   \n",
       "F1-ORG        NaN        NaN        NaN      NaN      NaN        NaN   \n",
       "F1-PER    8.57625  47.702857  28.391429  32.1575  34.5975  39.691111   \n",
       "P-LOC     0.00000   0.000000   0.000000   0.0000   0.0000  60.000000   \n",
       "P-MISC   70.00000  60.000000  60.000000  70.0000  65.0000  65.000000   \n",
       "P-O      89.54000  91.146000  90.138000  90.5000  90.7090  91.122000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "P-PER    53.63800  51.554000  57.193000  63.3810  66.7380  77.824000   \n",
       "R-LOC     0.00000   0.000000   0.000000   0.0000   0.0000   5.712000   \n",
       "R-MISC   21.00000  18.000000  18.000000  21.0000  24.0000  24.000000   \n",
       "R-O      99.89000  99.379000  99.835000  99.7590  99.6610  99.725000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "R-PER     4.00000  25.000000  12.250000  16.7500  19.1250  23.500000   \n",
       "\n",
       "              0.6       0.7     0.8        0.9  \n",
       "F1-LOC        NaN       NaN     NaN  17.380000  \n",
       "F1-MISC  46.15000  46.15000  46.150  43.591111  \n",
       "F1-O     94.91800  94.86800  95.157  95.299000  \n",
       "F1-ORG        NaN       NaN     NaN        NaN  \n",
       "F1-PER   34.62875  31.67875  42.050  41.984444  \n",
       "P-LOC     0.00000   0.00000   0.000  60.000000  \n",
       "P-MISC   60.00000  60.00000  80.000  72.500000  \n",
       "P-O      90.53800  90.38400  91.105  91.426000  \n",
       "P-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "P-PER    66.39100  68.14200  66.391  75.073000  \n",
       "R-LOC     0.00000   0.00000   0.000   5.712000  \n",
       "R-MISC   18.00000  18.00000  24.000  27.000000  \n",
       "R-O      99.74800  99.82400  99.608  99.531000  \n",
       "R-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "R-PER    17.62500  15.75000  24.375  26.875000  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>34.145859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>90.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>64.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>1.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>18.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   17.380000\n",
       "F1-MISC  45.400611\n",
       "F1-O     94.957600\n",
       "F1-ORG         NaN\n",
       "F1-PER   34.145859\n",
       "P-LOC    12.000000\n",
       "P-MISC   66.250000\n",
       "P-O      90.660800\n",
       "P-ORG     0.000000\n",
       "P-PER    64.632500\n",
       "R-LOC     1.142400\n",
       "R-MISC   21.300000\n",
       "R-O      99.696000\n",
       "R-ORG     0.000000\n",
       "R-PER    18.525000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.206887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>10.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>25.298221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.795628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.565721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>8.529639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.301515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.155470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>6.936167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    0.000000\n",
       "F1-MISC   1.206887\n",
       "F1-O      0.254209\n",
       "F1-ORG         NaN\n",
       "F1-PER   10.728242\n",
       "P-LOC    25.298221\n",
       "P-MISC    6.795628\n",
       "P-O       0.565721\n",
       "P-ORG     0.000000\n",
       "P-PER     8.529639\n",
       "R-LOC     2.408391\n",
       "R-MISC    3.301515\n",
       "R-O       0.155470\n",
       "R-ORG     0.000000\n",
       "R-PER     6.936167"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-4a85ba04e569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_fingerprints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreal_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ne-tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1770\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1771\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1772\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
