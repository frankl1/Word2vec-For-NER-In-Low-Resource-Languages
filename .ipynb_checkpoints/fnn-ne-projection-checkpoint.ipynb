{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 50\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab\n",
    "h1_size = 160\n",
    "h2_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                dataset[\"word\"].append(l[0])\n",
    "                dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4962</td>\n",
       "      <td>4753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>913</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>343</td>\n",
       "      <td>4362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4962   4753\n",
       "unique   913      5\n",
       "top        ,      O\n",
       "freq     343   4362"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 87.91 %\n",
      "MISC % = 2.12 %\n",
      "PER % = 4.94 %\n",
      "LOC % = 0.81 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.27 %\n",
      "MISC % = 1.86 %\n",
      "PER % = 8.87 %\n",
      "LOC % = 1.97 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>2376.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2376.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 912 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of          the    Holy  Spirit      In   first  \\\n",
       "0  4753.0   4753.0  4753.0  4753.000000  4753.0  4753.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4753.000000     0.0     0.0  4753.0  4753.0   \n",
       "2     0.0      0.0     0.0  1584.333374  4753.0  4753.0     0.0     0.0   \n",
       "3     0.0      0.0  4753.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4753.0  2376.500000     0.0     0.0     0.0     0.0   \n",
       "5     0.0      0.0     0.0  4753.000000  4753.0  4753.0     0.0     0.0   \n",
       "6  4753.0      0.0     0.0     0.000000     0.0     0.0     0.0     0.0   \n",
       "7     0.0      0.0     0.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "8     0.0      0.0     0.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "9     0.0      0.0  4753.0  1584.333374  4753.0  4753.0     0.0     0.0   \n",
       "\n",
       "     book            ,  ...   considered  dream  She  save  fulfill  Immanuel  \\\n",
       "0     0.0     0.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "1  4753.0  1584.333374  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "2     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "3     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "4     0.0  1188.250000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "5     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "6     0.0     0.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "7     0.0  1584.333374  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "8     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "9     0.0  2376.500000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "\n",
       "   us)  woke  sleep  knew  \n",
       "0  0.0   0.0    0.0   0.0  \n",
       "1  0.0   0.0    0.0   0.0  \n",
       "2  0.0   0.0    0.0   0.0  \n",
       "3  0.0   0.0    0.0   0.0  \n",
       "4  0.0   0.0    0.0   0.0  \n",
       "5  0.0   0.0    0.0   0.0  \n",
       "6  0.0   0.0    0.0   0.0  \n",
       "7  0.0   0.0    0.0   0.0  \n",
       "8  0.0   0.0    0.0   0.0  \n",
       "9  0.0   0.0    0.0   0.0  \n",
       "\n",
       "[10 rows x 912 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "count   912\n",
       "unique  912\n",
       "top      On\n",
       "freq      1"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (210, 912) (912,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "892       Eliud\n",
       "893     Eleazar\n",
       "894     Matthan\n",
       "895     husband\n",
       "896    fourteen\n",
       "897   unwilling\n",
       "898       shame\n",
       "899    resolved\n",
       "900     divorce\n",
       "901     quietly\n",
       "902  considered\n",
       "903       dream\n",
       "904         She\n",
       "905        save\n",
       "906     fulfill\n",
       "907    Immanuel\n",
       "908         us)\n",
       "909        woke\n",
       "910       sleep\n",
       "911        knew"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (912,)\n",
      "(912, 210) (912,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912, 5)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (611, 210)\n",
      "y_train.shape = (611, 5)\n",
      "X_val.shape = (301, 210)\n",
      "y_val.shape = (301, 5)\n",
      "O % in training data = 87.89 %\n",
      "O % in validation data = 89.37 %\n",
      "MISC % in training data = 1.31 %\n",
      "MISC % in validation data = 1.0 %\n",
      "PER % in training data = 8.67 %\n",
      "PER % in validation data = 7.97 %\n",
      "LOC % in training data = 1.96 %\n",
      "LOC % in validation data = 1.66 %\n",
      "ORG % in training data = 0.16 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1_size, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(h2_size, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=2, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.37 %\n",
      "MISC % = 2.18 %\n",
      "PER % = 5.76 %\n",
      "LOC % = 0.89 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 90.0 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.25 %\n",
      "LOC % = 1.84 %\n",
      "ORG % = 0.19 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4394</td>\n",
       "      <td>4185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1030</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>413</td>\n",
       "      <td>3795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4394   4185\n",
       "unique  1030      5\n",
       "top        ,      O\n",
       "freq     413   3795"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sÃ²</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sÃ²      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>obÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>yasÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>oyolÃ«ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>bÃ«yole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>AvÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>angavÃ«bÃ«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>oyÃ²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>anganÃ²á¹…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1009        nlo\n",
       "1010        obÃ«\n",
       "1011      mbara\n",
       "1012    yabyali\n",
       "1013      dzili\n",
       "1014       yasÃ²\n",
       "1015    oyolÃ«ge\n",
       "1016       kode\n",
       "1017       dili\n",
       "1018     atoban\n",
       "1019        sik\n",
       "1020       Ntud\n",
       "1021     bÃ«yole\n",
       "1022   Emmanuel\n",
       "1023      AvÃ«bÃ«\n",
       "1024   angavÃ«bÃ«\n",
       "1025        oyÃ²\n",
       "1026  angabende\n",
       "1027    anganÃ²á¹…\n",
       "1028   angayole"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 210) (1029,)\n",
      "(1029, 210) (1029,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029,) 1029\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 210)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50790, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50790 to 0.50294, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.50294\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.50294\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38880, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38880 to 0.37030, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37030 to 0.36008, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36008\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36008 to 0.35451, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35451 to 0.34547, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34547\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34547\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18346, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18346 to 0.18335, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18335\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18335\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26838, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26838\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26838\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15897, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15897\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15897\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19744, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19744\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19744\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08464, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08464\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08464\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11811, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11811 to 0.07420, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07420 to 0.07341, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07341\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07341\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16050, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16050\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16050\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09999, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09999\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09999\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52454, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52454 to 0.51003, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51003\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51003\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36965, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36965 to 0.36136, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36136\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36136 to 0.35158, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35158 to 0.34592, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34592\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34592\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17948, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17948\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17948\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27457, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27457\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27457\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20752, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20752\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20752\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19791, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19791\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19791\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10300, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10300 to 0.10105, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10105\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10105\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08762, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08762 to 0.07136, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07136\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07136\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16660, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16660 to 0.14536, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14536\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14536\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09230, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09230\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09230\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51718, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51718 to 0.51092, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51092\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51092\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38389, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38389 to 0.37253, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37253 to 0.36469, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36469\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36469\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22288, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22288 to 0.22146, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 0.22146 to 0.21627, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21627\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21627\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28636, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28636\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28636\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17655, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17655\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17655\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16810, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16810 to 0.16660, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16660\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16660\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13531, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13531 to 0.07780, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07780\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07780\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08872, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08872\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08872\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16182, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16182\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16182\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09452, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09452\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09452\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51373, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.51373\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51373\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41466, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41466 to 0.41406, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.41406\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41406\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27172, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27172 to 0.26877, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26877 to 0.25350, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25350\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25350\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35522, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35522 to 0.33215, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.33215\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33215\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22235, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22235\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22235 to 0.21641, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21641\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21641\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17711, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17711\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17711\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10782, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10782 to 0.10307, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10307 to 0.09951, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09951\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09951\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09500, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09500 to 0.08402, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08402\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08402\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11603, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11603\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11603\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10398, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10398 to 0.10311, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10311\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10311\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51013, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51013 to 0.50626, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.50626\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.50626\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37983, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37983 to 0.36989, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36989 to 0.35699, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35699 to 0.35625, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35625\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35625 to 0.35007, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35007 to 0.34015, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34015 to 0.32682, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32682\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32682\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18607, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18607\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21320, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21320\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13320, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13320\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15737, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15737\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15737\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13343, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13343 to 0.08340, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08340\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08340\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05825, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05825 to 0.05819, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05819\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05819\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15746, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15746 to 0.15316, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15316\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15316\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11446, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11446\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11446\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52700, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.52700\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.52700\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41091, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41091 to 0.38915, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38915\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38915 to 0.37460, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37460 to 0.36265, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36265 to 0.35765, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35765\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35765 to 0.35289, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35289\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35289 to 0.35194, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.35194\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35194 to 0.34998, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34998 to 0.34979, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34979\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34979\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15628, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15628\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15628\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23999, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23999\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23999\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13331, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13331\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15954, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15954\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15954\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06306, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06306\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09976, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09976 to 0.09411, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09411\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17193, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17193\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11907, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11907\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11907\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51066, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.51066\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51066 to 0.49819, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49819\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.49819\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38460, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38460 to 0.36650, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36650\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36650\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20795, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20795\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20795 to 0.20562, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20562\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20562\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33982, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33982 to 0.32747, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32747 to 0.31641, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31641 to 0.31047, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31047\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31047\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18012, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18012\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18012\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15341, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15341\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15341\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13160, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13160 to 0.11153, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11153\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11153\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07007, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07007 to 0.06740, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06740\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06740\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11948, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11948\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11948\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10101, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10101\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10101\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49549, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49549 to 0.49125, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49125\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49125\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35679, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35679 to 0.34550, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34550\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34550 to 0.33779, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33779 to 0.32865, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32865\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32865\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19715, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19715 to 0.18927, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18927\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26876, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26876 to 0.26090, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26090 to 0.26000, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26000\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15445, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15445 to 0.14695, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14695\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14695\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15324, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15324\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15324\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12963, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12963 to 0.10326, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10326 to 0.10048, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10048\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10048\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05926, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05926\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05926\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11813, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11813 to 0.11342, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11342\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11342\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11611, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11611\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11611\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50661, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50661 to 0.49272, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49272\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49272\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35554, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35554 to 0.34947, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34947 to 0.33933, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33933\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33933 to 0.33688, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33688 to 0.33134, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33134\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33134\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20051, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20051\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20051 to 0.19997, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19997 to 0.19714, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19714\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19714\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27640, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27640 to 0.24952, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24952\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24952\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13361, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13361\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13361\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15976, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15976\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10535, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10535 to 0.09961, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09961\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09961\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05083, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05083\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05083\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11330, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11330\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11330\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09883, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09883\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09883\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 160)               33760     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 60,325\n",
      "Trainable params: 60,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51068, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.51068\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51068\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38676, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38676 to 0.37242, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37242 to 0.36648, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36648 to 0.35661, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35661\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35661 to 0.34627, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34627\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34627\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24545, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24545\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24545 to 0.24234, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24234\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24234\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28139, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28139 to 0.25763, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25763\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25763\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18485, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18485\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18485\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16505, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16505\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16505\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08032, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08032 to 0.07881, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07881 to 0.04785, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04785\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06594, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06594\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06594\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17199, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17199\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17199\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13536, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13536 to 0.12129, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12129\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12129\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>78.615000</td>\n",
       "      <td>74.305000</td>\n",
       "      <td>80.112000</td>\n",
       "      <td>74.015000</td>\n",
       "      <td>77.750000</td>\n",
       "      <td>76.786000</td>\n",
       "      <td>79.073000</td>\n",
       "      <td>81.755000</td>\n",
       "      <td>79.722000</td>\n",
       "      <td>83.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>77.321000</td>\n",
       "      <td>76.469000</td>\n",
       "      <td>75.749000</td>\n",
       "      <td>77.706000</td>\n",
       "      <td>79.134000</td>\n",
       "      <td>76.740000</td>\n",
       "      <td>86.941000</td>\n",
       "      <td>77.839000</td>\n",
       "      <td>76.793000</td>\n",
       "      <td>78.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>68.745000</td>\n",
       "      <td>66.871000</td>\n",
       "      <td>62.206000</td>\n",
       "      <td>68.510000</td>\n",
       "      <td>67.707000</td>\n",
       "      <td>61.757000</td>\n",
       "      <td>74.126000</td>\n",
       "      <td>66.925000</td>\n",
       "      <td>63.661000</td>\n",
       "      <td>66.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>54.849000</td>\n",
       "      <td>54.718000</td>\n",
       "      <td>52.624000</td>\n",
       "      <td>47.076000</td>\n",
       "      <td>56.155000</td>\n",
       "      <td>55.509000</td>\n",
       "      <td>54.537000</td>\n",
       "      <td>59.686000</td>\n",
       "      <td>55.161000</td>\n",
       "      <td>56.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>52.484000</td>\n",
       "      <td>52.739000</td>\n",
       "      <td>52.558000</td>\n",
       "      <td>47.180000</td>\n",
       "      <td>54.604000</td>\n",
       "      <td>56.447000</td>\n",
       "      <td>54.541000</td>\n",
       "      <td>56.907000</td>\n",
       "      <td>55.879000</td>\n",
       "      <td>51.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>42.222000</td>\n",
       "      <td>44.445000</td>\n",
       "      <td>42.778000</td>\n",
       "      <td>40.001000</td>\n",
       "      <td>46.757000</td>\n",
       "      <td>46.295000</td>\n",
       "      <td>44.076000</td>\n",
       "      <td>47.871000</td>\n",
       "      <td>44.352000</td>\n",
       "      <td>41.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>70.140000</td>\n",
       "      <td>68.232222</td>\n",
       "      <td>66.125556</td>\n",
       "      <td>68.590000</td>\n",
       "      <td>70.871111</td>\n",
       "      <td>70.093333</td>\n",
       "      <td>70.132222</td>\n",
       "      <td>74.653333</td>\n",
       "      <td>69.376667</td>\n",
       "      <td>72.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>68.885556</td>\n",
       "      <td>67.994444</td>\n",
       "      <td>66.471111</td>\n",
       "      <td>62.838889</td>\n",
       "      <td>70.822222</td>\n",
       "      <td>71.963333</td>\n",
       "      <td>64.643000</td>\n",
       "      <td>72.475556</td>\n",
       "      <td>70.626667</td>\n",
       "      <td>68.094444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>57.512222</td>\n",
       "      <td>58.162222</td>\n",
       "      <td>54.398889</td>\n",
       "      <td>52.757778</td>\n",
       "      <td>60.721111</td>\n",
       "      <td>58.172222</td>\n",
       "      <td>53.923000</td>\n",
       "      <td>61.476667</td>\n",
       "      <td>57.015556</td>\n",
       "      <td>56.408889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          0          0          0          0          0  \\\n",
       "P_test    78.615000  74.305000  80.112000  74.015000  77.750000  76.786000   \n",
       "P_train   77.321000  76.469000  75.749000  77.706000  79.134000  76.740000   \n",
       "P_ewo     68.745000  66.871000  62.206000  68.510000  67.707000  61.757000   \n",
       "R_test    54.849000  54.718000  52.624000  47.076000  56.155000  55.509000   \n",
       "R_train   52.484000  52.739000  52.558000  47.180000  54.604000  56.447000   \n",
       "R_ewo     42.222000  44.445000  42.778000  40.001000  46.757000  46.295000   \n",
       "F1-test   70.140000  68.232222  66.125556  68.590000  70.871111  70.093333   \n",
       "F1-train  68.885556  67.994444  66.471111  62.838889  70.822222  71.963333   \n",
       "F1-ewo    57.512222  58.162222  54.398889  52.757778  60.721111  58.172222   \n",
       "\n",
       "                  0          0          0          0  \n",
       "P_test    79.073000  81.755000  79.722000  83.083000  \n",
       "P_train   86.941000  77.839000  76.793000  78.524000  \n",
       "P_ewo     74.126000  66.925000  63.661000  66.993000  \n",
       "R_test    54.537000  59.686000  55.161000  56.021000  \n",
       "R_train   54.541000  56.907000  55.879000  51.162000  \n",
       "R_ewo     44.076000  47.871000  44.352000  41.574000  \n",
       "F1-test   70.132222  74.653333  69.376667  72.230000  \n",
       "F1-train  64.643000  72.475556  70.626667  68.094444  \n",
       "F1-ewo    53.923000  61.476667  57.015556  56.408889  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>78.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>78.321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>66.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>54.633600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>53.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>44.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>70.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>68.481522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>57.054856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "P_test    78.521600\n",
       "P_train   78.321600\n",
       "P_ewo     66.750100\n",
       "R_test    54.633600\n",
       "R_train   53.450100\n",
       "R_ewo     44.037100\n",
       "F1-test   70.044444\n",
       "F1-train  68.481522\n",
       "F1-ewo    57.054856"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>2.929565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>3.188461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>3.615139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>3.197732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>2.908552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>2.465286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>2.307579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>3.150334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>2.817094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "P_test    2.929565\n",
       "P_train   3.188461\n",
       "P_ewo     3.615139\n",
       "R_test    3.197732\n",
       "R_train   2.908552\n",
       "R_ewo     2.465286\n",
       "F1-test   2.307579\n",
       "F1-train  3.150334\n",
       "F1-ewo    2.817094"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>96.443000</td>\n",
       "      <td>96.421000</td>\n",
       "      <td>96.425000</td>\n",
       "      <td>96.223000</td>\n",
       "      <td>96.636000</td>\n",
       "      <td>96.575000</td>\n",
       "      <td>96.59700</td>\n",
       "      <td>96.688000</td>\n",
       "      <td>96.600000</td>\n",
       "      <td>96.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>94.143000</td>\n",
       "      <td>94.230000</td>\n",
       "      <td>94.212000</td>\n",
       "      <td>93.565000</td>\n",
       "      <td>94.421000</td>\n",
       "      <td>94.587000</td>\n",
       "      <td>94.37400</td>\n",
       "      <td>94.680000</td>\n",
       "      <td>94.569000</td>\n",
       "      <td>93.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.897000</td>\n",
       "      <td>98.775000</td>\n",
       "      <td>98.815000</td>\n",
       "      <td>99.091000</td>\n",
       "      <td>99.008000</td>\n",
       "      <td>98.691000</td>\n",
       "      <td>98.96500</td>\n",
       "      <td>98.829000</td>\n",
       "      <td>98.773000</td>\n",
       "      <td>99.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>64.065000</td>\n",
       "      <td>64.081111</td>\n",
       "      <td>64.065000</td>\n",
       "      <td>57.372857</td>\n",
       "      <td>62.530000</td>\n",
       "      <td>68.413333</td>\n",
       "      <td>61.81875</td>\n",
       "      <td>61.937778</td>\n",
       "      <td>62.375000</td>\n",
       "      <td>61.431250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>78.75000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>38.242000</td>\n",
       "      <td>44.061000</td>\n",
       "      <td>38.242000</td>\n",
       "      <td>28.576000</td>\n",
       "      <td>41.354000</td>\n",
       "      <td>47.487000</td>\n",
       "      <td>37.04100</td>\n",
       "      <td>42.061000</td>\n",
       "      <td>36.444000</td>\n",
       "      <td>36.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>74.954444</td>\n",
       "      <td>73.555556</td>\n",
       "      <td>71.955556</td>\n",
       "      <td>69.900000</td>\n",
       "      <td>76.171111</td>\n",
       "      <td>76.974444</td>\n",
       "      <td>71.05100</td>\n",
       "      <td>79.104444</td>\n",
       "      <td>76.863333</td>\n",
       "      <td>74.494444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>78.192000</td>\n",
       "      <td>75.099000</td>\n",
       "      <td>76.575000</td>\n",
       "      <td>76.587000</td>\n",
       "      <td>78.411000</td>\n",
       "      <td>78.082000</td>\n",
       "      <td>87.23200</td>\n",
       "      <td>77.481000</td>\n",
       "      <td>75.766000</td>\n",
       "      <td>77.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>59.923000</td>\n",
       "      <td>61.033000</td>\n",
       "      <td>59.642000</td>\n",
       "      <td>56.650000</td>\n",
       "      <td>62.337000</td>\n",
       "      <td>62.696000</td>\n",
       "      <td>63.13200</td>\n",
       "      <td>66.521000</td>\n",
       "      <td>65.287000</td>\n",
       "      <td>59.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>48.671250</td>\n",
       "      <td>53.291667</td>\n",
       "      <td>54.604286</td>\n",
       "      <td>45.708333</td>\n",
       "      <td>57.795714</td>\n",
       "      <td>49.677778</td>\n",
       "      <td>49.11375</td>\n",
       "      <td>50.412857</td>\n",
       "      <td>49.961250</td>\n",
       "      <td>48.231429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>56.090000</td>\n",
       "      <td>56.111000</td>\n",
       "      <td>50.523000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.977000</td>\n",
       "      <td>65.709000</td>\n",
       "      <td>65.22800</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>74.692000</td>\n",
       "      <td>65.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>31.239000</td>\n",
       "      <td>23.508000</td>\n",
       "      <td>32.725000</td>\n",
       "      <td>18.973000</td>\n",
       "      <td>31.373000</td>\n",
       "      <td>37.819000</td>\n",
       "      <td>30.34500</td>\n",
       "      <td>26.733000</td>\n",
       "      <td>29.821000</td>\n",
       "      <td>25.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0          0          0          0          0  \\\n",
       "F1-O     96.443000  96.421000  96.425000  96.223000  96.636000  96.575000   \n",
       "P-O      94.143000  94.230000  94.212000  93.565000  94.421000  94.587000   \n",
       "R-O      98.897000  98.775000  98.815000  99.091000  99.008000  98.691000   \n",
       "F1-MISC  64.065000  64.081111  64.065000  57.372857  62.530000  68.413333   \n",
       "P-MISC   80.000000  88.750000  80.000000  70.000000  90.000000  88.750000   \n",
       "R-MISC   38.242000  44.061000  38.242000  28.576000  41.354000  47.487000   \n",
       "F1-PER   74.954444  73.555556  71.955556  69.900000  76.171111  76.974444   \n",
       "P-PER    78.192000  75.099000  76.575000  76.587000  78.411000  78.082000   \n",
       "R-PER    59.923000  61.033000  59.642000  56.650000  62.337000  62.696000   \n",
       "F1-LOC   48.671250  53.291667  54.604286  45.708333  57.795714  49.677778   \n",
       "P-LOC    56.090000  56.111000  50.523000  60.000000  60.977000  65.709000   \n",
       "R-LOC    31.239000  23.508000  32.725000  18.973000  31.373000  37.819000   \n",
       "F1-ORG    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "P-ORG     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "R-ORG     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "                0          0          0          0  \n",
       "F1-O     96.59700  96.688000  96.600000  96.420000  \n",
       "P-O      94.37400  94.680000  94.569000  93.986000  \n",
       "R-O      98.96500  98.829000  98.773000  99.022000  \n",
       "F1-MISC  61.81875  61.937778  62.375000  61.431250  \n",
       "P-MISC   78.75000  87.500000  80.000000  80.000000  \n",
       "R-MISC   37.04100  42.061000  36.444000  36.132000  \n",
       "F1-PER   71.05100  79.104444  76.863333  74.494444  \n",
       "P-PER    87.23200  77.481000  75.766000  77.871000  \n",
       "R-PER    63.13200  66.521000  65.287000  59.619000  \n",
       "F1-LOC   49.11375  50.412857  49.961250  48.231429  \n",
       "P-LOC    65.22800  61.000000  74.692000  65.192000  \n",
       "R-LOC    30.34500  26.733000  29.821000  25.841000  \n",
       "F1-ORG    0.00000   0.000000   0.000000   0.000000  \n",
       "P-ORG     0.00000   0.000000   0.000000   0.000000  \n",
       "R-ORG     0.00000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>96.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>94.276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.886600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>62.809008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>82.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>38.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>74.502433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>78.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>61.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>50.746831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>61.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>28.837700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     96.502800\n",
       "P-O      94.276700\n",
       "R-O      98.886600\n",
       "F1-MISC  62.809008\n",
       "P-MISC   82.375000\n",
       "R-MISC   38.964000\n",
       "F1-PER   74.502433\n",
       "P-PER    78.129600\n",
       "R-PER    61.684000\n",
       "F1-LOC   50.746831\n",
       "P-LOC    61.552200\n",
       "R-LOC    28.837700\n",
       "F1-ORG    0.000000\n",
       "P-ORG     0.000000\n",
       "R-ORG     0.000000"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.140254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.331651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.130456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>2.781637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.276333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>5.174146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>2.912235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>3.382867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>2.929268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>3.521413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>6.673527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>5.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-O     0.140254\n",
       "P-O      0.331651\n",
       "R-O      0.130456\n",
       "F1-MISC  2.781637\n",
       "P-MISC   6.276333\n",
       "R-MISC   5.174146\n",
       "F1-PER   2.912235\n",
       "P-PER    3.382867\n",
       "R-PER    2.929268\n",
       "F1-LOC   3.521413\n",
       "P-LOC    6.673527\n",
       "R-LOC    5.274000\n",
       "F1-ORG   0.000000\n",
       "P-ORG    0.000000\n",
       "R-ORG    0.000000"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>96.416000</td>\n",
       "      <td>96.480000</td>\n",
       "      <td>96.375000</td>\n",
       "      <td>96.220000</td>\n",
       "      <td>96.477000</td>\n",
       "      <td>96.539000</td>\n",
       "      <td>96.359000</td>\n",
       "      <td>96.910000</td>\n",
       "      <td>96.494000</td>\n",
       "      <td>96.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>94.164000</td>\n",
       "      <td>94.518000</td>\n",
       "      <td>93.995000</td>\n",
       "      <td>93.369000</td>\n",
       "      <td>94.396000</td>\n",
       "      <td>94.389000</td>\n",
       "      <td>94.144000</td>\n",
       "      <td>94.883000</td>\n",
       "      <td>94.207000</td>\n",
       "      <td>94.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.865000</td>\n",
       "      <td>98.628000</td>\n",
       "      <td>98.997000</td>\n",
       "      <td>99.374000</td>\n",
       "      <td>98.746000</td>\n",
       "      <td>98.868000</td>\n",
       "      <td>98.748000</td>\n",
       "      <td>99.127000</td>\n",
       "      <td>99.011000</td>\n",
       "      <td>99.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>53.334000</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "      <td>61.111667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>77.322222</td>\n",
       "      <td>75.281111</td>\n",
       "      <td>72.244444</td>\n",
       "      <td>73.767500</td>\n",
       "      <td>78.635556</td>\n",
       "      <td>75.546667</td>\n",
       "      <td>78.300000</td>\n",
       "      <td>79.201111</td>\n",
       "      <td>75.668889</td>\n",
       "      <td>76.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>81.253000</td>\n",
       "      <td>74.460000</td>\n",
       "      <td>81.293000</td>\n",
       "      <td>73.432000</td>\n",
       "      <td>79.808000</td>\n",
       "      <td>82.083000</td>\n",
       "      <td>80.499000</td>\n",
       "      <td>80.979000</td>\n",
       "      <td>78.654000</td>\n",
       "      <td>82.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>62.174000</td>\n",
       "      <td>63.508000</td>\n",
       "      <td>58.940000</td>\n",
       "      <td>53.035000</td>\n",
       "      <td>64.620000</td>\n",
       "      <td>60.479000</td>\n",
       "      <td>63.746000</td>\n",
       "      <td>65.953000</td>\n",
       "      <td>62.730000</td>\n",
       "      <td>60.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>44.445000</td>\n",
       "      <td>39.334000</td>\n",
       "      <td>44.445000</td>\n",
       "      <td>52.223333</td>\n",
       "      <td>43.890000</td>\n",
       "      <td>45.782857</td>\n",
       "      <td>42.668000</td>\n",
       "      <td>54.762857</td>\n",
       "      <td>53.334000</td>\n",
       "      <td>61.111667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>23.333000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>26.666000</td>\n",
       "      <td>21.667000</td>\n",
       "      <td>28.333000</td>\n",
       "      <td>26.667000</td>\n",
       "      <td>26.667000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>21.667000</td>\n",
       "      <td>33.333000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          0          0          0          0          0  \\\n",
       "F1-O     96.416000  96.480000  96.375000  96.220000  96.477000  96.539000   \n",
       "P-O      94.164000  94.518000  93.995000  93.369000  94.396000  94.389000   \n",
       "R-O      98.865000  98.628000  98.997000  99.374000  98.746000  98.868000   \n",
       "F1-MISC  61.111667  61.111667  61.111667  53.334000  61.111667  61.111667   \n",
       "P-MISC   40.000000  40.000000  40.000000  30.000000  40.000000  40.000000   \n",
       "R-MISC   35.000000  35.000000  35.000000  25.000000  35.000000  35.000000   \n",
       "F1-PER   77.322222  75.281111  72.244444  73.767500  78.635556  75.546667   \n",
       "P-PER    81.253000  74.460000  81.293000  73.432000  79.808000  82.083000   \n",
       "R-PER    62.174000  63.508000  58.940000  53.035000  64.620000  60.479000   \n",
       "F1-LOC   44.445000  39.334000  44.445000  52.223333  43.890000  45.782857   \n",
       "P-LOC    35.000000  23.333000  30.000000  40.000000  30.000000  39.000000   \n",
       "R-LOC    26.666000  21.667000  28.333000  26.667000  26.667000  35.000000   \n",
       "F1-ORG    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "P-ORG     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "R-ORG     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "                 0          0          0          0  \n",
       "F1-O     96.359000  96.910000  96.494000  96.663000  \n",
       "P-O      94.144000  94.883000  94.207000  94.295000  \n",
       "R-O      98.748000  99.127000  99.011000  99.234000  \n",
       "F1-MISC  61.111667  61.111667  61.111667  61.111667  \n",
       "P-MISC   40.000000  40.000000  40.000000  40.000000  \n",
       "R-MISC   35.000000  35.000000  35.000000  35.000000  \n",
       "F1-PER   78.300000  79.201111  75.668889  76.140000  \n",
       "P-PER    80.499000  80.979000  78.654000  82.166000  \n",
       "R-PER    63.746000  65.953000  62.730000  60.735000  \n",
       "F1-LOC   42.668000  54.762857  53.334000  61.111667  \n",
       "P-LOC    25.000000  50.000000  30.000000  40.000000  \n",
       "R-LOC    21.667000  33.333000  25.000000  35.000000  \n",
       "F1-ORG    0.000000   0.000000   0.000000   0.000000  \n",
       "P-ORG     0.000000   0.000000   0.000000   0.000000  \n",
       "R-ORG     0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>96.493300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>94.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.959800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>60.333900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>76.210750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>79.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>61.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>48.199671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>34.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     96.493300\n",
       "P-O      94.236000\n",
       "R-O      98.959800\n",
       "F1-MISC  60.333900\n",
       "P-MISC   39.000000\n",
       "R-MISC   34.000000\n",
       "F1-PER   76.210750\n",
       "P-PER    79.462700\n",
       "R-PER    61.592000\n",
       "F1-LOC   48.199671\n",
       "P-LOC    34.233300\n",
       "R-LOC    28.000000\n",
       "F1-ORG    0.000000\n",
       "P-ORG     0.000000\n",
       "R-ORG     0.000000"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.187874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.390851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.234943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>2.459514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>2.204218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>3.096084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>3.656960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>6.783600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>8.139346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>4.956465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-O     0.187874\n",
       "P-O      0.390851\n",
       "R-O      0.234943\n",
       "F1-MISC  2.459514\n",
       "P-MISC   3.162278\n",
       "R-MISC   3.162278\n",
       "F1-PER   2.204218\n",
       "P-PER    3.096084\n",
       "R-PER    3.656960\n",
       "F1-LOC   6.783600\n",
       "P-LOC    8.139346\n",
       "R-LOC    4.956465\n",
       "F1-ORG   0.000000\n",
       "P-ORG    0.000000\n",
       "R-ORG    0.000000"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.1500</td>\n",
       "      <td>43.6825</td>\n",
       "      <td>43.682500</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150</td>\n",
       "      <td>43.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.43100</td>\n",
       "      <td>95.075000</td>\n",
       "      <td>94.737000</td>\n",
       "      <td>94.9000</td>\n",
       "      <td>94.9640</td>\n",
       "      <td>95.227000</td>\n",
       "      <td>94.91800</td>\n",
       "      <td>94.86800</td>\n",
       "      <td>95.157</td>\n",
       "      <td>95.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>8.57625</td>\n",
       "      <td>47.702857</td>\n",
       "      <td>28.391429</td>\n",
       "      <td>32.1575</td>\n",
       "      <td>34.5975</td>\n",
       "      <td>39.691111</td>\n",
       "      <td>34.62875</td>\n",
       "      <td>31.67875</td>\n",
       "      <td>42.050</td>\n",
       "      <td>41.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>70.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.54000</td>\n",
       "      <td>91.146000</td>\n",
       "      <td>90.138000</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>90.7090</td>\n",
       "      <td>91.122000</td>\n",
       "      <td>90.53800</td>\n",
       "      <td>90.38400</td>\n",
       "      <td>91.105</td>\n",
       "      <td>91.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>53.63800</td>\n",
       "      <td>51.554000</td>\n",
       "      <td>57.193000</td>\n",
       "      <td>63.3810</td>\n",
       "      <td>66.7380</td>\n",
       "      <td>77.824000</td>\n",
       "      <td>66.39100</td>\n",
       "      <td>68.14200</td>\n",
       "      <td>66.391</td>\n",
       "      <td>75.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.89000</td>\n",
       "      <td>99.379000</td>\n",
       "      <td>99.835000</td>\n",
       "      <td>99.7590</td>\n",
       "      <td>99.6610</td>\n",
       "      <td>99.725000</td>\n",
       "      <td>99.74800</td>\n",
       "      <td>99.82400</td>\n",
       "      <td>99.608</td>\n",
       "      <td>99.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>19.1250</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17.62500</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>24.375</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        0.1        0.2      0.3      0.4        0.5  \\\n",
       "F1-LOC        NaN        NaN        NaN      NaN      NaN  17.380000   \n",
       "F1-MISC  46.15000  46.150000  46.150000  46.1500  43.6825  43.682500   \n",
       "F1-O     94.43100  95.075000  94.737000  94.9000  94.9640  95.227000   \n",
       "F1-ORG        NaN        NaN        NaN      NaN      NaN        NaN   \n",
       "F1-PER    8.57625  47.702857  28.391429  32.1575  34.5975  39.691111   \n",
       "P-LOC     0.00000   0.000000   0.000000   0.0000   0.0000  60.000000   \n",
       "P-MISC   70.00000  60.000000  60.000000  70.0000  65.0000  65.000000   \n",
       "P-O      89.54000  91.146000  90.138000  90.5000  90.7090  91.122000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "P-PER    53.63800  51.554000  57.193000  63.3810  66.7380  77.824000   \n",
       "R-LOC     0.00000   0.000000   0.000000   0.0000   0.0000   5.712000   \n",
       "R-MISC   21.00000  18.000000  18.000000  21.0000  24.0000  24.000000   \n",
       "R-O      99.89000  99.379000  99.835000  99.7590  99.6610  99.725000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "R-PER     4.00000  25.000000  12.250000  16.7500  19.1250  23.500000   \n",
       "\n",
       "              0.6       0.7     0.8        0.9  \n",
       "F1-LOC        NaN       NaN     NaN  17.380000  \n",
       "F1-MISC  46.15000  46.15000  46.150  43.591111  \n",
       "F1-O     94.91800  94.86800  95.157  95.299000  \n",
       "F1-ORG        NaN       NaN     NaN        NaN  \n",
       "F1-PER   34.62875  31.67875  42.050  41.984444  \n",
       "P-LOC     0.00000   0.00000   0.000  60.000000  \n",
       "P-MISC   60.00000  60.00000  80.000  72.500000  \n",
       "P-O      90.53800  90.38400  91.105  91.426000  \n",
       "P-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "P-PER    66.39100  68.14200  66.391  75.073000  \n",
       "R-LOC     0.00000   0.00000   0.000   5.712000  \n",
       "R-MISC   18.00000  18.00000  24.000  27.000000  \n",
       "R-O      99.74800  99.82400  99.608  99.531000  \n",
       "R-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "R-PER    17.62500  15.75000  24.375  26.875000  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>34.145859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>90.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>64.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>1.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>18.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   17.380000\n",
       "F1-MISC  45.400611\n",
       "F1-O     94.957600\n",
       "F1-ORG         NaN\n",
       "F1-PER   34.145859\n",
       "P-LOC    12.000000\n",
       "P-MISC   66.250000\n",
       "P-O      90.660800\n",
       "P-ORG     0.000000\n",
       "P-PER    64.632500\n",
       "R-LOC     1.142400\n",
       "R-MISC   21.300000\n",
       "R-O      99.696000\n",
       "R-ORG     0.000000\n",
       "R-PER    18.525000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.206887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>10.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>25.298221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.795628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.565721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>8.529639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.301515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.155470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>6.936167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    0.000000\n",
       "F1-MISC   1.206887\n",
       "F1-O      0.254209\n",
       "F1-ORG         NaN\n",
       "F1-PER   10.728242\n",
       "P-LOC    25.298221\n",
       "P-MISC    6.795628\n",
       "P-O       0.565721\n",
       "P-ORG     0.000000\n",
       "P-PER     8.529639\n",
       "R-LOC     2.408391\n",
       "R-MISC    3.301515\n",
       "R-O       0.155470\n",
       "R-ORG     0.000000\n",
       "R-PER     6.936167"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-4a85ba04e569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_fingerprints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreal_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ne-tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                              'argument.')\n\u001b[1;32m   1151\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
