{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 10\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "shuffle = is_only_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                dataset[\"word\"].append(l[0])\n",
    "                dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    nb_word_in_corpus = aDataframe[aDataframe.word != \"\\n\"].word.size\n",
    "    words_in_current_phrase = []\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            words_in_current_phrase.append(word)\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.float32)\n",
    "            fingerprints[word][current_bi_phrase_index] += 1\n",
    "        else:\n",
    "            nb_word_in_current_phrase = len(words_in_current_phrase)\n",
    "#             for w in words_in_current_phrase:\n",
    "#                 fingerprints[w][current_bi_phrase_index] = nb_word_in_corpus / fingerprints[w][current_bi_phrase_index]                \n",
    "            current_bi_phrase_index += 1\n",
    "            words_in_current_phrase = []\n",
    "    for word in fingerprints:\n",
    "        for i in range(nb_of_biphrases):\n",
    "            if fingerprints[word][i] != 0:\n",
    "                fingerprints[word][i] = nb_word_in_corpus / fingerprints[word][i]\n",
    "#         fingerprints[word][nb_of_biphrases] = nb_word_in_corpus / aDataframe[aDataframe.word == word].word.size\n",
    "        \n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4962</td>\n",
       "      <td>4753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>913</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>343</td>\n",
       "      <td>4362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4962   4753\n",
       "unique   913      5\n",
       "top        ,      O\n",
       "freq     343   4362"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Promise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word ne-tag\n",
       "0      The      O\n",
       "1  Promise      O\n",
       "2       of      O\n",
       "3      the      O\n",
       "4     Holy   MISC\n",
       "5   Spirit   MISC\n",
       "6       \\n   None\n",
       "7       In      O\n",
       "8      the      O\n",
       "9    first      O"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 87.91 %\n",
      "MISC % = 2.12 %\n",
      "PER % = 4.94 %\n",
      "LOC % = 0.81 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.27 %\n",
      "MISC % = 1.86 %\n",
      "PER % = 8.87 %\n",
      "LOC % = 1.97 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Promise</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Holy</th>\n",
       "      <th>Spirit</th>\n",
       "      <th>In</th>\n",
       "      <th>first</th>\n",
       "      <th>book</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>considered</th>\n",
       "      <th>dream</th>\n",
       "      <th>She</th>\n",
       "      <th>save</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>Immanuel</th>\n",
       "      <th>us)</th>\n",
       "      <th>woke</th>\n",
       "      <th>sleep</th>\n",
       "      <th>knew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>2376.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>1584.333374</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2376.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 912 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  Promise      of          the    Holy  Spirit      In   first  \\\n",
       "0  4753.0   4753.0  4753.0  4753.000000  4753.0  4753.0     0.0     0.0   \n",
       "1     0.0      0.0     0.0  4753.000000     0.0     0.0  4753.0  4753.0   \n",
       "2     0.0      0.0     0.0  1584.333374  4753.0  4753.0     0.0     0.0   \n",
       "3     0.0      0.0  4753.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "4     0.0      0.0  4753.0  2376.500000     0.0     0.0     0.0     0.0   \n",
       "5     0.0      0.0     0.0  4753.000000  4753.0  4753.0     0.0     0.0   \n",
       "6  4753.0      0.0     0.0     0.000000     0.0     0.0     0.0     0.0   \n",
       "7     0.0      0.0     0.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "8     0.0      0.0     0.0  4753.000000     0.0     0.0     0.0     0.0   \n",
       "9     0.0      0.0  4753.0  1584.333374  4753.0  4753.0     0.0     0.0   \n",
       "\n",
       "     book            ,  ...   considered  dream  She  save  fulfill  Immanuel  \\\n",
       "0     0.0     0.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "1  4753.0  1584.333374  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "2     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "3     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "4     0.0  1188.250000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "5     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "6     0.0     0.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "7     0.0  1584.333374  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "8     0.0  4753.000000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "9     0.0  2376.500000  ...          0.0    0.0  0.0   0.0      0.0       0.0   \n",
       "\n",
       "   us)  woke  sleep  knew  \n",
       "0  0.0   0.0    0.0   0.0  \n",
       "1  0.0   0.0    0.0   0.0  \n",
       "2  0.0   0.0    0.0   0.0  \n",
       "3  0.0   0.0    0.0   0.0  \n",
       "4  0.0   0.0    0.0   0.0  \n",
       "5  0.0   0.0    0.0   0.0  \n",
       "6  0.0   0.0    0.0   0.0  \n",
       "7  0.0   0.0    0.0   0.0  \n",
       "8  0.0   0.0    0.0   0.0  \n",
       "9  0.0   0.0    0.0   0.0  \n",
       "\n",
       "[10 rows x 912 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fingerprints['you'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>greeted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "count       912\n",
       "unique      912\n",
       "top     greeted\n",
       "freq          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (210, 912) (912,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "892       Eliud\n",
       "893     Eleazar\n",
       "894     Matthan\n",
       "895     husband\n",
       "896    fourteen\n",
       "897   unwilling\n",
       "898       shame\n",
       "899    resolved\n",
       "900     divorce\n",
       "901     quietly\n",
       "902  considered\n",
       "903       dream\n",
       "904         She\n",
       "905        save\n",
       "906     fulfill\n",
       "907    Immanuel\n",
       "908         us)\n",
       "909        woke\n",
       "910       sleep\n",
       "911        knew"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (912,)\n",
      "(912, 210) (912,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    if shuffle:\n",
    "        X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (611, 210)\n",
      "y_train.shape = (611, 5)\n",
      "X_val.shape = (301, 210)\n",
      "y_val.shape = (301, 5)\n",
      "O % in training data = 88.05 %\n",
      "O % in validation data = 89.04 %\n",
      "MISC % in training data = 1.15 %\n",
      "MISC % in validation data = 1.33 %\n",
      "PER % in training data = 8.67 %\n",
      "PER % in validation data = 7.97 %\n",
      "LOC % in training data = 1.96 %\n",
      "LOC % in validation data = 1.66 %\n",
      "ORG % in training data = 0.16 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(640, input_dim=input_dim, activation='sigmoid', name=\"hidden1\"))\n",
    "    model.add(Dense(160, activation='sigmoid', name=\"hidden2\"))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid', name=\"outputlayer\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax', name=\"outputlayer\"))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    early_stop = EarlyStopping(patience=2, verbose=2) # stop learning if the error is the same between two consecutive epochs\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=1) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0, shuffle=shuffle, callbacks=[best_model_cp, early_stop])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.37 %\n",
      "MISC % = 2.18 %\n",
      "PER % = 5.76 %\n",
      "LOC % = 0.89 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 90.0 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.25 %\n",
      "LOC % = 1.84 %\n",
      "ORG % = 0.19 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4394</td>\n",
       "      <td>4185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1030</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>413</td>\n",
       "      <td>3795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word ne-tag\n",
       "count   4394   4185\n",
       "unique  1030      5\n",
       "top        ,      O\n",
       "freq     413   3795"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ne-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mfufub</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nsisim</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ayi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sò</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word ne-tag\n",
       "0  Mfufub   MISC\n",
       "1  Nsisim   MISC\n",
       "2     ayi      O\n",
       "3      sò      O\n",
       "4      \\n   None"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>obë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>yasò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>oyolëge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>bëyole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Avëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>angavëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>oyò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>anganòṅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1009        nlo\n",
       "1010        obë\n",
       "1011      mbara\n",
       "1012    yabyali\n",
       "1013      dzili\n",
       "1014       yasò\n",
       "1015    oyolëge\n",
       "1016       kode\n",
       "1017       dili\n",
       "1018     atoban\n",
       "1019        sik\n",
       "1020       Ntud\n",
       "1021     bëyole\n",
       "1022   Emmanuel\n",
       "1023      Avëbë\n",
       "1024   angavëbë\n",
       "1025        oyò\n",
       "1026  angabende\n",
       "1027    anganòṅ\n",
       "1028   angayole"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 210) (1029,)\n",
      "(1029, 210) (1029,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    if shuffle:\n",
    "        X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029,) 1029\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 210)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo = X_ewo.reshape((X_ewo.shape[0], en_nb_of_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(X.shape[1], len(tagSet))\n",
    "# resultEval, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / k)   \n",
    "    output = None\n",
    "    model = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51957, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.51957\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51957 to 0.42881, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42881 to 0.38687, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38687\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38687\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11202, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11202\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11202 to 0.11067, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11067\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11067 to 0.10716, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10716\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10716\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17482, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17482 to 0.08321, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08321\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08321\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11092, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11092\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11092\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10338, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10338 to 0.10334, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10334\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10334\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08570, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08570 to 0.05639, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05639\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05639 to 0.04680, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04680\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04680\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14265, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14265\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14265\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09304, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09304\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09304\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04606, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04606\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04606\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12028, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12028\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12028\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46571, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46571 to 0.43293, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.43293\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43293\n",
      "Epoch 00004: early stopping\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11712, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11712\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12027, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12027\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12027\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14327, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14327\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14327\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11472, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11472\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11472\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05453, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05453 to 0.05098, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05098\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05098\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17619, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17619\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17619\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10869, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10869\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10869\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04384, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04384\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04384\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10187, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10187 to 0.09494, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09494\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09494\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48151, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48151 to 0.46725, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46725 to 0.45615, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45615\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.45615 to 0.44707, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44707\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44707\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10651, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10651\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10568, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10568 to 0.08344, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08344\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08344\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13697, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13697\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13697\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08709, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08709\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08709\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06547, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06547 to 0.05972, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05972\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05972 to 0.04953, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04953\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04953 to 0.04541, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04541\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04541\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20411, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20411 to 0.16470, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16470\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16470\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08812, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08812\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08812\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05388, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05388\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05388\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09925, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09925\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09925\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53909, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53909 to 0.51927, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51927 to 0.50240, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50240 to 0.44099, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44099 to 0.40535, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40535\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40535 to 0.36866, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36866\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36866\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10168, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10168\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10168\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10173, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10173\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10173 to 0.09416, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09416 to 0.07750, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07750\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07750\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12017, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12017\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12017\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11424, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11424\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11424\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03013, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03013\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03013\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15079, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15079\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15079\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08812, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08812\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08812\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03664, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03664\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03664\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10761, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10761\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10761\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45429, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45429\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45429\n",
      "Epoch 00003: early stopping\n",
      "number of correct positive predictions is 0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17026, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17026\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17026 to 0.13313, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13313 to 0.12944, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12944 to 0.11763, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11763\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11763\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09040, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09040 to 0.07113, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07113\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13932, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13932\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13932\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14535, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14535 to 0.12393, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12393 to 0.11773, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11773\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11773\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03968, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03968\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03968\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14898, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14898\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14898\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10444, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10444\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10444\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04470, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04470\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04470\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08592, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08592\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08592\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49159, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49159 to 0.42690, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42690 to 0.41478, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.41478 to 0.40182, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.40182\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40182\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10925, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10925 to 0.10836, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10836\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10836\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08677, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08677\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08677\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11262, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11262\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11262\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12415, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12415 to 0.11964, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11964\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11964\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09599, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09599 to 0.06233, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06233 to 0.04303, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04303\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04303\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16203, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16203 to 0.14930, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14930\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14930\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08095, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08095\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08095\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04522, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04522\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04522\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07361, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07361\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07361\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44067, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.44067\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44067 to 0.41536, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41536\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41536\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13758, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13758 to 0.09733, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09733\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09733\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10550, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10550\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10550\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13395, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13395\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13395\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10924, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10924\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10924\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05762, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05762 to 0.04595, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04595\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04595\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15556, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15556\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15556\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11936, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11936 to 0.11666, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11666\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11666\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06531, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06531\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06531\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11186, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11186 to 0.09098, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09098\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09098\n",
      "Epoch 00004: early stopping\n",
      "AlgoCrossValIter - 8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47779, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47779 to 0.45911, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45911 to 0.44384, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44384 to 0.43676, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.43676 to 0.40646, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40646\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.40646\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12407, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12407 to 0.11897, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11897 to 0.11716, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11716\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11716\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08236, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08236\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08236\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11954, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11954 to 0.11684, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11684\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11684\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08954, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08954\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08954\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05415, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05415\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05415\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13788, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.13788\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13788\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10019, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10019\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10019\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05571, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05571\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05571\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08462, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08462\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08462\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48975, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48975 to 0.48738, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48738 to 0.46317, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46317 to 0.43532, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.43532 to 0.42941, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.42941\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42941\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10193, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10193\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09330, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09330 to 0.08844, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08844\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08844\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14393, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14393 to 0.13442, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.13442\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13442\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12502, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.12502\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12502 to 0.12179, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12179\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12179\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05197, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05197\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05197 to 0.04045, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04045\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04045\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15342, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15342\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15342\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10831, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10831 to 0.09880, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09880\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09880\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04834, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04834\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04834\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09782, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09782\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09782\n",
      "Epoch 00003: early stopping\n",
      "AlgoCrossValIter - 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 640)               135040    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 160)               102560    \n",
      "_________________________________________________________________\n",
      "outputlayer (Dense)          (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 238,405\n",
      "Trainable params: 238,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50165, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50165 to 0.46424, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46424 to 0.45667, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45667 to 0.38551, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38551\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38551\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibaaslabs/.env/nn-ne-projection/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11728, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11728 to 0.10182, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10182\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10182\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09118, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09118\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09118\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10895, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10895\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10895\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14725, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14725 to 0.13737, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13737 to 0.12360, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12360\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12360\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05874, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05874 to 0.05365, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05365\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05365\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16279, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16279\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16279\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09421, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09421\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09421\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06521, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06521\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06521\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08418, saving model to best-model-conll.hdfs\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08418\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08418\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult, model = algoCrossVal(X, y, X_ewo, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>89.144</td>\n",
       "      <td>75.112</td>\n",
       "      <td>87.339</td>\n",
       "      <td>86.770</td>\n",
       "      <td>80.465000</td>\n",
       "      <td>84.984</td>\n",
       "      <td>83.963</td>\n",
       "      <td>81.951</td>\n",
       "      <td>87.098</td>\n",
       "      <td>83.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>90.876</td>\n",
       "      <td>86.225</td>\n",
       "      <td>88.108</td>\n",
       "      <td>88.398</td>\n",
       "      <td>86.197000</td>\n",
       "      <td>86.516</td>\n",
       "      <td>86.571</td>\n",
       "      <td>84.639</td>\n",
       "      <td>87.153</td>\n",
       "      <td>87.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>80.869</td>\n",
       "      <td>77.149</td>\n",
       "      <td>79.115</td>\n",
       "      <td>77.312</td>\n",
       "      <td>75.959000</td>\n",
       "      <td>76.989</td>\n",
       "      <td>77.876</td>\n",
       "      <td>73.028</td>\n",
       "      <td>77.583</td>\n",
       "      <td>77.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>74.328</td>\n",
       "      <td>71.870</td>\n",
       "      <td>74.722</td>\n",
       "      <td>76.409</td>\n",
       "      <td>68.962000</td>\n",
       "      <td>76.642</td>\n",
       "      <td>71.877</td>\n",
       "      <td>79.204</td>\n",
       "      <td>71.912</td>\n",
       "      <td>74.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>78.424</td>\n",
       "      <td>76.284</td>\n",
       "      <td>79.281</td>\n",
       "      <td>81.462</td>\n",
       "      <td>73.971000</td>\n",
       "      <td>83.659</td>\n",
       "      <td>79.182</td>\n",
       "      <td>85.703</td>\n",
       "      <td>81.677</td>\n",
       "      <td>81.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>61.758</td>\n",
       "      <td>61.112</td>\n",
       "      <td>63.056</td>\n",
       "      <td>64.353</td>\n",
       "      <td>58.241000</td>\n",
       "      <td>65.556</td>\n",
       "      <td>64.814</td>\n",
       "      <td>69.073</td>\n",
       "      <td>65.555</td>\n",
       "      <td>64.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>79.699</td>\n",
       "      <td>81.080</td>\n",
       "      <td>78.411</td>\n",
       "      <td>80.125</td>\n",
       "      <td>82.167778</td>\n",
       "      <td>78.300</td>\n",
       "      <td>74.803</td>\n",
       "      <td>79.329</td>\n",
       "      <td>75.924</td>\n",
       "      <td>77.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>83.859</td>\n",
       "      <td>79.771</td>\n",
       "      <td>82.875</td>\n",
       "      <td>84.310</td>\n",
       "      <td>77.248000</td>\n",
       "      <td>84.840</td>\n",
       "      <td>81.939</td>\n",
       "      <td>84.906</td>\n",
       "      <td>83.607</td>\n",
       "      <td>83.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>69.532</td>\n",
       "      <td>66.947</td>\n",
       "      <td>69.674</td>\n",
       "      <td>69.541</td>\n",
       "      <td>64.257000</td>\n",
       "      <td>70.488</td>\n",
       "      <td>69.733</td>\n",
       "      <td>70.463</td>\n",
       "      <td>70.137</td>\n",
       "      <td>69.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       0       0       0          0       0       0       0  \\\n",
       "P_test    89.144  75.112  87.339  86.770  80.465000  84.984  83.963  81.951   \n",
       "P_train   90.876  86.225  88.108  88.398  86.197000  86.516  86.571  84.639   \n",
       "P_ewo     80.869  77.149  79.115  77.312  75.959000  76.989  77.876  73.028   \n",
       "R_test    74.328  71.870  74.722  76.409  68.962000  76.642  71.877  79.204   \n",
       "R_train   78.424  76.284  79.281  81.462  73.971000  83.659  79.182  85.703   \n",
       "R_ewo     61.758  61.112  63.056  64.353  58.241000  65.556  64.814  69.073   \n",
       "F1-test   79.699  81.080  78.411  80.125  82.167778  78.300  74.803  79.329   \n",
       "F1-train  83.859  79.771  82.875  84.310  77.248000  84.840  81.939  84.906   \n",
       "F1-ewo    69.532  66.947  69.674  69.541  64.257000  70.488  69.733  70.463   \n",
       "\n",
       "               0       0  \n",
       "P_test    87.098  83.604  \n",
       "P_train   87.153  87.837  \n",
       "P_ewo     77.583  77.166  \n",
       "R_test    71.912  74.739  \n",
       "R_train   81.677  81.151  \n",
       "R_ewo     65.555  64.999  \n",
       "F1-test   75.924  77.824  \n",
       "F1-train  83.607  83.970  \n",
       "F1-ewo    70.137  69.896  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.to_csv(\"results/merge-{0}.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>84.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>87.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>77.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>74.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>80.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>63.851700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>78.766278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>82.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>69.066800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "P_test    84.043000\n",
       "P_train   87.252000\n",
       "P_ewo     77.304600\n",
       "R_test    74.066500\n",
       "R_train   80.079400\n",
       "R_ewo     63.851700\n",
       "F1-test   78.766278\n",
       "F1-train  82.732500\n",
       "F1-ewo    69.066800"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>4.105271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>1.684321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>2.017411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>2.977341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>3.431090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>2.973290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>2.235420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>2.465754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>1.963093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "P_test    4.105271\n",
       "P_train   1.684321\n",
       "P_ewo     2.017411\n",
       "R_test    2.977341\n",
       "R_train   3.431090\n",
       "R_ewo     2.973290\n",
       "F1-test   2.235420\n",
       "F1-train  2.465754\n",
       "F1-ewo    1.963093"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>98.060</td>\n",
       "      <td>97.696000</td>\n",
       "      <td>97.956000</td>\n",
       "      <td>98.073</td>\n",
       "      <td>97.652000</td>\n",
       "      <td>98.0800</td>\n",
       "      <td>97.854000</td>\n",
       "      <td>98.094</td>\n",
       "      <td>98.008000</td>\n",
       "      <td>98.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.233</td>\n",
       "      <td>97.036000</td>\n",
       "      <td>97.359000</td>\n",
       "      <td>97.629</td>\n",
       "      <td>96.769000</td>\n",
       "      <td>97.8960</td>\n",
       "      <td>97.351000</td>\n",
       "      <td>98.226</td>\n",
       "      <td>97.665000</td>\n",
       "      <td>97.5610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.912</td>\n",
       "      <td>98.403000</td>\n",
       "      <td>98.580000</td>\n",
       "      <td>98.539</td>\n",
       "      <td>98.607000</td>\n",
       "      <td>98.2760</td>\n",
       "      <td>98.387000</td>\n",
       "      <td>97.975</td>\n",
       "      <td>98.374000</td>\n",
       "      <td>98.4840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>75.375</td>\n",
       "      <td>73.316667</td>\n",
       "      <td>73.236000</td>\n",
       "      <td>73.694</td>\n",
       "      <td>74.680000</td>\n",
       "      <td>71.4760</td>\n",
       "      <td>74.650000</td>\n",
       "      <td>77.770</td>\n",
       "      <td>73.181000</td>\n",
       "      <td>72.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>97.460</td>\n",
       "      <td>81.844000</td>\n",
       "      <td>97.778000</td>\n",
       "      <td>94.028</td>\n",
       "      <td>84.773000</td>\n",
       "      <td>91.5260</td>\n",
       "      <td>80.884000</td>\n",
       "      <td>90.988</td>\n",
       "      <td>94.253000</td>\n",
       "      <td>95.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>62.979</td>\n",
       "      <td>58.543000</td>\n",
       "      <td>59.958000</td>\n",
       "      <td>63.776</td>\n",
       "      <td>57.634000</td>\n",
       "      <td>63.4730</td>\n",
       "      <td>59.837000</td>\n",
       "      <td>68.838</td>\n",
       "      <td>62.362000</td>\n",
       "      <td>61.4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>87.719</td>\n",
       "      <td>85.050000</td>\n",
       "      <td>87.463000</td>\n",
       "      <td>88.402</td>\n",
       "      <td>81.357000</td>\n",
       "      <td>89.3640</td>\n",
       "      <td>86.698000</td>\n",
       "      <td>88.848</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>88.5760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>91.056</td>\n",
       "      <td>86.681000</td>\n",
       "      <td>88.509000</td>\n",
       "      <td>88.949</td>\n",
       "      <td>86.145000</td>\n",
       "      <td>88.0320</td>\n",
       "      <td>88.755000</td>\n",
       "      <td>86.167</td>\n",
       "      <td>88.887000</td>\n",
       "      <td>88.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>85.372</td>\n",
       "      <td>84.599000</td>\n",
       "      <td>86.930000</td>\n",
       "      <td>88.607</td>\n",
       "      <td>80.904000</td>\n",
       "      <td>90.8100</td>\n",
       "      <td>85.640000</td>\n",
       "      <td>92.163</td>\n",
       "      <td>87.571000</td>\n",
       "      <td>89.1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>71.027</td>\n",
       "      <td>65.014444</td>\n",
       "      <td>72.408889</td>\n",
       "      <td>70.998</td>\n",
       "      <td>68.812222</td>\n",
       "      <td>71.4520</td>\n",
       "      <td>73.911111</td>\n",
       "      <td>72.420</td>\n",
       "      <td>73.184000</td>\n",
       "      <td>73.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>88.111</td>\n",
       "      <td>77.614000</td>\n",
       "      <td>77.105000</td>\n",
       "      <td>88.815</td>\n",
       "      <td>81.897000</td>\n",
       "      <td>83.1480</td>\n",
       "      <td>72.799000</td>\n",
       "      <td>78.604</td>\n",
       "      <td>80.504000</td>\n",
       "      <td>77.1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>61.638</td>\n",
       "      <td>54.321000</td>\n",
       "      <td>60.404000</td>\n",
       "      <td>62.465</td>\n",
       "      <td>54.839000</td>\n",
       "      <td>67.6050</td>\n",
       "      <td>65.114000</td>\n",
       "      <td>72.587</td>\n",
       "      <td>70.885000</td>\n",
       "      <td>61.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>33.335000</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>53.336</td>\n",
       "      <td>50.002500</td>\n",
       "      <td>50.0025</td>\n",
       "      <td>53.336000</td>\n",
       "      <td>33.335</td>\n",
       "      <td>44.446667</td>\n",
       "      <td>50.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          0          0       0          0        0          0  \\\n",
       "F1-O     98.060  97.696000  97.956000  98.073  97.652000  98.0800  97.854000   \n",
       "P-O      97.233  97.036000  97.359000  97.629  96.769000  97.8960  97.351000   \n",
       "R-O      98.912  98.403000  98.580000  98.539  98.607000  98.2760  98.387000   \n",
       "F1-MISC  75.375  73.316667  73.236000  73.694  74.680000  71.4760  74.650000   \n",
       "P-MISC   97.460  81.844000  97.778000  94.028  84.773000  91.5260  80.884000   \n",
       "R-MISC   62.979  58.543000  59.958000  63.776  57.634000  63.4730  59.837000   \n",
       "F1-PER   87.719  85.050000  87.463000  88.402  81.357000  89.3640  86.698000   \n",
       "P-PER    91.056  86.681000  88.509000  88.949  86.145000  88.0320  88.755000   \n",
       "R-PER    85.372  84.599000  86.930000  88.607  80.904000  90.8100  85.640000   \n",
       "F1-LOC   71.027  65.014444  72.408889  70.998  68.812222  71.4520  73.911111   \n",
       "P-LOC    88.111  77.614000  77.105000  88.815  81.897000  83.1480  72.799000   \n",
       "R-LOC    61.638  54.321000  60.404000  62.465  54.839000  67.6050  65.114000   \n",
       "F1-ORG    0.000  33.335000  44.446667  53.336  50.002500  50.0025  53.336000   \n",
       "P-ORG     0.000   5.000000  10.000000  20.000  15.000000  15.0000  20.000000   \n",
       "R-ORG     0.000  10.000000  20.000000  40.000  30.000000  30.0000  40.000000   \n",
       "\n",
       "              0          0        0  \n",
       "F1-O     98.094  98.008000  98.0130  \n",
       "P-O      98.226  97.665000  97.5610  \n",
       "R-O      97.975  98.374000  98.4840  \n",
       "F1-MISC  77.770  73.181000  72.0160  \n",
       "P-MISC   90.988  94.253000  95.1820  \n",
       "R-MISC   68.838  62.362000  61.4530  \n",
       "F1-PER   88.848  87.400000  88.5760  \n",
       "P-PER    86.167  88.887000  88.4940  \n",
       "R-PER    92.163  87.571000  89.1010  \n",
       "F1-LOC   72.420  73.184000  73.0700  \n",
       "P-LOC    78.604  80.504000  77.1450  \n",
       "R-LOC    72.587  70.885000  61.3170  \n",
       "F1-ORG   33.335  44.446667  50.0025  \n",
       "P-ORG     5.000  10.000000  15.0000  \n",
       "R-ORG    10.000  20.000000  30.0000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.to_csv(\"results/train-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.948600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>97.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>73.939467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>90.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>61.885300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>87.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>88.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>87.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>71.229767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>80.574200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>63.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>41.224283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.948600\n",
       "P-O      97.472500\n",
       "R-O      98.453700\n",
       "F1-MISC  73.939467\n",
       "P-MISC   90.871600\n",
       "R-MISC   61.885300\n",
       "F1-PER   87.087700\n",
       "P-PER    88.167500\n",
       "R-PER    87.169700\n",
       "F1-LOC   71.229767\n",
       "P-LOC    80.574200\n",
       "R-LOC    63.117500\n",
       "F1-ORG   41.224283\n",
       "P-ORG    11.500000\n",
       "R-ORG    23.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.161503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.419913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.243079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.797333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.235793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.218012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>2.357130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>1.504098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>3.259828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>2.620879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>5.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>6.085143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>16.224978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>6.687468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>13.374935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O      0.161503\n",
       "P-O       0.419913\n",
       "R-O       0.243079\n",
       "F1-MISC   1.797333\n",
       "P-MISC    6.235793\n",
       "R-MISC    3.218012\n",
       "F1-PER    2.357130\n",
       "P-PER     1.504098\n",
       "R-PER     3.259828\n",
       "F1-LOC    2.620879\n",
       "P-LOC     5.055100\n",
       "R-LOC     6.085143\n",
       "F1-ORG   16.224978\n",
       "P-ORG     6.687468\n",
       "R-ORG    13.374935"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.59500</td>\n",
       "      <td>97.042000</td>\n",
       "      <td>97.542000</td>\n",
       "      <td>97.516000</td>\n",
       "      <td>97.248000</td>\n",
       "      <td>97.528000</td>\n",
       "      <td>97.230000</td>\n",
       "      <td>97.382000</td>\n",
       "      <td>97.155000</td>\n",
       "      <td>97.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.62400</td>\n",
       "      <td>96.344000</td>\n",
       "      <td>96.650000</td>\n",
       "      <td>96.848000</td>\n",
       "      <td>95.886000</td>\n",
       "      <td>97.002000</td>\n",
       "      <td>96.547000</td>\n",
       "      <td>97.316000</td>\n",
       "      <td>96.297000</td>\n",
       "      <td>96.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.63100</td>\n",
       "      <td>97.864000</td>\n",
       "      <td>98.509000</td>\n",
       "      <td>98.238000</td>\n",
       "      <td>98.740000</td>\n",
       "      <td>98.127000</td>\n",
       "      <td>97.999000</td>\n",
       "      <td>97.490000</td>\n",
       "      <td>98.113000</td>\n",
       "      <td>97.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>51.66750</td>\n",
       "      <td>42.223333</td>\n",
       "      <td>42.223333</td>\n",
       "      <td>45.926667</td>\n",
       "      <td>42.223333</td>\n",
       "      <td>45.926667</td>\n",
       "      <td>42.223333</td>\n",
       "      <td>59.048571</td>\n",
       "      <td>42.223333</td>\n",
       "      <td>45.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>36.66700</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>31.667000</td>\n",
       "      <td>36.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>83.01400</td>\n",
       "      <td>86.758889</td>\n",
       "      <td>82.421000</td>\n",
       "      <td>85.524000</td>\n",
       "      <td>89.718889</td>\n",
       "      <td>84.413000</td>\n",
       "      <td>78.927000</td>\n",
       "      <td>83.191000</td>\n",
       "      <td>80.793000</td>\n",
       "      <td>82.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>87.44800</td>\n",
       "      <td>75.686000</td>\n",
       "      <td>86.381000</td>\n",
       "      <td>86.729000</td>\n",
       "      <td>80.699000</td>\n",
       "      <td>86.563000</td>\n",
       "      <td>86.714000</td>\n",
       "      <td>85.047000</td>\n",
       "      <td>87.507000</td>\n",
       "      <td>86.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>82.10800</td>\n",
       "      <td>81.452000</td>\n",
       "      <td>83.611000</td>\n",
       "      <td>86.275000</td>\n",
       "      <td>81.225000</td>\n",
       "      <td>87.020000</td>\n",
       "      <td>80.429000</td>\n",
       "      <td>84.747000</td>\n",
       "      <td>80.707000</td>\n",
       "      <td>82.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>62.38125</td>\n",
       "      <td>53.672857</td>\n",
       "      <td>74.150000</td>\n",
       "      <td>56.054286</td>\n",
       "      <td>53.333750</td>\n",
       "      <td>66.508333</td>\n",
       "      <td>61.430000</td>\n",
       "      <td>60.715000</td>\n",
       "      <td>54.338889</td>\n",
       "      <td>60.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>60.00000</td>\n",
       "      <td>36.666000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>38.333000</td>\n",
       "      <td>53.333000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>48.333000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>56.666000</td>\n",
       "      <td>46.666000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>44.16700</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>39.167000</td>\n",
       "      <td>44.167000</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>49.167000</td>\n",
       "      <td>44.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0          0          0          0          0          0  \\\n",
       "F1-O     97.59500  97.042000  97.542000  97.516000  97.248000  97.528000   \n",
       "P-O      96.62400  96.344000  96.650000  96.848000  95.886000  97.002000   \n",
       "R-O      98.63100  97.864000  98.509000  98.238000  98.740000  98.127000   \n",
       "F1-MISC  51.66750  42.223333  42.223333  45.926667  42.223333  45.926667   \n",
       "P-MISC   50.00000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "R-MISC   36.66700  31.667000  31.667000  36.667000  31.667000  36.667000   \n",
       "F1-PER   83.01400  86.758889  82.421000  85.524000  89.718889  84.413000   \n",
       "P-PER    87.44800  75.686000  86.381000  86.729000  80.699000  86.563000   \n",
       "R-PER    82.10800  81.452000  83.611000  86.275000  81.225000  87.020000   \n",
       "F1-LOC   62.38125  53.672857  74.150000  56.054286  53.333750  66.508333   \n",
       "P-LOC    60.00000  36.666000  60.000000  38.333000  53.333000  40.000000   \n",
       "R-LOC    44.16700  42.500000  47.500000  42.500000  39.167000  44.167000   \n",
       "F1-ORG    0.00000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "                 0          0          0          0  \n",
       "F1-O     97.230000  97.382000  97.155000  97.265000  \n",
       "P-O      96.547000  97.316000  96.297000  96.713000  \n",
       "R-O      97.999000  97.490000  98.113000  97.866000  \n",
       "F1-MISC  42.223333  59.048571  42.223333  45.926667  \n",
       "P-MISC   50.000000  50.000000  50.000000  50.000000  \n",
       "R-MISC   31.667000  36.667000  31.667000  36.667000  \n",
       "F1-PER   78.927000  83.191000  80.793000  82.598000  \n",
       "P-PER    86.714000  85.047000  87.507000  86.007000  \n",
       "R-PER    80.429000  84.747000  80.707000  82.588000  \n",
       "F1-LOC   61.430000  60.715000  54.338889  60.340000  \n",
       "P-LOC    48.333000  45.000000  56.666000  46.666000  \n",
       "R-LOC    46.667000  57.500000  49.167000  44.167000  \n",
       "F1-ORG    0.000000   0.000000   0.000000   0.000000  \n",
       "P-ORG     0.000000   0.000000   0.000000   0.000000  \n",
       "R-ORG     0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.to_csv(\"results/test-by-tag-merge-{0}.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>97.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>96.622700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>98.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.961274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>34.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>83.735878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>84.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>83.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>60.292437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>48.499700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>45.750200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-O     97.350300\n",
       "P-O      96.622700\n",
       "R-O      98.157700\n",
       "F1-MISC  45.961274\n",
       "P-MISC   50.000000\n",
       "R-MISC   34.167000\n",
       "F1-PER   83.735878\n",
       "P-PER    84.878100\n",
       "R-PER    83.016200\n",
       "F1-LOC   60.292437\n",
       "P-LOC    48.499700\n",
       "R-LOC    45.750200\n",
       "F1-ORG    0.000000\n",
       "P-ORG     0.000000\n",
       "R-ORG     0.000000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.189171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.396710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.385608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>5.514657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>2.635231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>3.059019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>3.781122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>2.325916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>6.516272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>8.729543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>5.006888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "F1-O     0.189171\n",
       "P-O      0.396710\n",
       "R-O      0.385608\n",
       "F1-MISC  5.514657\n",
       "P-MISC   0.000000\n",
       "R-MISC   2.635231\n",
       "F1-PER   3.059019\n",
       "P-PER    3.781122\n",
       "R-PER    2.325916\n",
       "F1-LOC   6.516272\n",
       "P-LOC    8.729543\n",
       "R-LOC    5.006888\n",
       "F1-ORG   0.000000\n",
       "P-ORG    0.000000\n",
       "R-ORG    0.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.1500</td>\n",
       "      <td>43.6825</td>\n",
       "      <td>43.682500</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.15000</td>\n",
       "      <td>46.150</td>\n",
       "      <td>43.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.43100</td>\n",
       "      <td>95.075000</td>\n",
       "      <td>94.737000</td>\n",
       "      <td>94.9000</td>\n",
       "      <td>94.9640</td>\n",
       "      <td>95.227000</td>\n",
       "      <td>94.91800</td>\n",
       "      <td>94.86800</td>\n",
       "      <td>95.157</td>\n",
       "      <td>95.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>8.57625</td>\n",
       "      <td>47.702857</td>\n",
       "      <td>28.391429</td>\n",
       "      <td>32.1575</td>\n",
       "      <td>34.5975</td>\n",
       "      <td>39.691111</td>\n",
       "      <td>34.62875</td>\n",
       "      <td>31.67875</td>\n",
       "      <td>42.050</td>\n",
       "      <td>41.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>70.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.54000</td>\n",
       "      <td>91.146000</td>\n",
       "      <td>90.138000</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>90.7090</td>\n",
       "      <td>91.122000</td>\n",
       "      <td>90.53800</td>\n",
       "      <td>90.38400</td>\n",
       "      <td>91.105</td>\n",
       "      <td>91.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>53.63800</td>\n",
       "      <td>51.554000</td>\n",
       "      <td>57.193000</td>\n",
       "      <td>63.3810</td>\n",
       "      <td>66.7380</td>\n",
       "      <td>77.824000</td>\n",
       "      <td>66.39100</td>\n",
       "      <td>68.14200</td>\n",
       "      <td>66.391</td>\n",
       "      <td>75.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.89000</td>\n",
       "      <td>99.379000</td>\n",
       "      <td>99.835000</td>\n",
       "      <td>99.7590</td>\n",
       "      <td>99.6610</td>\n",
       "      <td>99.725000</td>\n",
       "      <td>99.74800</td>\n",
       "      <td>99.82400</td>\n",
       "      <td>99.608</td>\n",
       "      <td>99.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>19.1250</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17.62500</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>24.375</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        0.1        0.2      0.3      0.4        0.5  \\\n",
       "F1-LOC        NaN        NaN        NaN      NaN      NaN  17.380000   \n",
       "F1-MISC  46.15000  46.150000  46.150000  46.1500  43.6825  43.682500   \n",
       "F1-O     94.43100  95.075000  94.737000  94.9000  94.9640  95.227000   \n",
       "F1-ORG        NaN        NaN        NaN      NaN      NaN        NaN   \n",
       "F1-PER    8.57625  47.702857  28.391429  32.1575  34.5975  39.691111   \n",
       "P-LOC     0.00000   0.000000   0.000000   0.0000   0.0000  60.000000   \n",
       "P-MISC   70.00000  60.000000  60.000000  70.0000  65.0000  65.000000   \n",
       "P-O      89.54000  91.146000  90.138000  90.5000  90.7090  91.122000   \n",
       "P-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "P-PER    53.63800  51.554000  57.193000  63.3810  66.7380  77.824000   \n",
       "R-LOC     0.00000   0.000000   0.000000   0.0000   0.0000   5.712000   \n",
       "R-MISC   21.00000  18.000000  18.000000  21.0000  24.0000  24.000000   \n",
       "R-O      99.89000  99.379000  99.835000  99.7590  99.6610  99.725000   \n",
       "R-ORG     0.00000   0.000000   0.000000   0.0000   0.0000   0.000000   \n",
       "R-PER     4.00000  25.000000  12.250000  16.7500  19.1250  23.500000   \n",
       "\n",
       "              0.6       0.7     0.8        0.9  \n",
       "F1-LOC        NaN       NaN     NaN  17.380000  \n",
       "F1-MISC  46.15000  46.15000  46.150  43.591111  \n",
       "F1-O     94.91800  94.86800  95.157  95.299000  \n",
       "F1-ORG        NaN       NaN     NaN        NaN  \n",
       "F1-PER   34.62875  31.67875  42.050  41.984444  \n",
       "P-LOC     0.00000   0.00000   0.000  60.000000  \n",
       "P-MISC   60.00000  60.00000  80.000  72.500000  \n",
       "P-O      90.53800  90.38400  91.105  91.426000  \n",
       "P-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "P-PER    66.39100  68.14200  66.391  75.073000  \n",
       "R-LOC     0.00000   0.00000   0.000   5.712000  \n",
       "R-MISC   18.00000  18.00000  24.000  27.000000  \n",
       "R-O      99.74800  99.82400  99.608  99.531000  \n",
       "R-ORG     0.00000   0.00000   0.000   0.000000  \n",
       "R-PER    17.62500  15.75000  24.375  26.875000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult = pd.read_csv(\"results/ewo-by-tag-merge-{0}.csv\".format(2), index_col=0)\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>45.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>34.145859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>66.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>90.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>64.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>1.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>99.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>18.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC   17.380000\n",
       "F1-MISC  45.400611\n",
       "F1-O     94.957600\n",
       "F1-ORG         NaN\n",
       "F1-PER   34.145859\n",
       "P-LOC    12.000000\n",
       "P-MISC   66.250000\n",
       "P-O      90.660800\n",
       "P-ORG     0.000000\n",
       "P-PER    64.632500\n",
       "R-LOC     1.142400\n",
       "R-MISC   21.300000\n",
       "R-O      99.696000\n",
       "R-ORG     0.000000\n",
       "R-PER    18.525000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>1.206887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>10.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>25.298221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>6.795628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.565721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>8.529639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>2.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>3.301515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.155470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>6.936167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "F1-LOC    0.000000\n",
       "F1-MISC   1.206887\n",
       "F1-O      0.254209\n",
       "F1-ORG         NaN\n",
       "F1-PER   10.728242\n",
       "P-LOC    25.298221\n",
       "P-MISC    6.795628\n",
       "P-O       0.565721\n",
       "P-ORG     0.000000\n",
       "P-PER     8.529639\n",
       "R-LOC     2.408391\n",
       "R-MISC    3.301515\n",
       "R-O       0.155470\n",
       "R-ORG     0.000000\n",
       "R-PER     6.936167"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\tReal\tFreq\tWord\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-4a85ba04e569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_fingerprints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreal_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ne-tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env/nn-ne-projection/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                              'argument.')\n\u001b[1;32m   1151\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env/nn-ne-projection/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env/nn-ne-projection/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected hidden1_input to have 2 dimensions, but got array with shape (1, 1, 210)"
     ]
    }
   ],
   "source": [
    "columns = en_fingerprints.columns\n",
    "\n",
    "print(\"Pred\", \"Real\", \"Freq\", \"Word\", sep=\"\\t\")\n",
    "for c in columns:\n",
    "    prediction = model.predict(en_fingerprints[c].values.reshape((1, 1, 210)))\n",
    "    pred_tag = int2tag[np.argmax(prediction)]\n",
    "    real_tag = en_corpus[en_corpus.word == c].iloc[0]['ne-tag']\n",
    "    \n",
    "    if pred_tag != real_tag:\n",
    "        print(pred_tag, real_tag, en_fingerprints[c].max(), c, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
