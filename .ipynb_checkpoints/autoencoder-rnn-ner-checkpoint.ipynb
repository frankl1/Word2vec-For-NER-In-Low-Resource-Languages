{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1516045322673,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "NamUCuj1bBjd",
    "outputId": "7874258f-7c3e-4646-f238-36437759767b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import keras\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "BINARY = False\n",
    "timestep = 1\n",
    "epochs = 10\n",
    "en_corpus_file = \"corpus-en.txt\"\n",
    "ewo_corpus_file = \"corpus-ewo.txt\"\n",
    "best_model_file = \"best-model-conll.hdfs\"\n",
    "max_nb_of_phrases =  -1\n",
    "duplication = 1\n",
    "max_depth = 0\n",
    "is_only_vocab = True\n",
    "time_history_default = None\n",
    "time_history_autoencoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9h7fyDCbkMG"
   },
   "outputs": [],
   "source": [
    "with_encoding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def getTag(aString):\n",
    "    tag = \"O\"\n",
    "    if BINARY:\n",
    "        if aString != \"O\":\n",
    "            return \"NE\"\n",
    "    else:\n",
    "        tag = aString\n",
    "    return tag\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def load_corpus(file, max_nb_of_phrases):\n",
    "    nb_of_phrases = 0\n",
    "    dataset = {\"word\": [], \"ne-tag\": []}\n",
    "    with open(file) as f:\n",
    "        prev_line = None\n",
    "        for cpt, line in enumerate(f):\n",
    "            if cpt == 0:\n",
    "                continue\n",
    "            if nb_of_phrases == max_nb_of_phrases:\n",
    "                break;\n",
    "\n",
    "            l = line.strip()\n",
    "            if len(l) == 0 and len(prev_line) != 0:\n",
    "                nb_of_phrases += 1\n",
    "                dataset[\"word\"].append(line)\n",
    "                dataset[\"ne-tag\"].append(None)\n",
    "            else:\n",
    "                l = l.split(\"\\t\")\n",
    "                dataset[\"word\"].append(l[0])\n",
    "                dataset[\"ne-tag\"].append(ne_type(l[1]))\n",
    "            prev_line = line.strip()\n",
    "        \n",
    "    return pd.DataFrame(dataset), nb_of_phrases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus_fingerprint(aDataframe, nb_of_biphrases):\n",
    "    # create distributionnal signature\n",
    "    fingerprints = {}\n",
    "    current_bi_phrase_index = 0\n",
    "    for index, row in aDataframe.iterrows():\n",
    "        if current_bi_phrase_index > nb_of_biphrases:\n",
    "            break\n",
    "            \n",
    "        word = row['word']\n",
    "        \n",
    "        if word != \"\\n\":\n",
    "            if word not in fingerprints:\n",
    "                fingerprints[word] = np.zeros(nb_of_biphrases, dtype=np.int8)\n",
    "            fingerprints[word][current_bi_phrase_index] = 1\n",
    "        else:\n",
    "            current_bi_phrase_index += 1\n",
    "    return pd.DataFrame(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def corpus2trainingdata(aDataframe, fingerprintsDataFrame):\n",
    "    X = np.zeros((aDataframe.shape[0], fingerprintsDataFrame.shape[0]), dtype=np.int8)\n",
    "    y = np.zeros(aDataframe.shape[0], dtype=np.int8)\n",
    "    i = 0\n",
    "    for row in aDataframe.iterrows():\n",
    "        X[i] = fingerprintsDataFrame[row[1]['word']].values\n",
    "        y[i] = tag2int[getTag(row[1]['ne-tag'])]\n",
    "        i += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size = 0.33):\n",
    "    total = X.shape[0]\n",
    "    train_length = round(total * (1 - test_size)) \n",
    "    return X[:train_length], X[train_length:], y[:train_length], y[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def ne_type(aType):\n",
    "    aType = aType.lower()\n",
    "    if 'per' in aType:\n",
    "        t =  'NE' if BINARY else 'PER' \n",
    "    elif 'loc' in aType:\n",
    "        t =  'NE' if BINARY else 'LOC'\n",
    "    elif 'org' in aType:\n",
    "        t =  'NE' if BINARY else 'ORG'\n",
    "    elif 'hour' in aType:\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    elif aType != 'o' and len(aType) > 0 :\n",
    "        t =  'NE' if BINARY else 'MISC'\n",
    "    else:\n",
    "        t = 'O'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred, words=None, BINARY=False):\n",
    "    if BINARY:\n",
    "        p = precision_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        r = recall_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=tag2int['NE'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "    else:\n",
    "        p = precision_score(y_pred, y_true, average='macro')\n",
    "        r = recall_score(y_pred, y_true, average='macro')\n",
    "        f1 = f1_score(y_pred, y_true, average='macro')\n",
    "        acc = accuracy_score(y_pred, y_true)\n",
    "    if words is None:\n",
    "        model_output_vs = pd.DataFrame({'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "    else:\n",
    "        model_output_vs = pd.DataFrame({'word': words, 'y_true': [int2tag[i] for i in y_true], 'y_pred': [int2tag[i] for i in y_pred]})\n",
    "\n",
    "    return p, r, f1, acc, model_output_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def P_R_F1(y_pred, y_true, neg_class):\n",
    "    same = y_pred[y_true==y_pred]\n",
    "    tp = same[same != neg_class].size\n",
    "    nb_of_pos_exple = y_true[y_true != neg_class].size\n",
    "    nb_of_pos_pred = y_pred[y_pred != neg_class].size\n",
    "    p = r = f1 = 0\n",
    "    try:\n",
    "        p = np.round(tp*100/nb_of_pos_pred, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of correct positive predictions is 0\")\n",
    "        \n",
    "    try:\n",
    "        r = np.round(tp*100/nb_of_pos_exple, 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"number of position exple is 0\")\n",
    "        \n",
    "    try:\n",
    "        f1 = np.round(2*r*p/(r+p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Recall and precision are 0\")\n",
    "\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mergeable(aListOfConsecutiveTokens, corpus, fingerprints):\n",
    "    n = len(aListOfConsecutiveTokens)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        w1, w2 = aListOfConsecutiveTokens[0], aListOfConsecutiveTokens[1]\n",
    "        rep1, rep2 = fingerprints[aListOfConsecutiveTokens[0]], fingerprints[aListOfConsecutiveTokens[1]]\n",
    "        tag1, tag2 = corpus[corpus.word==w1].iloc[0]['ne-tag'], corpus[corpus.word==w2].iloc[0]['ne-tag']\n",
    "        if (tag1 == tag2) and (tag1 == \"O\"): # O + O => False\n",
    "            return False\n",
    "        if (tag1 != tag2) and (tag1 != \"O\") and (tag2 != \"O\"): # X + Y => False\n",
    "            return False\n",
    "        return rep1.equals(rep2)\n",
    "    else:\n",
    "        half = int(n / 2)\n",
    "        return is_mergeable(aListOfConsecutiveTokens[0:half+1], corpus, fingerprints) and is_mergeable(aListOfConsecutiveTokens[half:n], corpus, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q1OlcYPo1Att"
   },
   "outputs": [],
   "source": [
    "def merge(depth, corpus, fingerprint):\n",
    "    wordDf = corpus[corpus.word != \"\\n\"].word\n",
    "    nbOfWord = wordDf.shape[0]\n",
    "    text = list(wordDf)\n",
    "    X2, target2, tokens = [], [], []\n",
    "    level, newToken = 1, True\n",
    "    while level <= depth and newToken:\n",
    "        i, newToken = 0, False\n",
    "        limit = nbOfWord - level\n",
    "        while i < limit:\n",
    "            if is_mergeable(text[i:i+level+1], corpus, fingerprint):\n",
    "                tokens.append(\" \".join(text[i:i+level+1]))\n",
    "                newToken = True\n",
    "            i += 1\n",
    "        print(\"level \", level, \":\", set(tokens))\n",
    "        level += 1\n",
    "    \n",
    "    X2, target2 = np.array(X2), np.array(target2)\n",
    "    \n",
    "    return X2, target2, set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = [i for i in  range(X.shape[0])]\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "def create_and_train_autoencoder(X_train, code_dim, epochs=10):\n",
    "    input_data = Input(shape=(X_train.shape[1],))\n",
    "    encoded = Dense(code_dim, activation=\"sigmoid\")(input_data)\n",
    "    decoded = Dense(X_train.shape[1], activation=\"sigmoid\")(encoded)\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\")\n",
    "    autoencoder.fit(X_train, X_train, shuffle=True, epochs=epochs, validation_data=(X_train, X_train))\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNN2TBckE8m_"
   },
   "outputs": [],
   "source": [
    "en_corpus, en_nb_of_phrases = load_corpus(en_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'MISC': 1, 'PER': 2, 'LOC': 3, 'ORG': 4}\n"
     ]
    }
   ],
   "source": [
    "tagSet = en_corpus[\"ne-tag\"].dropna().unique()\n",
    "if BINARY:\n",
    "    tagSet = ['NE', 'O']\n",
    "tag2int = {j: i for i, j in enumerate(tagSet)}\n",
    "int2tag = {i: j for i, j in enumerate(tagSet)}\n",
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1515664141558,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "m85WcghdzCph",
    "outputId": "9fa6817e-15c4-4205-f8f4-82c30c2cb610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1515664144298,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Gw9r-Q9jlmvg",
    "outputId": "8ee33794-5639-4c97-ea43-06a66d89e207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4753</td>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4362</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ne-tag  word\n",
       "count    4753  4962\n",
       "unique      5   913\n",
       "top         O     ,\n",
       "freq     4362   343"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1515664147270,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "EZ_5FqH3yxhU",
    "outputId": "a129592b-9fa2-4937-a35a-a73245aef4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>Promise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Holy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Spirit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O</td>\n",
       "      <td>In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ne-tag     word\n",
       "0      O      The\n",
       "1      O  Promise\n",
       "2      O       of\n",
       "3      O      the\n",
       "4   MISC     Holy\n",
       "5   MISC   Spirit\n",
       "6   None       \\n\n",
       "7      O       In\n",
       "8      O      the\n",
       "9      O    first"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 87.91 %\n",
      "MISC % = 2.12 %\n",
      "PER % = 4.94 %\n",
      "LOC % = 0.81 %\n",
      "ORG % = 0.02 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 89.27 %\n",
      "MISC % = 1.86 %\n",
      "PER % = 8.87 %\n",
      "LOC % = 1.97 %\n",
      "ORG % = 0.11 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(en_corpus[en_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / en_corpus[en_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word == \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of bi-phrases 210\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of bi-phrases\", en_nb_of_phrases)\n",
    "en_fingerprints = corpus_fingerprint(en_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus[en_corpus.word != \"\\n\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, en_corpus, en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "count    912\n",
       "unique   912\n",
       "top     Lord\n",
       "freq       1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(en_corpus[en_corpus.word != \"\\n\"].word)\n",
    "en_vocab = pd.DataFrame({'text': text + list(tokens)})\n",
    "en_vocab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40378,
     "status": "ok",
     "timestamp": 1515671247748,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Mx1Yl-Npvh12",
    "outputId": "29d26922-46c0-47b6-9d1b-26ac26b118d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (210, 912) (912,)\n"
     ]
    }
   ],
   "source": [
    "if is_only_vocab:\n",
    "    X = np.zeros((en_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    target = np.zeros((en_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in en_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X[p] = en_fingerprints[c.split(\" \")[0]]\n",
    "            target[p] = tag2int[getTag(en_corpus[en_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X, target = shuffle(X, target)\n",
    "    print(X.shape, en_fingerprints.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Eliud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Eleazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Matthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>fulfill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Immanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "892       Eliud\n",
       "893     Eleazar\n",
       "894     Matthan\n",
       "895     husband\n",
       "896    fourteen\n",
       "897   unwilling\n",
       "898       shame\n",
       "899    resolved\n",
       "900     divorce\n",
       "901     quietly\n",
       "902  considered\n",
       "903       dream\n",
       "904         She\n",
       "905        save\n",
       "906     fulfill\n",
       "907    Immanuel\n",
       "908         us)\n",
       "909        woke\n",
       "910       sleep\n",
       "911        knew"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X, target = corpus2trainingdata(en_corpus[en_corpus.word != \"\\n\"], en_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 210) (912,)\n",
      "(912, 210) (912,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, target.shape)\n",
    "if len(X.shape) == len(X2.shape):\n",
    "    X = np.concatenate((X, X2))\n",
    "    target = np.concatenate((target, target2))\n",
    "    X, target = shuffle(X, target)\n",
    "print(X.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 912 samples, validate on 912 samples\n",
      "Epoch 1/20\n",
      "912/912 [==============================] - 0s 195us/step - loss: 0.7033 - val_loss: 0.6987\n",
      "Epoch 2/20\n",
      "912/912 [==============================] - 0s 161us/step - loss: 0.6945 - val_loss: 0.6900\n",
      "Epoch 3/20\n",
      "912/912 [==============================] - 0s 157us/step - loss: 0.6859 - val_loss: 0.6814\n",
      "Epoch 4/20\n",
      "912/912 [==============================] - 0s 115us/step - loss: 0.6774 - val_loss: 0.6730\n",
      "Epoch 5/20\n",
      "912/912 [==============================] - 0s 98us/step - loss: 0.6691 - val_loss: 0.6648\n",
      "Epoch 6/20\n",
      "912/912 [==============================] - 0s 169us/step - loss: 0.6609 - val_loss: 0.6567\n",
      "Epoch 7/20\n",
      "912/912 [==============================] - 0s 180us/step - loss: 0.6529 - val_loss: 0.6487\n",
      "Epoch 8/20\n",
      "912/912 [==============================] - 0s 171us/step - loss: 0.6450 - val_loss: 0.6409\n",
      "Epoch 9/20\n",
      "912/912 [==============================] - 0s 103us/step - loss: 0.6373 - val_loss: 0.6333\n",
      "Epoch 10/20\n",
      "912/912 [==============================] - 0s 103us/step - loss: 0.6297 - val_loss: 0.6258\n",
      "Epoch 11/20\n",
      "912/912 [==============================] - 0s 162us/step - loss: 0.6223 - val_loss: 0.6184\n",
      "Epoch 12/20\n",
      "912/912 [==============================] - 0s 194us/step - loss: 0.6149 - val_loss: 0.6111\n",
      "Epoch 13/20\n",
      "912/912 [==============================] - 0s 186us/step - loss: 0.6077 - val_loss: 0.6040\n",
      "Epoch 14/20\n",
      "912/912 [==============================] - 0s 197us/step - loss: 0.6007 - val_loss: 0.5970\n",
      "Epoch 15/20\n",
      "912/912 [==============================] - 0s 177us/step - loss: 0.5937 - val_loss: 0.5901\n",
      "Epoch 16/20\n",
      "912/912 [==============================] - 0s 195us/step - loss: 0.5869 - val_loss: 0.5834\n",
      "Epoch 17/20\n",
      "912/912 [==============================] - 0s 201us/step - loss: 0.5802 - val_loss: 0.5768\n",
      "Epoch 18/20\n",
      "912/912 [==============================] - 0s 103us/step - loss: 0.5737 - val_loss: 0.5703\n",
      "Epoch 19/20\n",
      "912/912 [==============================] - 0s 110us/step - loss: 0.5672 - val_loss: 0.5639\n",
      "Epoch 20/20\n",
      "912/912 [==============================] - 0s 107us/step - loss: 0.5609 - val_loss: 0.5576\n"
     ]
    }
   ],
   "source": [
    "#encoding\n",
    "encoder = None\n",
    "if with_encoding:\n",
    "    encoder = create_and_train_autoencoder(X_train=X, code_dim=105, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5211265  0.5007705  0.48045832 0.46695423 0.5013819  0.5110806\n",
      " 0.4892157  0.49492922 0.5141073  0.4907691  0.49917176 0.4919977\n",
      " 0.48330146 0.49402916 0.47615057 0.50871265 0.49408615 0.47685164\n",
      " 0.49098873 0.5062708  0.4751904  0.48350462 0.4691016  0.48240003\n",
      " 0.4732721  0.5227527  0.49278572 0.51308554 0.46921358 0.5046807\n",
      " 0.49613118 0.5050585  0.53322744 0.5327735  0.48609406 0.5270021\n",
      " 0.49062496 0.5325807  0.4712937  0.53323525 0.5091743  0.52026105\n",
      " 0.51255244 0.48532775 0.51352906 0.47419164 0.48523787 0.5315397\n",
      " 0.49447408 0.47977334 0.534224   0.52416867 0.49683645 0.47905055\n",
      " 0.5243849  0.5168504  0.50817245 0.48420277 0.49042907 0.49662575\n",
      " 0.49234915 0.49057162 0.49899086 0.47510254 0.4867539  0.4895171\n",
      " 0.48784363 0.48337126 0.48882484 0.47295913 0.48417526 0.47215062\n",
      " 0.5110909  0.48278385 0.51594007 0.4765113  0.52458596 0.53033274\n",
      " 0.47278726 0.5340229  0.5275985  0.5149643  0.5170001  0.4898818\n",
      " 0.5262383  0.4814509  0.4987726  0.5237311  0.47255147 0.50864685\n",
      " 0.52639025 0.49042034 0.5306118  0.48777723 0.47607952 0.50984555\n",
      " 0.48502848 0.473995   0.4710461  0.52710307 0.5263417  0.49538305\n",
      " 0.47290248 0.47917223 0.48670286]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "if with_encoding:\n",
    "    X_encoded = encoder.predict(X)\n",
    "    print(X_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1515671250872,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "HLn_an5ExZSC",
    "outputId": "382c3159-7917-40e3-e469-27c244d86663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target.copy()\n",
    "y[0:100]\n",
    "if not BINARY:\n",
    "    y = np_utils.to_categorical(y, len(tagSet))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1515671252070,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "sF3M9I53xlY1",
    "outputId": "8d011439-2df0-4440-b334-7e21e44c2208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (611, 1, 105)\n",
      "y_train.shape = (611, 5)\n",
      "X_val.shape = (301, 1, 105)\n",
      "y_val.shape = (301, 5)\n",
      "O % in training data = 88.54 %\n",
      "O % in validation data = 88.04 %\n",
      "MISC % in training data = 1.64 %\n",
      "MISC % in validation data = 0.33 %\n",
      "PER % in training data = 7.53 %\n",
      "PER % in validation data = 10.3 %\n",
      "LOC % in training data = 2.13 %\n",
      "LOC % in validation data = 1.33 %\n",
      "ORG % in training data = 0.16 %\n",
      "ORG % in validation data = 0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_encoded, y, test_size=0.33)\n",
    "X_train = X_train.reshape(X_train.shape[0], timestep, X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], timestep, X_val.shape[1])\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_val.shape =\", X_val.shape)\n",
    "print(\"y_val.shape =\", y_val.shape)\n",
    "\n",
    "tTarget = np.array([np.argmax(yy) for yy in y_train])\n",
    "vTarget = np.array([np.argmax(yy) for yy in y_val])\n",
    "\n",
    "for tag in tagSet:\n",
    "    print(\"{0} % in training data = {1} %\".format(tag, np.round(tTarget[tTarget==tag2int[tag]].size * 100 / tTarget.shape[0], 2)))\n",
    "    print(\"{0} % in validation data = {1} %\".format(tag, np.round(vTarget[vTarget==tag2int[tag]].size * 100 / vTarget.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1515671862146,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "cvpl6zMzxm6X",
    "outputId": "ef520c78-0fd3-494a-defd-fb3e2f01d371"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(640, input_shape=(None, input_dim), activation='sigmoid'))\n",
    "    model.add(Dense(160, activation='sigmoid'))\n",
    "    if BINARY:\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "output_extras": [
      {
       "item_id": 99
      },
      {
       "item_id": 223
      },
      {
       "item_id": 284
      },
      {
       "item_id": 347
      },
      {
       "item_id": 394
      },
      {
       "item_id": 445
      },
      {
       "item_id": 490
      },
      {
       "item_id": 542
      },
      {
       "item_id": 590
      },
      {
       "item_id": 639
      },
      {
       "item_id": 684
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676115,
     "status": "ok",
     "timestamp": 1515672664054,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "uY2-NcCZxpXe",
    "outputId": "adcd5c23-d0c6-463a-bc11-db5d415eba1d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=epochs):\n",
    "    time_history_cb = TimeHistory()\n",
    "    best_model_cp = ModelCheckpoint(best_model_file, save_best_only=True, verbose=2) # saved best model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, callbacks=[best_model_cp, time_history_cb])\n",
    "    best_model = keras.models.load_model(best_model_file) #loading the best model\n",
    "    return best_model, time_history_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, binary=BINARY):\n",
    "    if BINARY:\n",
    "        y_pred = np.round(model.predict(X))\n",
    "        y_true = y\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        y_pred = np.array([np.argmax(p) for p in predictions])\n",
    "        y_true = np.array([np.argmax(t) for t in y ])\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23179,
     "status": "ok",
     "timestamp": 1515672689915,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "N33cmgKEyPOb",
    "outputId": "917cdaec-b68c-47d5-a8ea-bd6ef7387a67"
   },
   "outputs": [],
   "source": [
    "def model_performance(y_true, y_pred):\n",
    "    return P_R_F1(y_pred, y_true, tag2int['O']) #precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace_by_tag(y_true, y_pred, tag):\n",
    "    p, r, f1 = 0, 0, 0\n",
    "    \n",
    "    eq = y_pred[y_pred==y_true]\n",
    "    correctly_pred = eq[eq==tag].size\n",
    "    try:\n",
    "        p = np.round(100 * correctly_pred / y_pred[y_pred==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        r = np.round(100 * correctly_pred / y_true[y_true==tag].size, 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        f1 = np.round(2 * r * p / (r + p), 2)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [],
   "source": [
    "ewo_corpus, ewo_nb_of_phrases = load_corpus(ewo_corpus_file, max_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_nb_of_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 86.37 %\n",
      "MISC % = 2.18 %\n",
      "PER % = 5.76 %\n",
      "LOC % = 0.89 %\n",
      "ORG % = 0.05 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O % = 90.0 %\n",
      "MISC % = 1.17 %\n",
      "PER % = 8.25 %\n",
      "LOC % = 1.84 %\n",
      "ORG % = 0.19 %\n"
     ]
    }
   ],
   "source": [
    "for tag in tagSet:\n",
    "    print(\"{0} % = {1} %\".format(tag, np.round(ewo_corpus[ewo_corpus['ne-tag']==tag].word.unique().shape[0] * 100 / ewo_corpus[ewo_corpus['ne-tag']!='\\n'].word.unique().shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4185</td>\n",
       "      <td>4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3795</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ne-tag  word\n",
       "count    4185  4394\n",
       "unique      5  1030\n",
       "top         O     ,\n",
       "freq     3795   413"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1515664313240,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "OObRLXTr268N",
    "outputId": "6361a898-fd04-4e15-8aa7-936a12b3221a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne-tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Mfufub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Nsisim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>ayi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>sò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ne-tag    word\n",
       "0   MISC  Mfufub\n",
       "1   MISC  Nsisim\n",
       "2      O     ayi\n",
       "3      O      sò\n",
       "4   None      \\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "ewo_fingerprints = corpus_fingerprint(ewo_corpus, en_nb_of_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "X2, target2, tokens = merge(max_depth, ewo_corpus, ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word.unique())\n",
    "else:\n",
    "    text = list(ewo_corpus[ewo_corpus.word != \"\\n\"].word)\n",
    "ewo_vocab = pd.DataFrame({\"text\":text + list(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "error",
     "timestamp": 1515688720429,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "aRDNM0C8yX5N",
    "outputId": "b5a14626-4a9b-484c-c597-f1b1f37673c9"
   },
   "outputs": [],
   "source": [
    "if is_only_vocab:\n",
    "    X_ewo = np.zeros((ewo_vocab.shape[0] * duplication, en_nb_of_phrases))\n",
    "    ewo_target = np.zeros((ewo_vocab.shape[0] * duplication))\n",
    "    p=0\n",
    "    for i, row in ewo_vocab.iterrows():\n",
    "        c = row.text\n",
    "        for j in range(duplication):\n",
    "            X_ewo[p] = ewo_fingerprints[c.split(\" \")[0]]\n",
    "            ewo_target[p] = tag2int[getTag(ewo_corpus[ewo_corpus.word == c.split(\" \")[-1:][0]]['ne-tag'].iloc[0])]\n",
    "            p+=1\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>nlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>obë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>mbara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>yabyali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>dzili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>yasò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>oyolëge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>dili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>atoban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>sik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Ntud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>bëyole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Emmanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Avëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>angavëbë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>oyò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>angabende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>anganòṅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>angayole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "1009        nlo\n",
       "1010        obë\n",
       "1011      mbara\n",
       "1012    yabyali\n",
       "1013      dzili\n",
       "1014       yasò\n",
       "1015    oyolëge\n",
       "1016       kode\n",
       "1017       dili\n",
       "1018     atoban\n",
       "1019        sik\n",
       "1020       Ntud\n",
       "1021     bëyole\n",
       "1022   Emmanuel\n",
       "1023      Avëbë\n",
       "1024   angavëbë\n",
       "1025        oyò\n",
       "1026  angabende\n",
       "1027    anganòṅ\n",
       "1028   angayole"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewo_vocab[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_only_vocab:\n",
    "    X_ewo, ewo_target = corpus2trainingdata(ewo_corpus[ewo_corpus.word != \"\\n\"], ewo_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 210) (1029,)\n",
      "(1029, 210) (1029,)\n"
     ]
    }
   ],
   "source": [
    "print(X_ewo.shape, ewo_target.shape)\n",
    "if len(X_ewo.shape) == len(X2.shape):\n",
    "    X_ewo = np.concatenate((X_ewo, X2))\n",
    "    ewo_target = np.concatenate((ewo_target, target2))\n",
    "    X_ewo, ewo_target = shuffle(X_ewo, ewo_target)\n",
    "print(X_ewo.shape, ewo_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 105)\n"
     ]
    }
   ],
   "source": [
    "X_ewo_encoded = X_ewo.copy()\n",
    "if with_encoding:\n",
    "    X_ewo_encoded = encoder.predict(X_ewo)\n",
    "    print(X_ewo_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029,) 1029\n"
     ]
    }
   ],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "print(y_ewo.shape, len(ewo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1514134592547,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "fuSYSwUPDiQY",
    "outputId": "658c1a63-1a76-4487-e151-47364c6dbc85"
   },
   "outputs": [],
   "source": [
    "y_ewo = ewo_target.copy()\n",
    "y_ewo[:20]\n",
    "if not BINARY:\n",
    "    y_ewo = np_utils.to_categorical(y_ewo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6835,
     "status": "ok",
     "timestamp": 1514134601113,
     "user": {
      "displayName": "Michael Franklin Mbouopda",
      "photoUrl": "//lh3.googleusercontent.com/-2_Vuj9ESsJ0/AAAAAAAAAAI/AAAAAAAABSc/r-SRcN0jWPw/s50-c-k-no/photo.jpg",
      "userId": "117384351130599115261"
     },
     "user_tz": -60
    },
    "id": "Cev5j8YFzPYl",
    "outputId": "87ab5b4b-a75d-43b0-d346-5ba18a4522c0"
   },
   "outputs": [],
   "source": [
    "X_ewo_encoded = X_ewo_encoded.reshape((X_ewo.shape[0], timestep, X_ewo_encoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, epochs=epochs, model=None):\n",
    "    test_precision, train_precision, ewo_precision = [], [], []\n",
    "    test_recall, train_recall, ewo_recall = [], [], []\n",
    "    test_fscore, train_fscore, ewo_fscore = [], [], []\n",
    "    \n",
    "    test_result_by_tag = {}\n",
    "    train_result_by_tag = {}\n",
    "    ewo_result_by_tag = {}\n",
    "    for t in tagSet:\n",
    "        f1_key = \"F1-\"+t\n",
    "        p_key = \"P-\"+t\n",
    "        r_key = \"R-\"+t\n",
    "        train_result_by_tag[f1_key], train_result_by_tag[p_key], train_result_by_tag[r_key] = [], [], []\n",
    "        test_result_by_tag[f1_key], test_result_by_tag[p_key], test_result_by_tag[r_key] = [], [], []\n",
    "        ewo_result_by_tag[f1_key], ewo_result_by_tag[p_key], ewo_result_by_tag[r_key] = [], [], []\n",
    "\n",
    "    m, time_history = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "        \n",
    "    y_true, y_pred = predict(m, X_train, y_train)\n",
    "    p_train, r_train, f1_train = model_performance(y_true, y_pred)\n",
    "        \n",
    "    y_true_val, y_pred_val = predict(m, X_val, y_val)\n",
    "    p_val, r_val, f1_val = model_performance(y_true_val, y_pred_val)\n",
    "        \n",
    "    y_true_ewo, y_pred_ewo = predict(m, X_ewo, y_ewo) \n",
    "    p_ewo, r_ewo, f1_ewo = model_performance(y_true_ewo, y_pred_ewo)\n",
    "        \n",
    "    for t in range(len(int2tag)):\n",
    "        f1_key = \"F1-\" + int2tag[t]\n",
    "        p_key = \"P-\" + int2tag[t]\n",
    "        r_key = \"R-\" + int2tag[t]\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true, y_pred, t)\n",
    "        train_result_by_tag[p_key].append(p)\n",
    "        train_result_by_tag[r_key].append(r)\n",
    "        train_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_val, y_pred_val, t)\n",
    "        test_result_by_tag[p_key].append(p)\n",
    "        test_result_by_tag[r_key].append(r)\n",
    "        test_result_by_tag[f1_key].append(f1)\n",
    "            \n",
    "        p, r, f1 = model_performace_by_tag(y_true_ewo, y_pred_ewo, t)\n",
    "        ewo_result_by_tag[p_key].append(p)\n",
    "        ewo_result_by_tag[r_key].append(r)\n",
    "        ewo_result_by_tag[f1_key].append(f1)\n",
    "                \n",
    "    test_precision.append(p_val)\n",
    "    train_precision.append(p_train)\n",
    "    ewo_precision.append(p_ewo)\n",
    "        \n",
    "    test_recall.append(r_val)\n",
    "    train_recall.append(r_train)\n",
    "    ewo_recall.append(r_ewo)\n",
    "        \n",
    "    test_fscore.append(f1_val)\n",
    "    train_fscore.append(f1_train)\n",
    "    ewo_fscore.append(f1_ewo)\n",
    "    return pd.DataFrame({\n",
    "        'P_test': test_precision, \n",
    "        'P_train': train_precision, \n",
    "        'P_ewo': ewo_precision, 'R_test': test_recall, 'R_train': train_recall, \n",
    "        'R_ewo': ewo_recall, 'F1-test': test_fscore, 'F1-train': train_fscore, 'F1-ewo': ewo_fscore}), pd.DataFrame(train_result_by_tag), pd.DataFrame(test_result_by_tag), pd.DataFrame(ewo_result_by_tag), time_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 611 samples, validate on 301 samples\n",
      "Epoch 1/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.6057 - acc: 0.8455Epoch 00001: val_loss improved from inf to 0.49847, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.5997 - acc: 0.8478 - val_loss: 0.4985 - val_acc: 0.8804\n",
      "Epoch 2/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4982 - acc: 0.8849Epoch 00002: val_loss did not improve\n",
      "611/611 [==============================] - 0s 734us/step - loss: 0.4960 - acc: 0.8854 - val_loss: 0.5116 - val_acc: 0.8804\n",
      "Epoch 3/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.8865Epoch 00003: val_loss did not improve\n",
      "611/611 [==============================] - 0s 791us/step - loss: 0.4950 - acc: 0.8854 - val_loss: 0.5732 - val_acc: 0.8804\n",
      "Epoch 4/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4898 - acc: 0.8837Epoch 00004: val_loss improved from 0.49847 to 0.48131, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 954us/step - loss: 0.4836 - acc: 0.8854 - val_loss: 0.4813 - val_acc: 0.8804\n",
      "Epoch 5/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4923 - acc: 0.8854Epoch 00005: val_loss improved from 0.48131 to 0.47079, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 840us/step - loss: 0.4872 - acc: 0.8854 - val_loss: 0.4708 - val_acc: 0.8804\n",
      "Epoch 6/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4832 - acc: 0.8849Epoch 00006: val_loss improved from 0.47079 to 0.45524, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.4818 - acc: 0.8854 - val_loss: 0.4552 - val_acc: 0.8804\n",
      "Epoch 7/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4772 - acc: 0.8865Epoch 00007: val_loss improved from 0.45524 to 0.45422, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 988us/step - loss: 0.4800 - acc: 0.8854 - val_loss: 0.4542 - val_acc: 0.8804\n",
      "Epoch 8/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4702 - acc: 0.8848Epoch 00008: val_loss did not improve\n",
      "611/611 [==============================] - 0s 785us/step - loss: 0.4729 - acc: 0.8854 - val_loss: 0.5639 - val_acc: 0.8804\n",
      "Epoch 9/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8865Epoch 00009: val_loss improved from 0.45422 to 0.44886, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.4793 - acc: 0.8854 - val_loss: 0.4489 - val_acc: 0.8804\n",
      "Epoch 10/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4949 - acc: 0.8787Epoch 00010: val_loss improved from 0.44886 to 0.43745, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 833us/step - loss: 0.4763 - acc: 0.8854 - val_loss: 0.4374 - val_acc: 0.8804\n",
      "Epoch 11/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4659 - acc: 0.8860Epoch 00011: val_loss did not improve\n",
      "611/611 [==============================] - 0s 568us/step - loss: 0.4701 - acc: 0.8854 - val_loss: 0.4556 - val_acc: 0.8804\n",
      "Epoch 12/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4710 - acc: 0.8854Epoch 00012: val_loss did not improve\n",
      "611/611 [==============================] - 0s 784us/step - loss: 0.4716 - acc: 0.8854 - val_loss: 0.4491 - val_acc: 0.8804\n",
      "Epoch 13/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4815 - acc: 0.8819Epoch 00013: val_loss did not improve\n",
      "611/611 [==============================] - 1s 905us/step - loss: 0.4710 - acc: 0.8854 - val_loss: 0.4502 - val_acc: 0.8804\n",
      "Epoch 14/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4868 - acc: 0.8805Epoch 00014: val_loss did not improve\n",
      "611/611 [==============================] - 1s 821us/step - loss: 0.4711 - acc: 0.8854 - val_loss: 0.4539 - val_acc: 0.8804\n",
      "Epoch 15/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4846 - acc: 0.8828- ETA: 0s - loss: 0.4908 - acc: Epoch 00015: val_loss did not improve\n",
      "611/611 [==============================] - 1s 883us/step - loss: 0.4683 - acc: 0.8854 - val_loss: 0.4447 - val_acc: 0.8804\n",
      "Epoch 16/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4648 - acc: 0.8887Epoch 00016: val_loss did not improve\n",
      "611/611 [==============================] - 0s 659us/step - loss: 0.4704 - acc: 0.8854 - val_loss: 0.4402 - val_acc: 0.8804\n",
      "Epoch 17/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4528 - acc: 0.8887Epoch 00017: val_loss did not improve\n",
      "611/611 [==============================] - 1s 915us/step - loss: 0.4686 - acc: 0.8854 - val_loss: 0.4493 - val_acc: 0.8804\n",
      "Epoch 18/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4729 - acc: 0.8842Epoch 00018: val_loss did not improve\n",
      "611/611 [==============================] - 1s 875us/step - loss: 0.4682 - acc: 0.8854 - val_loss: 0.4467 - val_acc: 0.8804\n",
      "Epoch 19/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4653 - acc: 0.8879Epoch 00019: val_loss did not improve\n",
      "611/611 [==============================] - 1s 927us/step - loss: 0.4684 - acc: 0.8854 - val_loss: 0.4387 - val_acc: 0.8804\n",
      "Epoch 20/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4580 - acc: 0.8887Epoch 00020: val_loss improved from 0.43745 to 0.43605, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 0s 778us/step - loss: 0.4677 - acc: 0.8854 - val_loss: 0.4360 - val_acc: 0.8804\n",
      "Epoch 21/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4669 - acc: 0.8854Epoch 00021: val_loss improved from 0.43605 to 0.43374, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.4679 - acc: 0.8854 - val_loss: 0.4337 - val_acc: 0.8804\n",
      "Epoch 22/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4531 - acc: 0.8906Epoch 00022: val_loss did not improve\n",
      "611/611 [==============================] - 0s 697us/step - loss: 0.4680 - acc: 0.8854 - val_loss: 0.4399 - val_acc: 0.8804\n",
      "Epoch 23/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4742 - acc: 0.8842Epoch 00023: val_loss did not improve\n",
      "611/611 [==============================] - 0s 789us/step - loss: 0.4667 - acc: 0.8854 - val_loss: 0.4403 - val_acc: 0.8804\n",
      "Epoch 24/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.8849Epoch 00024: val_loss did not improve\n",
      "611/611 [==============================] - 0s 780us/step - loss: 0.4670 - acc: 0.8854 - val_loss: 0.4397 - val_acc: 0.8804\n",
      "Epoch 25/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4774 - acc: 0.8824Epoch 00025: val_loss improved from 0.43374 to 0.43303, saving model to best-model-conll.hdfs\n",
      "611/611 [==============================] - 0s 686us/step - loss: 0.4679 - acc: 0.8854 - val_loss: 0.4330 - val_acc: 0.8804\n",
      "Epoch 26/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4659 - acc: 0.8860Epoch 00026: val_loss did not improve\n",
      "611/611 [==============================] - 0s 665us/step - loss: 0.4649 - acc: 0.8854 - val_loss: 0.4399 - val_acc: 0.8804\n",
      "Epoch 27/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4486 - acc: 0.8887Epoch 00027: val_loss did not improve\n",
      "611/611 [==============================] - 0s 602us/step - loss: 0.4652 - acc: 0.8854 - val_loss: 0.4427 - val_acc: 0.8804\n",
      "Epoch 28/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4884 - acc: 0.8789Epoch 00028: val_loss did not improve\n",
      "611/611 [==============================] - 0s 636us/step - loss: 0.4662 - acc: 0.8854 - val_loss: 0.4462 - val_acc: 0.8804\n",
      "Epoch 29/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8849Epoch 00029: val_loss did not improve\n",
      "611/611 [==============================] - 1s 844us/step - loss: 0.4640 - acc: 0.8854 - val_loss: 0.4356 - val_acc: 0.8804\n",
      "Epoch 30/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4297 - acc: 0.8965Epoch 00030: val_loss did not improve\n",
      "611/611 [==============================] - 0s 597us/step - loss: 0.4649 - acc: 0.8854 - val_loss: 0.4337 - val_acc: 0.8804\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4741 - acc: 0.8837Epoch 00031: val_loss did not improve\n",
      "611/611 [==============================] - 0s 746us/step - loss: 0.4658 - acc: 0.8854 - val_loss: 0.4382 - val_acc: 0.8804\n",
      "Epoch 32/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4508 - acc: 0.8906Epoch 00032: val_loss did not improve\n",
      "611/611 [==============================] - 1s 818us/step - loss: 0.4680 - acc: 0.8854 - val_loss: 0.4410 - val_acc: 0.8804\n",
      "Epoch 33/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8849Epoch 00033: val_loss did not improve\n",
      "611/611 [==============================] - 1s 831us/step - loss: 0.4654 - acc: 0.8854 - val_loss: 0.4395 - val_acc: 0.8804\n",
      "Epoch 34/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4680 - acc: 0.8828Epoch 00034: val_loss did not improve\n",
      "611/611 [==============================] - 0s 726us/step - loss: 0.4664 - acc: 0.8854 - val_loss: 0.4439 - val_acc: 0.8804\n",
      "Epoch 35/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.8849Epoch 00035: val_loss did not improve\n",
      "611/611 [==============================] - 0s 793us/step - loss: 0.4670 - acc: 0.8854 - val_loss: 0.4422 - val_acc: 0.8804\n",
      "Epoch 36/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8865Epoch 00036: val_loss did not improve\n",
      "611/611 [==============================] - 1s 832us/step - loss: 0.4655 - acc: 0.8854 - val_loss: 0.4363 - val_acc: 0.8804\n",
      "Epoch 37/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4915 - acc: 0.8770Epoch 00037: val_loss did not improve\n",
      "611/611 [==============================] - 0s 707us/step - loss: 0.4668 - acc: 0.8854 - val_loss: 0.4437 - val_acc: 0.8804\n",
      "Epoch 38/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4747 - acc: 0.8842Epoch 00038: val_loss did not improve\n",
      "611/611 [==============================] - 0s 783us/step - loss: 0.4673 - acc: 0.8854 - val_loss: 0.4380 - val_acc: 0.8804\n",
      "Epoch 39/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8865Epoch 00039: val_loss did not improve\n",
      "611/611 [==============================] - 0s 812us/step - loss: 0.4661 - acc: 0.8854 - val_loss: 0.4341 - val_acc: 0.8804\n",
      "Epoch 40/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4172 - acc: 0.9026Epoch 00040: val_loss did not improve\n",
      "611/611 [==============================] - 0s 709us/step - loss: 0.4678 - acc: 0.8854 - val_loss: 0.4394 - val_acc: 0.8804\n",
      "Epoch 41/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4720 - acc: 0.8854Epoch 00041: val_loss did not improve\n",
      "611/611 [==============================] - 0s 696us/step - loss: 0.4681 - acc: 0.8854 - val_loss: 0.4386 - val_acc: 0.8804\n",
      "Epoch 42/50\n",
      "512/611 [========================>.....] - ETA: 0s - loss: 0.4811 - acc: 0.8809Epoch 00042: val_loss did not improve\n",
      "611/611 [==============================] - 0s 685us/step - loss: 0.4656 - acc: 0.8854 - val_loss: 0.4474 - val_acc: 0.8804\n",
      "Epoch 43/50\n",
      "544/611 [=========================>....] - ETA: 0s - loss: 0.4464 - acc: 0.8934Epoch 00043: val_loss did not improve\n",
      "611/611 [==============================] - 0s 667us/step - loss: 0.4657 - acc: 0.8854 - val_loss: 0.4349 - val_acc: 0.8804\n",
      "Epoch 44/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8849Epoch 00044: val_loss did not improve\n",
      "611/611 [==============================] - 0s 685us/step - loss: 0.4653 - acc: 0.8854 - val_loss: 0.4402 - val_acc: 0.8804\n",
      "Epoch 45/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4749 - acc: 0.8837Epoch 00045: val_loss did not improve\n",
      "611/611 [==============================] - 1s 919us/step - loss: 0.4669 - acc: 0.8854 - val_loss: 0.4430 - val_acc: 0.8804\n",
      "Epoch 46/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4689 - acc: 0.8854Epoch 00046: val_loss did not improve\n",
      "611/611 [==============================] - 1s 881us/step - loss: 0.4676 - acc: 0.8854 - val_loss: 0.4393 - val_acc: 0.8804\n",
      "Epoch 47/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8849Epoch 00047: val_loss did not improve\n",
      "611/611 [==============================] - 0s 676us/step - loss: 0.4646 - acc: 0.8854 - val_loss: 0.4350 - val_acc: 0.8804\n",
      "Epoch 48/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4720 - acc: 0.8837Epoch 00048: val_loss did not improve\n",
      "611/611 [==============================] - 0s 708us/step - loss: 0.4661 - acc: 0.8854 - val_loss: 0.4404 - val_acc: 0.8804\n",
      "Epoch 49/50\n",
      "576/611 [===========================>..] - ETA: 0s - loss: 0.4677 - acc: 0.8854Epoch 00049: val_loss did not improve\n",
      "611/611 [==============================] - 1s 927us/step - loss: 0.4661 - acc: 0.8854 - val_loss: 0.4404 - val_acc: 0.8804\n",
      "Epoch 50/50\n",
      "608/611 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.8849Epoch 00050: val_loss did not improve\n",
      "611/611 [==============================] - 1s 911us/step - loss: 0.4656 - acc: 0.8854 - val_loss: 0.4363 - val_acc: 0.8804\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_encoded.shape[1], len(tagSet))\n",
    "if with_encoding:\n",
    "    resultEval, train_by_tag, test_by_tag, ewo_by_tag, time_history_autoencoder = algoEval(X_train, y_train, X_val, y_val, X_ewo_encoded, y_ewo, model=model, epochs=50)\n",
    "    pd.DataFrame(time_history_autoencoder.times).to_csv(\"time_history_autoencoder.csv\")\n",
    "else:\n",
    "    resultEval, train_by_tag, test_by_tag, ewo_by_tag, time_history_default = algoEval(X_train, y_train, X_val, y_val, X_ewo_encoded, y_ewo, model=model, epochs=50)\n",
    "    pd.DataFrame(time_history_default.times).to_csv(\"time_history_default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found File b'time_history_default.csv' does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    time_history_default = pd.read_csv(\"time_history_default.csv\", usecols=[1])[\"0\"].values.tolist()\n",
    "    time_history_autoencoder = pd.read_csv(\"time_history_autoencoder.csv\", usecols=[1])[\"0\"].values.tolist()\n",
    "    figure, axis = plt.subplots()\n",
    "    axis.plot(time_history_default, label=\"default\")\n",
    "    axis.plot(time_history_autoencoder, ls=\"--\", label=\"autoencoder\")\n",
    "    axis.set_ylabel(\"Training time\")\n",
    "    axis.set_xlabel(\"Epochs\")\n",
    "    axis.legend()\n",
    "    figure.savefig(fname=\"time-by-epochs.png\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"file not found\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_b`y_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewo_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultEval.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoCrossVal(model, X, y, X_ewo, y_ewo, k = 10, repeat=1): \n",
    "    block_size = int(X.shape[0] / 4)   \n",
    "    output = None\n",
    "    train_by_tags, test_by_tags, ewo_by_tags = None, None, None\n",
    "    for it in range(repeat):\n",
    "        print(\"AlgoCrossValIter -\", it+1)\n",
    "        model = create_model(X.shape[1], len(tagSet))\n",
    "        results = None\n",
    "        train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = None, None, None\n",
    "        for i in range(k):\n",
    "            X_val, y_val = X[i*block_size:i*block_size+block_size], y[i*block_size:i*block_size+block_size]\n",
    "            X_train = np.concatenate((X[0:i*block_size], X[i*block_size+block_size:]))\n",
    "            y_train = np.concatenate((y[0:i*block_size], y[i*block_size+block_size:]))\n",
    "\n",
    "            X_train = X_train.reshape(X_train.shape[0], timestep, X_train.shape[1])\n",
    "            X_val = X_val.reshape(X_val.shape[0], timestep, X_val.shape[1])\n",
    "\n",
    "            result, train_by_tag, test_by_tag, ewo_by_tag, thistory = algoEval(X_train, y_train, X_val, y_val, X_ewo, y_ewo, model=model)\n",
    "            if results is None:\n",
    "                results = result.copy()\n",
    "                train_by_tagsTmp, test_by_tagsTmp, ewo_by_tagsTmp = train_by_tag.copy(), test_by_tag.copy(), ewo_by_tag.copy()\n",
    "            else:\n",
    "                results = pd.concat([results, result], ignore_index=True)\n",
    "                train_by_tagsTmp = pd.concat([train_by_tagsTmp, train_by_tag], ignore_index=True)\n",
    "                test_by_tagsTmp = pd.concat([test_by_tagsTmp, test_by_tag], ignore_index=True)\n",
    "                ewo_by_tagsTmp = pd.concat([ewo_by_tagsTmp, ewo_by_tag], ignore_index=True)\n",
    "        \n",
    "        if output is None:\n",
    "            output = results.mean(axis=0).to_frame()\n",
    "            train_by_tags = train_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            test_by_tags = test_by_tagsTmp.mean(axis=0).to_frame()\n",
    "            ewo_by_tags = ewo_by_tagsTmp.mean(axis=0).to_frame()\n",
    "        else:\n",
    "            output = pd.concat([output, results.mean(axis=0).to_frame()], axis=1)\n",
    "            train_by_tags = pd.concat([train_by_tags, train_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            test_by_tags = pd.concat([test_by_tags, test_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "            ewo_by_tags = pd.concat([ewo_by_tags, ewo_by_tagsTmp.mean(axis=0).to_frame()], axis=1)\n",
    "\n",
    "    return output, train_by_tags, test_by_tags, ewo_by_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlgoCrossValIter - 1\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5704 - acc: 0.8750Epoch 00001: val_loss improved from inf to 0.37881, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 916us/step - loss: 0.5699 - acc: 0.8743 - val_loss: 0.3788 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5114 - acc: 0.8766Epoch 00002: val_loss improved from 0.37881 to 0.36551, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 730us/step - loss: 0.5144 - acc: 0.8743 - val_loss: 0.3655 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5020 - acc: 0.8719Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 747us/step - loss: 0.5011 - acc: 0.8743 - val_loss: 0.3851 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5169 - acc: 0.8719Epoch 00004: val_loss improved from 0.36551 to 0.36365, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 733us/step - loss: 0.5084 - acc: 0.8743 - val_loss: 0.3636 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4956 - acc: 0.8735Epoch 00005: val_loss improved from 0.36365 to 0.36234, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 903us/step - loss: 0.4928 - acc: 0.8743 - val_loss: 0.3623 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4996 - acc: 0.8717Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 594us/step - loss: 0.4986 - acc: 0.8743 - val_loss: 0.3645 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4776 - acc: 0.8781Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 678us/step - loss: 0.4897 - acc: 0.8743 - val_loss: 0.3747 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4688 - acc: 0.8781Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 669us/step - loss: 0.4868 - acc: 0.8743 - val_loss: 0.3720 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4891 - acc: 0.8766Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 604us/step - loss: 0.4903 - acc: 0.8743 - val_loss: 0.3732 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4988 - acc: 0.8684Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 811us/step - loss: 0.4916 - acc: 0.8743 - val_loss: 0.3659 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4513 - acc: 0.8891Epoch 00001: val_loss improved from inf to 0.49349, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 694us/step - loss: 0.4476 - acc: 0.8889 - val_loss: 0.4935 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4492 - acc: 0.8882Epoch 00002: val_loss improved from 0.49349 to 0.49301, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 867us/step - loss: 0.4462 - acc: 0.8889 - val_loss: 0.4930 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8869Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 717us/step - loss: 0.4443 - acc: 0.8889 - val_loss: 0.5031 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4439 - acc: 0.8872Epoch 00004: val_loss improved from 0.49301 to 0.49164, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 638us/step - loss: 0.4461 - acc: 0.8889 - val_loss: 0.4916 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.8884Epoch 00005: val_loss improved from 0.49164 to 0.49098, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 974us/step - loss: 0.4452 - acc: 0.8889 - val_loss: 0.4910 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4213 - acc: 0.8931Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 652us/step - loss: 0.4439 - acc: 0.8889 - val_loss: 0.4926 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4258 - acc: 0.8943Epoch 00007: val_loss improved from 0.49098 to 0.49080, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 860us/step - loss: 0.4446 - acc: 0.8889 - val_loss: 0.4908 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4525 - acc: 0.8859Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 692us/step - loss: 0.4443 - acc: 0.8889 - val_loss: 0.4944 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8884Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 573us/step - loss: 0.4450 - acc: 0.8889 - val_loss: 0.4985 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4503 - acc: 0.8875Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 549us/step - loss: 0.4458 - acc: 0.8889 - val_loss: 0.4943 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8854Epoch 00001: val_loss improved from inf to 0.49631, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 924us/step - loss: 0.4443 - acc: 0.8874 - val_loss: 0.4963 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4547 - acc: 0.8828Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 615us/step - loss: 0.4417 - acc: 0.8874 - val_loss: 0.5099 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4308 - acc: 0.8906Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 790us/step - loss: 0.4429 - acc: 0.8874 - val_loss: 0.5021 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4342 - acc: 0.8882Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 780us/step - loss: 0.4423 - acc: 0.8874 - val_loss: 0.5085 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4542 - acc: 0.8832Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 597us/step - loss: 0.4405 - acc: 0.8874 - val_loss: 0.5163 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4485 - acc: 0.8859Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 721us/step - loss: 0.4418 - acc: 0.8874 - val_loss: 0.5164 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8869Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 794us/step - loss: 0.4394 - acc: 0.8874 - val_loss: 0.5276 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8884Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 539us/step - loss: 0.4419 - acc: 0.8874 - val_loss: 0.5259 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4184 - acc: 0.8976Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 619us/step - loss: 0.4408 - acc: 0.8874 - val_loss: 0.5259 - val_acc: 0.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8854Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 911us/step - loss: 0.4406 - acc: 0.8874 - val_loss: 0.5404 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4729 - acc: 0.8832Epoch 00001: val_loss improved from inf to 0.46615, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 780us/step - loss: 0.4643 - acc: 0.8845 - val_loss: 0.4662 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4757 - acc: 0.8799Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 663us/step - loss: 0.4633 - acc: 0.8845 - val_loss: 0.4687 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4532 - acc: 0.8875Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 882us/step - loss: 0.4612 - acc: 0.8845 - val_loss: 0.4713 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4573 - acc: 0.8859Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 604us/step - loss: 0.4615 - acc: 0.8845 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4681 - acc: 0.8832Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 735us/step - loss: 0.4605 - acc: 0.8845 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4583 - acc: 0.8865Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 825us/step - loss: 0.4605 - acc: 0.8845 - val_loss: 0.4693 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8839Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 838us/step - loss: 0.4595 - acc: 0.8845 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4643 - acc: 0.8849Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 834us/step - loss: 0.4600 - acc: 0.8845 - val_loss: 0.4710 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8824Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 830us/step - loss: 0.4620 - acc: 0.8845 - val_loss: 0.4698 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4558 - acc: 0.8859Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 569us/step - loss: 0.4604 - acc: 0.8845 - val_loss: 0.4684 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 531us/step - loss: 0.4611 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "416/912 [============>.................] - ETA: 0s - loss: 0.4228 - acc: 0.8918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/keras/callbacks.py:403: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 576us/step - loss: 0.4600 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4602 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 584us/step - loss: 0.4604 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 650us/step - loss: 0.4609 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 652us/step - loss: 0.4595 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 682us/step - loss: 0.4595 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 820us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 566us/step - loss: 0.4595 - acc: 0.8838 0s - loss: 0.3918 - acc: \n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 519us/step - loss: 0.4580 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 629us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 636us/step - loss: 0.4594 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 541us/step - loss: 0.4587 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 781us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 677us/step - loss: 0.4581 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 641us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 680us/step - loss: 0.4588 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 684us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 560us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 503us/step - loss: 0.4567 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 638us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 675us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 685us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 576us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 563us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 625us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 650us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 649us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 633us/step - loss: 0.4577 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 610us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 564us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 624us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 580us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 579us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 599us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 557us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 573us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 562us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 569us/step - loss: 0.4583 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 681us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 583us/step - loss: 0.4550 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 490us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 589us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 562us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 668us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 798us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 580us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 558us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 544us/step - loss: 0.4566 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 694us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 644us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 596us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 789us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 832us/step - loss: 0.4551 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 709us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 633us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 554us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 611us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 524us/step - loss: 0.4565 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 2\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5946 - acc: 0.8289Epoch 00001: val_loss improved from inf to 0.41736, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 909us/step - loss: 0.5815 - acc: 0.8348 - val_loss: 0.4174 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.8720Epoch 00002: val_loss improved from 0.41736 to 0.37980, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 753us/step - loss: 0.5102 - acc: 0.8743 - val_loss: 0.3798 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4966 - acc: 0.8765Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 770us/step - loss: 0.5029 - acc: 0.8743 - val_loss: 0.5186 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.8780Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 772us/step - loss: 0.5128 - acc: 0.8743 - val_loss: 0.5015 - val_acc: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5018 - acc: 0.8719Epoch 00005: val_loss improved from 0.37980 to 0.36909, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 750us/step - loss: 0.5006 - acc: 0.8743 - val_loss: 0.3691 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5125 - acc: 0.8688Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 827us/step - loss: 0.4934 - acc: 0.8743 - val_loss: 0.3727 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4802 - acc: 0.8819Epoch 00007: val_loss improved from 0.36909 to 0.36494, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 724us/step - loss: 0.4945 - acc: 0.8743 - val_loss: 0.3649 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4978 - acc: 0.8720Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 816us/step - loss: 0.4906 - acc: 0.8743 - val_loss: 0.3704 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.8750Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 852us/step - loss: 0.4940 - acc: 0.8743 - val_loss: 0.3792 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.8720Epoch 00010: val_loss improved from 0.36494 to 0.36208, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 893us/step - loss: 0.4920 - acc: 0.8743 - val_loss: 0.3621 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4510 - acc: 0.8875Epoch 00001: val_loss improved from inf to 0.49382, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 721us/step - loss: 0.4461 - acc: 0.8889 - val_loss: 0.4938 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4589 - acc: 0.8849Epoch 00002: val_loss improved from 0.49382 to 0.49155, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.4476 - acc: 0.8889 - val_loss: 0.4916 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8884Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 651us/step - loss: 0.4463 - acc: 0.8889 - val_loss: 0.4955 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4642 - acc: 0.8849Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 596us/step - loss: 0.4473 - acc: 0.8889 - val_loss: 0.4982 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.8884Epoch 00005: val_loss improved from 0.49155 to 0.49034, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 740us/step - loss: 0.4463 - acc: 0.8889 - val_loss: 0.4903 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4435 - acc: 0.8882Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 722us/step - loss: 0.4441 - acc: 0.8889 - val_loss: 0.4916 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4451 - acc: 0.8906- ETA: 0s - loss: 0.4051 - acc: Epoch 00007: val_loss improved from 0.49034 to 0.48947, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 842us/step - loss: 0.4454 - acc: 0.8889 - val_loss: 0.4895 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8929Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 856us/step - loss: 0.4434 - acc: 0.8889 - val_loss: 0.4951 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4545 - acc: 0.8875Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 619us/step - loss: 0.4468 - acc: 0.8889 - val_loss: 0.4926 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.8914Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 872us/step - loss: 0.4433 - acc: 0.8889 - val_loss: 0.4924 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8884Epoch 00001: val_loss improved from inf to 0.49232, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 706us/step - loss: 0.4453 - acc: 0.8874 - val_loss: 0.4923 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4670 - acc: 0.8783Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 746us/step - loss: 0.4436 - acc: 0.8874 - val_loss: 0.5026 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4421 - acc: 0.8875Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 749us/step - loss: 0.4409 - acc: 0.8874 - val_loss: 0.5018 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4572 - acc: 0.8828Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 899us/step - loss: 0.4429 - acc: 0.8874 - val_loss: 0.5117 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4281 - acc: 0.8906Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 762us/step - loss: 0.4409 - acc: 0.8874 - val_loss: 0.5141 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4412 - acc: 0.8859Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 560us/step - loss: 0.4417 - acc: 0.8874 - val_loss: 0.5179 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4368 - acc: 0.8891Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 667us/step - loss: 0.4412 - acc: 0.8874 - val_loss: 0.5229 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4339 - acc: 0.8865Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 772us/step - loss: 0.4425 - acc: 0.8874 - val_loss: 0.5245 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8869Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 648us/step - loss: 0.4419 - acc: 0.8874 - val_loss: 0.5264 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4372 - acc: 0.8889Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 627us/step - loss: 0.4418 - acc: 0.8874 - val_loss: 0.5339 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4716 - acc: 0.8828Epoch 00001: val_loss improved from inf to 0.46792, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 616us/step - loss: 0.4627 - acc: 0.8845 - val_loss: 0.4679 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.8824Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 708us/step - loss: 0.4608 - acc: 0.8845 - val_loss: 0.4691 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8839Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 537us/step - loss: 0.4613 - acc: 0.8845 - val_loss: 0.4680 - val_acc: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4654 - acc: 0.8832Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 744us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4686 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8854Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 851us/step - loss: 0.4616 - acc: 0.8845 - val_loss: 0.4716 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4694 - acc: 0.8832Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 745us/step - loss: 0.4608 - acc: 0.8845 - val_loss: 0.4703 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4617 - acc: 0.8849Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 783us/step - loss: 0.4600 - acc: 0.8845 - val_loss: 0.4701 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4648 - acc: 0.8844Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 792us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4699 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4579 - acc: 0.8844Epoch 00009: val_loss improved from 0.46792 to 0.46790, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 762us/step - loss: 0.4587 - acc: 0.8845 - val_loss: 0.4679 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4672 - acc: 0.8837Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 634us/step - loss: 0.4590 - acc: 0.8845 - val_loss: 0.4680 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.4601 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 575us/step - loss: 0.4618 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 683us/step - loss: 0.4614 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 658us/step - loss: 0.4602 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 780us/step - loss: 0.4587 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 661us/step - loss: 0.4590 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 672us/step - loss: 0.4617 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 523us/step - loss: 0.4592 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 634us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 529us/step - loss: 0.4589 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 598us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 611us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 623us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 563us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 581us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 529us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 501us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 652us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 581us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 565us/step - loss: 0.4554 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 676us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 772us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 666us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 558us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 553us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 685us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 724us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 534us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 625us/step - loss: 0.4581 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 613us/step - loss: 0.4565 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 599us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 517us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 531us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 690us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 568us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 662us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 501us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 670us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 705us/step - loss: 0.4584 - acc: 0.8838 0s - loss: 0.4645 - acc: 0.881\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 516us/step - loss: 0.4571 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 543us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 593us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 553us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 602us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 489us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 482us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 482us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 540us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 505us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 541us/step - loss: 0.4562 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 570us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 536us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 568us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 689us/step - loss: 0.4555 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 614us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 556us/step - loss: 0.4546 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 626us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 683us/step - loss: 0.4551 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 618us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 649us/step - loss: 0.4556 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 3\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5960 - acc: 0.8273Epoch 00001: val_loss improved from inf to 0.59081, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 897us/step - loss: 0.5790 - acc: 0.8333 - val_loss: 0.5908 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8735Epoch 00002: val_loss improved from 0.59081 to 0.36696, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5168 - acc: 0.8743 - val_loss: 0.3670 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5153 - acc: 0.8719Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 635us/step - loss: 0.5050 - acc: 0.8743 - val_loss: 0.3776 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4822 - acc: 0.8799Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 704us/step - loss: 0.5026 - acc: 0.8743 - val_loss: 0.3867 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5154 - acc: 0.8701Epoch 00005: val_loss improved from 0.36696 to 0.36381, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 792us/step - loss: 0.4982 - acc: 0.8743 - val_loss: 0.3638 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5091 - acc: 0.8703Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 722us/step - loss: 0.4971 - acc: 0.8743 - val_loss: 0.3692 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.8735Epoch 00007: val_loss improved from 0.36381 to 0.36244, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 809us/step - loss: 0.4961 - acc: 0.8743 - val_loss: 0.3624 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.8735Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 667us/step - loss: 0.4899 - acc: 0.8743 - val_loss: 0.3720 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4827 - acc: 0.8750Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 555us/step - loss: 0.4861 - acc: 0.8743 - val_loss: 0.3835 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4849 - acc: 0.8735Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 747us/step - loss: 0.4842 - acc: 0.8743 - val_loss: 0.3633 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4455 - acc: 0.8891Epoch 00001: val_loss improved from inf to 0.49769, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 769us/step - loss: 0.4472 - acc: 0.8889 - val_loss: 0.4977 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4560 - acc: 0.8859Epoch 00002: val_loss improved from 0.49769 to 0.49070, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 772us/step - loss: 0.4458 - acc: 0.8889 - val_loss: 0.4907 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4435 - acc: 0.8899Epoch 00003: val_loss improved from 0.49070 to 0.49020, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 734us/step - loss: 0.4448 - acc: 0.8889 - val_loss: 0.4902 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4399 - acc: 0.8889- ETA: 0s - loss: 0.4544 - acc: 0.881Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 653us/step - loss: 0.4441 - acc: 0.8889 - val_loss: 0.4962 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4505 - acc: 0.8872Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 775us/step - loss: 0.4449 - acc: 0.8889 - val_loss: 0.4962 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4333 - acc: 0.8914Epoch 00006: val_loss improved from 0.49020 to 0.48974, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 975us/step - loss: 0.4429 - acc: 0.8889 - val_loss: 0.4897 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4454 - acc: 0.8891Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 735us/step - loss: 0.4447 - acc: 0.8889 - val_loss: 0.4991 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8869Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 550us/step - loss: 0.4462 - acc: 0.8889 - val_loss: 0.5000 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8914Epoch 00009: val_loss improved from 0.48974 to 0.48943, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 585us/step - loss: 0.4466 - acc: 0.8889 - val_loss: 0.4894 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4370 - acc: 0.8906Epoch 00010: val_loss improved from 0.48943 to 0.48910, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.4435 - acc: 0.8889 - val_loss: 0.4891 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4580 - acc: 0.8837Epoch 00001: val_loss improved from inf to 0.49980, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 681us/step - loss: 0.4443 - acc: 0.8874 - val_loss: 0.4998 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8869Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 681us/step - loss: 0.4419 - acc: 0.8874 - val_loss: 0.5060 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.8899Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 835us/step - loss: 0.4426 - acc: 0.8874 - val_loss: 0.5081 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8884Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 691us/step - loss: 0.4424 - acc: 0.8874 - val_loss: 0.5099 - val_acc: 0.8728\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4301 - acc: 0.8891Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 606us/step - loss: 0.4420 - acc: 0.8874 - val_loss: 0.5134 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8869Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 817us/step - loss: 0.4414 - acc: 0.8874 - val_loss: 0.5215 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4311 - acc: 0.8914Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 802us/step - loss: 0.4430 - acc: 0.8874 - val_loss: 0.5219 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4354 - acc: 0.8884Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 908us/step - loss: 0.4405 - acc: 0.8874 - val_loss: 0.5231 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4513 - acc: 0.8849Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 892us/step - loss: 0.4425 - acc: 0.8874 - val_loss: 0.5344 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4326 - acc: 0.8898Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 692us/step - loss: 0.4418 - acc: 0.8874 - val_loss: 0.5331 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4630 - acc: 0.8859Epoch 00001: val_loss improved from inf to 0.46236, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 813us/step - loss: 0.4642 - acc: 0.8845 - val_loss: 0.4624 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4747 - acc: 0.8816Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 784us/step - loss: 0.4625 - acc: 0.8845 - val_loss: 0.4683 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4330 - acc: 0.8891Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 711us/step - loss: 0.4627 - acc: 0.8845 - val_loss: 0.4678 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4585 - acc: 0.8859Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 777us/step - loss: 0.4602 - acc: 0.8845 - val_loss: 0.4691 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4473 - acc: 0.8844Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 696us/step - loss: 0.4626 - acc: 0.8845 - val_loss: 0.4713 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4664 - acc: 0.8828Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 931us/step - loss: 0.4606 - acc: 0.8845 - val_loss: 0.4765 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4624 - acc: 0.8859Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 667us/step - loss: 0.4613 - acc: 0.8845 - val_loss: 0.4697 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4618 - acc: 0.8832Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 759us/step - loss: 0.4593 - acc: 0.8845 - val_loss: 0.4704 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.8812Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 721us/step - loss: 0.4597 - acc: 0.8845 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4620 - acc: 0.8844Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 974us/step - loss: 0.4600 - acc: 0.8845 - val_loss: 0.4709 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 610us/step - loss: 0.4622 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 580us/step - loss: 0.4609 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 606us/step - loss: 0.4612 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 587us/step - loss: 0.4604 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 635us/step - loss: 0.4607 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 787us/step - loss: 0.4603 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 610us/step - loss: 0.4603 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 570us/step - loss: 0.4594 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 667us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 673us/step - loss: 0.4584 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 611us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 811us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 766us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 815us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 532us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 584us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 661us/step - loss: 0.4554 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 661us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 814us/step - loss: 0.4581 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 795us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 571us/step - loss: 0.4571 - acc: 0.8838 0s - loss: 0.4746 - acc:\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 839us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 552us/step - loss: 0.4587 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 563us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 553us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 611us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 619us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 537us/step - loss: 0.4571 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 819us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 698us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 723us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 824us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 778us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 721us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 785us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 760us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 752us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 720us/step - loss: 0.4576 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 755us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 750us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 777us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 755us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 722us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 870us/step - loss: 0.4540 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 759us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 675us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 678us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 684us/step - loss: 0.4577 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 701us/step - loss: 0.4555 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 701us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 947us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 806us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 880us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 682us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 786us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 656us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 702us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 671us/step - loss: 0.4580 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 4\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5904 - acc: 0.8422Epoch 00001: val_loss improved from inf to 0.38847, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5931 - acc: 0.8421 - val_loss: 0.3885 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.5064 - acc: 0.8715Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 756us/step - loss: 0.4964 - acc: 0.8743 - val_loss: 0.3936 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5195 - acc: 0.8735Epoch 00003: val_loss improved from 0.38847 to 0.36399, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 712us/step - loss: 0.5161 - acc: 0.8743 - val_loss: 0.3640 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5073 - acc: 0.8750Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 620us/step - loss: 0.5047 - acc: 0.8743 - val_loss: 0.3728 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5065 - acc: 0.8750Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 585us/step - loss: 0.5070 - acc: 0.8743 - val_loss: 0.3750 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4897 - acc: 0.8766Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 721us/step - loss: 0.4956 - acc: 0.8743 - val_loss: 0.3798 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5074 - acc: 0.8719Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 853us/step - loss: 0.4969 - acc: 0.8743 - val_loss: 0.3666 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4888 - acc: 0.8750Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 576us/step - loss: 0.4969 - acc: 0.8743 - val_loss: 0.3642 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5073 - acc: 0.8703Epoch 00009: val_loss improved from 0.36399 to 0.36324, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 725us/step - loss: 0.4938 - acc: 0.8743 - val_loss: 0.3632 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4806 - acc: 0.8766Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 593us/step - loss: 0.4896 - acc: 0.8743 - val_loss: 0.3684 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4369 - acc: 0.8922Epoch 00001: val_loss improved from inf to 0.49254, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 793us/step - loss: 0.4489 - acc: 0.8889 - val_loss: 0.4925 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4319 - acc: 0.8924Epoch 00002: val_loss improved from 0.49254 to 0.48950, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 940us/step - loss: 0.4455 - acc: 0.8889 - val_loss: 0.4895 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8899Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 633us/step - loss: 0.4455 - acc: 0.8889 - val_loss: 0.4914 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4478 - acc: 0.8884Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 755us/step - loss: 0.4455 - acc: 0.8889 - val_loss: 0.4911 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4347 - acc: 0.8914Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 700us/step - loss: 0.4450 - acc: 0.8889 - val_loss: 0.4898 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8884Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 524us/step - loss: 0.4460 - acc: 0.8889 - val_loss: 0.4930 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4477 - acc: 0.8891Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 591us/step - loss: 0.4441 - acc: 0.8889 - val_loss: 0.4925 - val_acc: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8899Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 668us/step - loss: 0.4457 - acc: 0.8889 - val_loss: 0.4913 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4478 - acc: 0.8875Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 847us/step - loss: 0.4436 - acc: 0.8889 - val_loss: 0.4925 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8884Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 724us/step - loss: 0.4438 - acc: 0.8889 - val_loss: 0.4896 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4435 - acc: 0.8865Epoch 00001: val_loss improved from inf to 0.49644, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 773us/step - loss: 0.4414 - acc: 0.8874 - val_loss: 0.4964 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4426 - acc: 0.8889Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 706us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5000 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4565 - acc: 0.8828Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 697us/step - loss: 0.4424 - acc: 0.8874 - val_loss: 0.5034 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4268 - acc: 0.8924Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 717us/step - loss: 0.4418 - acc: 0.8874 - val_loss: 0.5082 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8899Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 789us/step - loss: 0.4423 - acc: 0.8874 - val_loss: 0.5132 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4248 - acc: 0.8938Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 646us/step - loss: 0.4424 - acc: 0.8874 - val_loss: 0.5209 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4485 - acc: 0.8859Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 705us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5243 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4660 - acc: 0.8785Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 590us/step - loss: 0.4404 - acc: 0.8874 - val_loss: 0.5333 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4713 - acc: 0.8783Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 724us/step - loss: 0.4421 - acc: 0.8874 - val_loss: 0.5326 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8899Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 713us/step - loss: 0.4425 - acc: 0.8874 - val_loss: 0.5269 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8854Epoch 00001: val_loss improved from inf to 0.46436, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 679us/step - loss: 0.4615 - acc: 0.8845 - val_loss: 0.4644 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4649 - acc: 0.8849Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 787us/step - loss: 0.4606 - acc: 0.8845 - val_loss: 0.4692 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4738 - acc: 0.8797Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 602us/step - loss: 0.4612 - acc: 0.8845 - val_loss: 0.4717 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8869Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 643us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4745 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4787 - acc: 0.8783Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 647us/step - loss: 0.4588 - acc: 0.8845 - val_loss: 0.4746 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4819 - acc: 0.8785Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 669us/step - loss: 0.4612 - acc: 0.8845 - val_loss: 0.4682 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4526 - acc: 0.8898Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 619us/step - loss: 0.4596 - acc: 0.8845 - val_loss: 0.4729 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4549 - acc: 0.8859Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 695us/step - loss: 0.4572 - acc: 0.8845 - val_loss: 0.4690 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4534 - acc: 0.8837Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 588us/step - loss: 0.4585 - acc: 0.8845 - val_loss: 0.4666 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4769 - acc: 0.8783Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 857us/step - loss: 0.4582 - acc: 0.8845 - val_loss: 0.4693 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 467us/step - loss: 0.4610 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 537us/step - loss: 0.4622 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 544us/step - loss: 0.4606 - acc: 0.8838 0s - loss: 0.4657 - acc: 0\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 574us/step - loss: 0.4610 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 590us/step - loss: 0.4603 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 542us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 654us/step - loss: 0.4605 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 520us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 691us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 496us/step - loss: 0.4554 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 677us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 505us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 528us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 537us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 729us/step - loss: 0.4544 - acc: 0.8838\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 590us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 672us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 776us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 641us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.4576 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 668us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 719us/step - loss: 0.4553 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 584us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 586us/step - loss: 0.4581 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 611us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 529us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 595us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 602us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 548us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 589us/step - loss: 0.4568 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 678us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 630us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 674us/step - loss: 0.4554 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 650us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 573us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 583us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 636us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 689us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 598us/step - loss: 0.4547 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 649us/step - loss: 0.4569 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 664us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 664us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 540us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 589us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 722us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 647us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 540us/step - loss: 0.4555 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 668us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 542us/step - loss: 0.4565 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 716us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 575us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 581us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 646us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 577us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 578us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 687us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 531us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 748us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 578us/step - loss: 0.4554 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 5\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.8333Epoch 00001: val_loss improved from inf to 0.39903, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5653 - acc: 0.8363 - val_loss: 0.3990 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5228 - acc: 0.8701Epoch 00002: val_loss improved from 0.39903 to 0.36259, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 906us/step - loss: 0.5083 - acc: 0.8743 - val_loss: 0.3626 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5188 - acc: 0.8783Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 877us/step - loss: 0.5192 - acc: 0.8743 - val_loss: 0.5777 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4924 - acc: 0.8750Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 589us/step - loss: 0.5005 - acc: 0.8743 - val_loss: 0.3636 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.8720Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 558us/step - loss: 0.5172 - acc: 0.8743 - val_loss: 0.3739 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4983 - acc: 0.8720Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 803us/step - loss: 0.4922 - acc: 0.8743 - val_loss: 0.3688 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5149 - acc: 0.8668Epoch 00007: val_loss improved from 0.36259 to 0.36201, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 631us/step - loss: 0.4989 - acc: 0.8743 - val_loss: 0.3620 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4932 - acc: 0.8750Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 630us/step - loss: 0.4954 - acc: 0.8743 - val_loss: 0.3861 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.8735Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 888us/step - loss: 0.4900 - acc: 0.8743 - val_loss: 0.3683 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4920 - acc: 0.8735Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 650us/step - loss: 0.4919 - acc: 0.8743 - val_loss: 0.3698 - val_acc: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8884Epoch 00001: val_loss improved from inf to 0.49257, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 791us/step - loss: 0.4492 - acc: 0.8889 - val_loss: 0.4926 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4599 - acc: 0.8849Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 758us/step - loss: 0.4463 - acc: 0.8889 - val_loss: 0.5027 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4534 - acc: 0.8882Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 815us/step - loss: 0.4470 - acc: 0.8889 - val_loss: 0.4957 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4688 - acc: 0.8816Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 643us/step - loss: 0.4426 - acc: 0.8889 - val_loss: 0.5167 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4464 - acc: 0.8906Epoch 00005: val_loss improved from 0.49257 to 0.49172, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 887us/step - loss: 0.4491 - acc: 0.8889 - val_loss: 0.4917 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4499 - acc: 0.8884Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 622us/step - loss: 0.4475 - acc: 0.8889 - val_loss: 0.4934 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4626 - acc: 0.8816Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 691us/step - loss: 0.4434 - acc: 0.8889 - val_loss: 0.5029 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8884Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 906us/step - loss: 0.4447 - acc: 0.8889 - val_loss: 0.4938 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4715 - acc: 0.8799Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 691us/step - loss: 0.4447 - acc: 0.8889 - val_loss: 0.4978 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4393 - acc: 0.8891Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 745us/step - loss: 0.4451 - acc: 0.8889 - val_loss: 0.4969 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4596 - acc: 0.8816Epoch 00001: val_loss improved from inf to 0.51188, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 746us/step - loss: 0.4425 - acc: 0.8874 - val_loss: 0.5119 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4362 - acc: 0.8891Epoch 00002: val_loss improved from 0.51188 to 0.50190, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 987us/step - loss: 0.4420 - acc: 0.8874 - val_loss: 0.5019 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4545 - acc: 0.8819Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 842us/step - loss: 0.4424 - acc: 0.8874 - val_loss: 0.5149 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8884Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 704us/step - loss: 0.4413 - acc: 0.8874 - val_loss: 0.5052 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4100 - acc: 0.8980Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 834us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5117 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4548 - acc: 0.8832Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 786us/step - loss: 0.4421 - acc: 0.8874 - val_loss: 0.5149 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4478 - acc: 0.8854Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 752us/step - loss: 0.4419 - acc: 0.8874 - val_loss: 0.5256 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4469 - acc: 0.8854Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 932us/step - loss: 0.4411 - acc: 0.8874 - val_loss: 0.5316 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8884Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 738us/step - loss: 0.4418 - acc: 0.8874 - val_loss: 0.5295 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4443 - acc: 0.8875Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 676us/step - loss: 0.4412 - acc: 0.8874 - val_loss: 0.5296 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4731 - acc: 0.8816Epoch 00001: val_loss improved from inf to 0.46606, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 634us/step - loss: 0.4625 - acc: 0.8845 - val_loss: 0.4661 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4463 - acc: 0.8889Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 584us/step - loss: 0.4602 - acc: 0.8845 - val_loss: 0.4663 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4635 - acc: 0.8839Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 709us/step - loss: 0.4609 - acc: 0.8845 - val_loss: 0.4685 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8839Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 603us/step - loss: 0.4587 - acc: 0.8845 - val_loss: 0.4705 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4682 - acc: 0.8828Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 783us/step - loss: 0.4594 - acc: 0.8845 - val_loss: 0.4694 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8824Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 560us/step - loss: 0.4595 - acc: 0.8845 - val_loss: 0.4692 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4501 - acc: 0.8891- ETA: 0s - loss: 0.4211 - acc: 0.891Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 841us/step - loss: 0.4594 - acc: 0.8845 - val_loss: 0.4693 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8839Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 761us/step - loss: 0.4570 - acc: 0.8845 - val_loss: 0.4698 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4663 - acc: 0.8828Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 573us/step - loss: 0.4578 - acc: 0.8845 - val_loss: 0.4671 - val_acc: 0.8816\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/684 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8869Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 766us/step - loss: 0.4569 - acc: 0.8845 - val_loss: 0.4708 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 636us/step - loss: 0.4593 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 652us/step - loss: 0.4593 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 612us/step - loss: 0.4597 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 584us/step - loss: 0.4592 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 591us/step - loss: 0.4601 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 641us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 551us/step - loss: 0.4592 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 599us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 764us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 608us/step - loss: 0.4583 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 624us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 615us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 601us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 702us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 574us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 608us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 673us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 668us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 629us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 551us/step - loss: 0.4571 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 585us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 588us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.4555 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 576us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 478us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 610us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 534us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 482us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 529us/step - loss: 0.4570 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 674us/step - loss: 0.4554 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 611us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 592us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 514us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 462us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 467us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 514us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 504us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 479us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 652us/step - loss: 0.4561 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 633us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 638us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 590us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 781us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 746us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 702us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 562us/step - loss: 0.4546 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 578us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 565us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 674us/step - loss: 0.4558 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 682us/step - loss: 0.4545 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 661us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 676us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 641us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 543us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 560us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 627us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 536us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 859us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 637us/step - loss: 0.4552 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 6\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5772 - acc: 0.8348Epoch 00001: val_loss improved from inf to 0.44134, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 935us/step - loss: 0.5763 - acc: 0.8348 - val_loss: 0.4413 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8720Epoch 00002: val_loss improved from 0.44134 to 0.40275, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 759us/step - loss: 0.5010 - acc: 0.8743 - val_loss: 0.4027 - val_acc: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5184 - acc: 0.8720Epoch 00003: val_loss improved from 0.40275 to 0.37541, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 777us/step - loss: 0.5112 - acc: 0.8743 - val_loss: 0.3754 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5166 - acc: 0.8719Epoch 00004: val_loss improved from 0.37541 to 0.36909, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5050 - acc: 0.8743 - val_loss: 0.3691 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4986 - acc: 0.8719Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 865us/step - loss: 0.4998 - acc: 0.8743 - val_loss: 0.3972 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4693 - acc: 0.8844Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 879us/step - loss: 0.4952 - acc: 0.8743 - val_loss: 0.4563 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4823 - acc: 0.8750Epoch 00007: val_loss improved from 0.36909 to 0.36712, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.4926 - acc: 0.8743 - val_loss: 0.3671 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4721 - acc: 0.8797Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 672us/step - loss: 0.4923 - acc: 0.8743 - val_loss: 0.4693 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4931 - acc: 0.8750Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 773us/step - loss: 0.4919 - acc: 0.8743 - val_loss: 0.3887 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4934 - acc: 0.8750Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 658us/step - loss: 0.4899 - acc: 0.8743 - val_loss: 0.3705 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4583 - acc: 0.8865Epoch 00001: val_loss improved from inf to 0.49669, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 864us/step - loss: 0.4477 - acc: 0.8889 - val_loss: 0.4967 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4533 - acc: 0.8865Epoch 00002: val_loss improved from 0.49669 to 0.49313, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.4462 - acc: 0.8889 - val_loss: 0.4931 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4597 - acc: 0.8854Epoch 00003: val_loss improved from 0.49313 to 0.49157, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 797us/step - loss: 0.4458 - acc: 0.8889 - val_loss: 0.4916 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4517 - acc: 0.8898Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 667us/step - loss: 0.4459 - acc: 0.8889 - val_loss: 0.4937 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4410 - acc: 0.8906Epoch 00005: val_loss improved from 0.49157 to 0.49112, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 822us/step - loss: 0.4465 - acc: 0.8889 - val_loss: 0.4911 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4452 - acc: 0.8891Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 565us/step - loss: 0.4442 - acc: 0.8889 - val_loss: 0.4942 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4415 - acc: 0.8899Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 580us/step - loss: 0.4456 - acc: 0.8889 - val_loss: 0.4912 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4622 - acc: 0.8816Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 616us/step - loss: 0.4428 - acc: 0.8889 - val_loss: 0.5075 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4191 - acc: 0.8964Epoch 00009: val_loss improved from 0.49112 to 0.48832, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 706us/step - loss: 0.4440 - acc: 0.8889 - val_loss: 0.4883 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4436 - acc: 0.8899Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 686us/step - loss: 0.4447 - acc: 0.8889 - val_loss: 0.4911 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8884Epoch 00001: val_loss improved from inf to 0.49642, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 670us/step - loss: 0.4438 - acc: 0.8874 - val_loss: 0.4964 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4547 - acc: 0.8832Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 726us/step - loss: 0.4435 - acc: 0.8874 - val_loss: 0.5043 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8899Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 675us/step - loss: 0.4411 - acc: 0.8874 - val_loss: 0.5110 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4211 - acc: 0.8938Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 814us/step - loss: 0.4423 - acc: 0.8874 - val_loss: 0.5097 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4494 - acc: 0.8859Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 819us/step - loss: 0.4422 - acc: 0.8874 - val_loss: 0.5165 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4343 - acc: 0.8899Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 536us/step - loss: 0.4408 - acc: 0.8874 - val_loss: 0.5216 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8899Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 534us/step - loss: 0.4423 - acc: 0.8874 - val_loss: 0.5205 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4433 - acc: 0.8869Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 532us/step - loss: 0.4410 - acc: 0.8874 - val_loss: 0.5276 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8884Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 540us/step - loss: 0.4440 - acc: 0.8874 - val_loss: 0.5274 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8869Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 528us/step - loss: 0.4415 - acc: 0.8874 - val_loss: 0.5379 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4168 - acc: 0.8941Epoch 00001: val_loss improved from inf to 0.46395, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 630us/step - loss: 0.4647 - acc: 0.8845 - val_loss: 0.4639 - val_acc: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4786 - acc: 0.8797Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 670us/step - loss: 0.4619 - acc: 0.8845 - val_loss: 0.4764 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8839Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 800us/step - loss: 0.4648 - acc: 0.8845 - val_loss: 0.4697 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4411 - acc: 0.8865Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 710us/step - loss: 0.4635 - acc: 0.8845 - val_loss: 0.4700 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8839Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 764us/step - loss: 0.4621 - acc: 0.8845 - val_loss: 0.4708 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4754 - acc: 0.8797Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 577us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4722 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8854Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 740us/step - loss: 0.4631 - acc: 0.8845 - val_loss: 0.4689 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4214 - acc: 0.8980Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 571us/step - loss: 0.4588 - acc: 0.8845 - val_loss: 0.4853 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8839Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 705us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4692 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4617 - acc: 0.8844Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 847us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4695 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 645us/step - loss: 0.4632 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 609us/step - loss: 0.4603 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 571us/step - loss: 0.4640 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 512us/step - loss: 0.4616 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 497us/step - loss: 0.4608 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 532us/step - loss: 0.4601 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 576us/step - loss: 0.4609 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 623us/step - loss: 0.4608 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 597us/step - loss: 0.4599 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.4600 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 646us/step - loss: 0.4609 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 584us/step - loss: 0.4590 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 508us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 501us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 508us/step - loss: 0.4605 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 667us/step - loss: 0.4600 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 582us/step - loss: 0.4609 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 669us/step - loss: 0.4588 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 545us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 539us/step - loss: 0.4574 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 550us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 670us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 518us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 665us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 558us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 540us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 599us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 570us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 561us/step - loss: 0.4553 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 568us/step - loss: 0.4578 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 664us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 556us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 465us/step - loss: 0.4553 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 541us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 574us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 523us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 509us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 495us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 521us/step - loss: 0.4566 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 535us/step - loss: 0.4550 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 491us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 514us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 534us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 516us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 676us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 478us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 468us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 724us/step - loss: 0.4568 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 731us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 818us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 622us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 625us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 626us/step - loss: 0.4581 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 588us/step - loss: 0.4581 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 635us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 667us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 619us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 661us/step - loss: 0.4569 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 7\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.6394 - acc: 0.8247Epoch 00001: val_loss improved from inf to 0.37414, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 884us/step - loss: 0.6055 - acc: 0.8348 - val_loss: 0.3741 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5055 - acc: 0.8688Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 663us/step - loss: 0.4869 - acc: 0.8743 - val_loss: 0.3877 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4891 - acc: 0.8750Epoch 00003: val_loss improved from 0.37414 to 0.36380, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 904us/step - loss: 0.4931 - acc: 0.8743 - val_loss: 0.3638 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5008 - acc: 0.8750Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 741us/step - loss: 0.5027 - acc: 0.8743 - val_loss: 0.3645 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4776 - acc: 0.8797Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 711us/step - loss: 0.4940 - acc: 0.8743 - val_loss: 0.3823 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4968 - acc: 0.8720Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 683us/step - loss: 0.4893 - acc: 0.8743 - val_loss: 0.3803 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.5057 - acc: 0.8715Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 715us/step - loss: 0.5001 - acc: 0.8743 - val_loss: 0.3641 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4893 - acc: 0.8717Epoch 00008: val_loss improved from 0.36380 to 0.36235, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 707us/step - loss: 0.4899 - acc: 0.8743 - val_loss: 0.3624 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4981 - acc: 0.8720Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 822us/step - loss: 0.4918 - acc: 0.8743 - val_loss: 0.3636 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4906 - acc: 0.8735Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 716us/step - loss: 0.4880 - acc: 0.8743 - val_loss: 0.3646 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8869Epoch 00001: val_loss improved from inf to 0.51101, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 682us/step - loss: 0.4444 - acc: 0.8889 - val_loss: 0.5110 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4379 - acc: 0.8931Epoch 00002: val_loss improved from 0.51101 to 0.49033, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 894us/step - loss: 0.4491 - acc: 0.8889 - val_loss: 0.4903 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4293 - acc: 0.8947Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 749us/step - loss: 0.4445 - acc: 0.8889 - val_loss: 0.4924 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4481 - acc: 0.8875Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 746us/step - loss: 0.4462 - acc: 0.8889 - val_loss: 0.4968 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4405 - acc: 0.8865Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 803us/step - loss: 0.4468 - acc: 0.8889 - val_loss: 0.4953 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4280 - acc: 0.8947Epoch 00006: val_loss improved from 0.49033 to 0.49020, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 792us/step - loss: 0.4460 - acc: 0.8889 - val_loss: 0.4902 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4575 - acc: 0.8849Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 709us/step - loss: 0.4432 - acc: 0.8889 - val_loss: 0.4988 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4537 - acc: 0.8872Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 701us/step - loss: 0.4452 - acc: 0.8889 - val_loss: 0.4905 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4514 - acc: 0.8859Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 752us/step - loss: 0.4428 - acc: 0.8889 - val_loss: 0.4942 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4640 - acc: 0.8854Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 590us/step - loss: 0.4446 - acc: 0.8889 - val_loss: 0.4999 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4661 - acc: 0.8816Epoch 00001: val_loss improved from inf to 0.50446, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 865us/step - loss: 0.4445 - acc: 0.8874 - val_loss: 0.5045 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8854Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 656us/step - loss: 0.4431 - acc: 0.8874 - val_loss: 0.5088 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.8914Epoch 00003: val_loss improved from 0.50446 to 0.50327, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 697us/step - loss: 0.4431 - acc: 0.8874 - val_loss: 0.5033 - val_acc: 0.8728\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/684 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8854Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 923us/step - loss: 0.4434 - acc: 0.8874 - val_loss: 0.5104 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4590 - acc: 0.8812Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 876us/step - loss: 0.4402 - acc: 0.8874 - val_loss: 0.5177 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4353 - acc: 0.8891Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 810us/step - loss: 0.4419 - acc: 0.8874 - val_loss: 0.5165 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8869Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 826us/step - loss: 0.4425 - acc: 0.8874 - val_loss: 0.5174 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4395 - acc: 0.8875Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 859us/step - loss: 0.4417 - acc: 0.8874 - val_loss: 0.5198 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4509 - acc: 0.8837Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 632us/step - loss: 0.4407 - acc: 0.8874 - val_loss: 0.5304 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8884Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 732us/step - loss: 0.4408 - acc: 0.8874 - val_loss: 0.5301 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4560 - acc: 0.8875Epoch 00001: val_loss improved from inf to 0.46704, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 695us/step - loss: 0.4636 - acc: 0.8845 - val_loss: 0.4670 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.8854Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 659us/step - loss: 0.4626 - acc: 0.8845 - val_loss: 0.4683 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4835 - acc: 0.8767Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 640us/step - loss: 0.4611 - acc: 0.8845 - val_loss: 0.4687 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4733 - acc: 0.8812Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 793us/step - loss: 0.4611 - acc: 0.8845 - val_loss: 0.4687 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8854Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 797us/step - loss: 0.4615 - acc: 0.8845 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4594 - acc: 0.8844Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 783us/step - loss: 0.4603 - acc: 0.8845 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4590 - acc: 0.8844Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 568us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4724 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4584 - acc: 0.8859Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 677us/step - loss: 0.4597 - acc: 0.8845 - val_loss: 0.4738 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8899Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 524us/step - loss: 0.4601 - acc: 0.8845 - val_loss: 0.4775 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8839Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 514us/step - loss: 0.4586 - acc: 0.8845 - val_loss: 0.4712 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4621 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 512us/step - loss: 0.4605 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 653us/step - loss: 0.4595 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 541us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 574us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 629us/step - loss: 0.4594 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 618us/step - loss: 0.4587 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 557us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.4594 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 517us/step - loss: 0.4577 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 505us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 497us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 716us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 516us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 729us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 492us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 590us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 460us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 526us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 548us/step - loss: 0.4567 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 629us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 624us/step - loss: 0.4553 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 622us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 653us/step - loss: 0.4548 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 728us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 655us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 476us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 457us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 467us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 519us/step - loss: 0.4560 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 682us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 695us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 636us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 651us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 744us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 675us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 665us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 601us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 709us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 657us/step - loss: 0.4568 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 641us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 643us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 624us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 673us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 844us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 685us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 555us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 650us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 628us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 629us/step - loss: 0.4569 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 747us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 675us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 614us/step - loss: 0.4553 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 726us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 668us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 655us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 644us/step - loss: 0.4561 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 619us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 820us/step - loss: 0.4554 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 8\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.8318Epoch 00001: val_loss improved from inf to 0.37488, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 885us/step - loss: 0.6152 - acc: 0.8333 - val_loss: 0.3749 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4850 - acc: 0.8750Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 605us/step - loss: 0.4923 - acc: 0.8743 - val_loss: 0.4095 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5147 - acc: 0.8750Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 870us/step - loss: 0.5158 - acc: 0.8743 - val_loss: 0.6246 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5105 - acc: 0.8719Epoch 00004: val_loss improved from 0.37488 to 0.36997, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 760us/step - loss: 0.5023 - acc: 0.8743 - val_loss: 0.3700 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4699 - acc: 0.8812Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 674us/step - loss: 0.4898 - acc: 0.8743 - val_loss: 0.6539 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.5217 - acc: 0.8681Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 610us/step - loss: 0.4994 - acc: 0.8743 - val_loss: 0.3750 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4934 - acc: 0.8750Epoch 00007: val_loss improved from 0.36997 to 0.36825, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 683us/step - loss: 0.4933 - acc: 0.8743 - val_loss: 0.3682 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.8765Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 693us/step - loss: 0.4922 - acc: 0.8743 - val_loss: 0.4528 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.8765Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 904us/step - loss: 0.4930 - acc: 0.8743 - val_loss: 0.4026 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4971 - acc: 0.8735Epoch 00010: val_loss improved from 0.36825 to 0.36665, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 721us/step - loss: 0.4941 - acc: 0.8743 - val_loss: 0.3667 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8884Epoch 00001: val_loss improved from inf to 0.49058, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 746us/step - loss: 0.4461 - acc: 0.8889 - val_loss: 0.4906 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4560 - acc: 0.8849Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 688us/step - loss: 0.4454 - acc: 0.8889 - val_loss: 0.4979 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8884Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 524us/step - loss: 0.4477 - acc: 0.8889 - val_loss: 0.4951 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4605 - acc: 0.8849Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 754us/step - loss: 0.4462 - acc: 0.8889 - val_loss: 0.4953 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8899Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 518us/step - loss: 0.4437 - acc: 0.8889 - val_loss: 0.4929 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4481 - acc: 0.8884Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 535us/step - loss: 0.4457 - acc: 0.8889 - val_loss: 0.4924 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4375 - acc: 0.8914Epoch 00007: val_loss improved from 0.49058 to 0.48893, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 0s 674us/step - loss: 0.4447 - acc: 0.8889 - val_loss: 0.4889 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8914Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 662us/step - loss: 0.4446 - acc: 0.8889 - val_loss: 0.4902 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4442 - acc: 0.8891Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 540us/step - loss: 0.4436 - acc: 0.8889 - val_loss: 0.4919 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8899Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 688us/step - loss: 0.4443 - acc: 0.8889 - val_loss: 0.4893 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4404 - acc: 0.8891Epoch 00001: val_loss improved from inf to 0.49593, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 950us/step - loss: 0.4429 - acc: 0.8874 - val_loss: 0.4959 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4357 - acc: 0.8872Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 693us/step - loss: 0.4394 - acc: 0.8874 - val_loss: 0.5124 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4561 - acc: 0.8828Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 697us/step - loss: 0.4414 - acc: 0.8874 - val_loss: 0.5096 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4346 - acc: 0.8906Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 714us/step - loss: 0.4411 - acc: 0.8874 - val_loss: 0.5087 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4475 - acc: 0.8854Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 794us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5214 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4486 - acc: 0.8844Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 720us/step - loss: 0.4400 - acc: 0.8874 - val_loss: 0.5255 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4342 - acc: 0.8884Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 742us/step - loss: 0.4410 - acc: 0.8874 - val_loss: 0.5265 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4213 - acc: 0.8958Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 708us/step - loss: 0.4413 - acc: 0.8874 - val_loss: 0.5243 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4347 - acc: 0.8891Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 787us/step - loss: 0.4421 - acc: 0.8874 - val_loss: 0.5229 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4386 - acc: 0.8891Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 729us/step - loss: 0.4410 - acc: 0.8874 - val_loss: 0.5273 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4687 - acc: 0.8828Epoch 00001: val_loss improved from inf to 0.46904, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 824us/step - loss: 0.4636 - acc: 0.8845 - val_loss: 0.4690 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4757 - acc: 0.8797Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 836us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4732 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.8839Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 779us/step - loss: 0.4620 - acc: 0.8845 - val_loss: 0.4692 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8884Epoch 00004: val_loss improved from 0.46904 to 0.46595, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 725us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4660 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4548 - acc: 0.8865Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 660us/step - loss: 0.4627 - acc: 0.8845 - val_loss: 0.4686 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8839Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 550us/step - loss: 0.4606 - acc: 0.8845 - val_loss: 0.4687 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4536 - acc: 0.8859Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 541us/step - loss: 0.4593 - acc: 0.8845 - val_loss: 0.4754 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.8824Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 539us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4719 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4279 - acc: 0.8906Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 701us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4712 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4715 - acc: 0.8816Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 765us/step - loss: 0.4597 - acc: 0.8845 - val_loss: 0.4693 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 620us/step - loss: 0.4603 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 687us/step - loss: 0.4640 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 745us/step - loss: 0.4620 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 482us/step - loss: 0.4607 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 537us/step - loss: 0.4599 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 586us/step - loss: 0.4600 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 549us/step - loss: 0.4595 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 546us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 563us/step - loss: 0.4604 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.4580 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 572us/step - loss: 0.4613 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 490us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 455us/step - loss: 0.4590 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 509us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 516us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 689us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 790us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 697us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 712us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 722us/step - loss: 0.4581 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 622us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 638us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 642us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 660us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 673us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 663us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 680us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 810us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 548us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 637us/step - loss: 0.4569 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 576us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 691us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 550us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 599us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 552us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 594us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 636us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 563us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 630us/step - loss: 0.4555 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 499us/step - loss: 0.4572 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 702us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 602us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 629us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 708us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 729us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 634us/step - loss: 0.4554 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 717us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 762us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 762us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 554us/step - loss: 0.4540 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 694us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 773us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 696us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 706us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 663us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 677us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 598us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 605us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 604us/step - loss: 0.4570 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 9\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5765 - acc: 0.8240Epoch 00001: val_loss improved from inf to 0.36492, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 962us/step - loss: 0.5618 - acc: 0.8348 - val_loss: 0.3649 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4975 - acc: 0.8766Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 569us/step - loss: 0.5032 - acc: 0.8743 - val_loss: 0.5385 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5040 - acc: 0.8720Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 530us/step - loss: 0.4962 - acc: 0.8743 - val_loss: 0.4038 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5019 - acc: 0.8750Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 565us/step - loss: 0.5085 - acc: 0.8743 - val_loss: 0.4311 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.5035 - acc: 0.8750Epoch 00005: val_loss improved from 0.36492 to 0.36343, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 649us/step - loss: 0.5003 - acc: 0.8743 - val_loss: 0.3634 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.8750Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 551us/step - loss: 0.4933 - acc: 0.8743 - val_loss: 0.3788 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.5015 - acc: 0.8720Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 525us/step - loss: 0.4951 - acc: 0.8743 - val_loss: 0.3648 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4812 - acc: 0.8783Epoch 00008: val_loss improved from 0.36343 to 0.36237, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 746us/step - loss: 0.4916 - acc: 0.8743 - val_loss: 0.3624 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4785 - acc: 0.8781Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 571us/step - loss: 0.4908 - acc: 0.8743 - val_loss: 0.3763 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4896 - acc: 0.8750Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 533us/step - loss: 0.4898 - acc: 0.8743 - val_loss: 0.3838 - val_acc: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8914Epoch 00001: val_loss improved from inf to 0.49390, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 742us/step - loss: 0.4483 - acc: 0.8889 - val_loss: 0.4939 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4533 - acc: 0.8849Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 740us/step - loss: 0.4471 - acc: 0.8889 - val_loss: 0.5003 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4429 - acc: 0.8891Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 675us/step - loss: 0.4449 - acc: 0.8889 - val_loss: 0.4940 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4377 - acc: 0.8922Epoch 00004: val_loss improved from 0.49390 to 0.48970, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 647us/step - loss: 0.4455 - acc: 0.8889 - val_loss: 0.4897 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8884Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 771us/step - loss: 0.4455 - acc: 0.8889 - val_loss: 0.4900 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4502 - acc: 0.8875Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 735us/step - loss: 0.4456 - acc: 0.8889 - val_loss: 0.4902 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4572 - acc: 0.8844Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 674us/step - loss: 0.4453 - acc: 0.8889 - val_loss: 0.5005 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4257 - acc: 0.8958Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 821us/step - loss: 0.4448 - acc: 0.8889 - val_loss: 0.4917 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4588 - acc: 0.8844Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 794us/step - loss: 0.4472 - acc: 0.8889 - val_loss: 0.4942 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4557 - acc: 0.8849Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 914us/step - loss: 0.4451 - acc: 0.8889 - val_loss: 0.4977 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8869Epoch 00001: val_loss improved from inf to 0.49741, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 726us/step - loss: 0.4444 - acc: 0.8874 - val_loss: 0.4974 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4524 - acc: 0.8844Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 753us/step - loss: 0.4436 - acc: 0.8874 - val_loss: 0.5095 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4461 - acc: 0.8859Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 622us/step - loss: 0.4412 - acc: 0.8874 - val_loss: 0.5140 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8869Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 1s 801us/step - loss: 0.4418 - acc: 0.8874 - val_loss: 0.5173 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8869Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 722us/step - loss: 0.4440 - acc: 0.8874 - val_loss: 0.5196 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4512 - acc: 0.8844Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 0s 637us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5314 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4521 - acc: 0.8844Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 746us/step - loss: 0.4435 - acc: 0.8874 - val_loss: 0.5243 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4603 - acc: 0.8837Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 645us/step - loss: 0.4441 - acc: 0.8874 - val_loss: 0.5332 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4210 - acc: 0.8941Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 656us/step - loss: 0.4409 - acc: 0.8874 - val_loss: 0.5312 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8869Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 803us/step - loss: 0.4421 - acc: 0.8874 - val_loss: 0.5423 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4774 - acc: 0.8816Epoch 00001: val_loss improved from inf to 0.46707, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 727us/step - loss: 0.4668 - acc: 0.8845 - val_loss: 0.4671 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4748 - acc: 0.8812Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 858us/step - loss: 0.4650 - acc: 0.8845 - val_loss: 0.4723 - val_acc: 0.8816\n",
      "Epoch 3/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4737 - acc: 0.8832Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 748us/step - loss: 0.4645 - acc: 0.8845 - val_loss: 0.4681 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4682 - acc: 0.8832Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 697us/step - loss: 0.4631 - acc: 0.8845 - val_loss: 0.4680 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4657 - acc: 0.8828Epoch 00005: val_loss improved from 0.46707 to 0.46604, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 648us/step - loss: 0.4597 - acc: 0.8845 - val_loss: 0.4660 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4740 - acc: 0.8797Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 875us/step - loss: 0.4568 - acc: 0.8845 - val_loss: 0.4807 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4714 - acc: 0.8799Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 810us/step - loss: 0.4640 - acc: 0.8845 - val_loss: 0.4765 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4581 - acc: 0.8869Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 1s 844us/step - loss: 0.4622 - acc: 0.8845 - val_loss: 0.4774 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.8884Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 853us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4698 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4482 - acc: 0.8898Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 689us/step - loss: 0.4601 - acc: 0.8845 - val_loss: 0.4678 - val_acc: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 764us/step - loss: 0.4626 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 695us/step - loss: 0.4615 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 702us/step - loss: 0.4625 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 579us/step - loss: 0.4586 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 700us/step - loss: 0.4620 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 582us/step - loss: 0.4635 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 624us/step - loss: 0.4599 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 579us/step - loss: 0.4605 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 619us/step - loss: 0.4606 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 684us/step - loss: 0.4592 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 540us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 545us/step - loss: 0.4604 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 602us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 683us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 644us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 610us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 651us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 606us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 664us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 545us/step - loss: 0.4583 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 569us/step - loss: 0.4554 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 530us/step - loss: 0.4600 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 578us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 590us/step - loss: 0.4587 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 591us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 576us/step - loss: 0.4562 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 689us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 756us/step - loss: 0.4588 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 631us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 788us/step - loss: 0.4578 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 697us/step - loss: 0.4527 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 725us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 724us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 857us/step - loss: 0.4566 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 630us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 655us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 547us/step - loss: 0.4593 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 560us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 574us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 588us/step - loss: 0.4592 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 852us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 736us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 589us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 650us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 574us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 620us/step - loss: 0.4557 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 759us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 797us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 758us/step - loss: 0.4581 - acc: 0.8838 0s - loss: 0.4135 - acc:\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 596us/step - loss: 0.4591 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 707us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 605us/step - loss: 0.4549 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 711us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 773us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 594us/step - loss: 0.4583 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 742us/step - loss: 0.4575 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 618us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 793us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 595us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 592us/step - loss: 0.4565 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "AlgoCrossValIter - 10\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.6271 - acc: 0.8313Epoch 00001: val_loss improved from inf to 0.62058, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 975us/step - loss: 0.6224 - acc: 0.8319 - val_loss: 0.6206 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4932 - acc: 0.8832Epoch 00002: val_loss improved from 0.62058 to 0.42365, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 897us/step - loss: 0.5125 - acc: 0.8743 - val_loss: 0.4236 - val_acc: 0.9123\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5025 - acc: 0.8750Epoch 00003: val_loss improved from 0.42365 to 0.36835, saving model to best-model-conll.hdfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5059 - acc: 0.8743 - val_loss: 0.3684 - val_acc: 0.9123\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.8750Epoch 00004: val_loss improved from 0.36835 to 0.36752, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 979us/step - loss: 0.4983 - acc: 0.8743 - val_loss: 0.3675 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4745 - acc: 0.8812Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 649us/step - loss: 0.4994 - acc: 0.8743 - val_loss: 0.5450 - val_acc: 0.9123\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.5035 - acc: 0.8750Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 775us/step - loss: 0.5023 - acc: 0.8743 - val_loss: 0.3735 - val_acc: 0.9123\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.8720Epoch 00007: val_loss improved from 0.36752 to 0.36331, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 736us/step - loss: 0.4911 - acc: 0.8743 - val_loss: 0.3633 - val_acc: 0.9123\n",
      "Epoch 8/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4945 - acc: 0.8766Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 687us/step - loss: 0.4980 - acc: 0.8743 - val_loss: 0.3973 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4808 - acc: 0.8783Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 836us/step - loss: 0.4910 - acc: 0.8743 - val_loss: 0.4107 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4894 - acc: 0.8719Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 742us/step - loss: 0.4902 - acc: 0.8743 - val_loss: 0.3693 - val_acc: 0.9123\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4578 - acc: 0.8872Epoch 00001: val_loss improved from inf to 0.49181, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 669us/step - loss: 0.4461 - acc: 0.8889 - val_loss: 0.4918 - val_acc: 0.8684\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4504 - acc: 0.8875Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 1s 731us/step - loss: 0.4462 - acc: 0.8889 - val_loss: 0.4971 - val_acc: 0.8684\n",
      "Epoch 3/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8884Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 726us/step - loss: 0.4467 - acc: 0.8889 - val_loss: 0.4991 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4277 - acc: 0.8947Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 598us/step - loss: 0.4455 - acc: 0.8889 - val_loss: 0.4976 - val_acc: 0.8684\n",
      "Epoch 5/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8884Epoch 00005: val_loss improved from 0.49181 to 0.49152, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 866us/step - loss: 0.4445 - acc: 0.8889 - val_loss: 0.4915 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4091 - acc: 0.8958Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 834us/step - loss: 0.4445 - acc: 0.8889 - val_loss: 0.4922 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4456 - acc: 0.8906Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 589us/step - loss: 0.4453 - acc: 0.8889 - val_loss: 0.4961 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4095 - acc: 0.8980Epoch 00008: val_loss improved from 0.49152 to 0.48918, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 769us/step - loss: 0.4440 - acc: 0.8889 - val_loss: 0.4892 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4449 - acc: 0.8899Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 1s 797us/step - loss: 0.4460 - acc: 0.8889 - val_loss: 0.4901 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4373 - acc: 0.8906Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 632us/step - loss: 0.4434 - acc: 0.8889 - val_loss: 0.4914 - val_acc: 0.8684\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8884Epoch 00001: val_loss improved from inf to 0.49527, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 0s 581us/step - loss: 0.4441 - acc: 0.8874 - val_loss: 0.4953 - val_acc: 0.8728\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4433 - acc: 0.8875Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 671us/step - loss: 0.4420 - acc: 0.8874 - val_loss: 0.5044 - val_acc: 0.8728\n",
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4420 - acc: 0.8875Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 0s 665us/step - loss: 0.4409 - acc: 0.8874 - val_loss: 0.5045 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4447 - acc: 0.8875Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 622us/step - loss: 0.4413 - acc: 0.8874 - val_loss: 0.5081 - val_acc: 0.8728\n",
      "Epoch 5/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4448 - acc: 0.8865Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 1s 750us/step - loss: 0.4421 - acc: 0.8874 - val_loss: 0.5128 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4446 - acc: 0.8875Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 731us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5188 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8869Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 0s 536us/step - loss: 0.4433 - acc: 0.8874 - val_loss: 0.5199 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8854Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 535us/step - loss: 0.4416 - acc: 0.8874 - val_loss: 0.5236 - val_acc: 0.8728\n",
      "Epoch 9/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8884Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 716us/step - loss: 0.4417 - acc: 0.8874 - val_loss: 0.5255 - val_acc: 0.8728\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8884Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 0s 664us/step - loss: 0.4408 - acc: 0.8874 - val_loss: 0.5328 - val_acc: 0.8728\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 684 samples, validate on 228 samples\n",
      "Epoch 1/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4603 - acc: 0.8872Epoch 00001: val_loss improved from inf to 0.46599, saving model to best-model-conll.hdfs\n",
      "684/684 [==============================] - 1s 770us/step - loss: 0.4637 - acc: 0.8845 - val_loss: 0.4660 - val_acc: 0.8816\n",
      "Epoch 2/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4428 - acc: 0.8859Epoch 00002: val_loss did not improve\n",
      "684/684 [==============================] - 0s 578us/step - loss: 0.4628 - acc: 0.8845 - val_loss: 0.4676 - val_acc: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4569 - acc: 0.8859Epoch 00003: val_loss did not improve\n",
      "684/684 [==============================] - 1s 778us/step - loss: 0.4620 - acc: 0.8845 - val_loss: 0.4678 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.8839Epoch 00004: val_loss did not improve\n",
      "684/684 [==============================] - 0s 725us/step - loss: 0.4608 - acc: 0.8845 - val_loss: 0.4697 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4574 - acc: 0.8859Epoch 00005: val_loss did not improve\n",
      "684/684 [==============================] - 0s 672us/step - loss: 0.4624 - acc: 0.8845 - val_loss: 0.4709 - val_acc: 0.8816\n",
      "Epoch 6/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4646 - acc: 0.8819Epoch 00006: val_loss did not improve\n",
      "684/684 [==============================] - 1s 731us/step - loss: 0.4590 - acc: 0.8845 - val_loss: 0.4692 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "640/684 [===========================>..] - ETA: 0s - loss: 0.4611 - acc: 0.8844Epoch 00007: val_loss did not improve\n",
      "684/684 [==============================] - 1s 787us/step - loss: 0.4616 - acc: 0.8845 - val_loss: 0.4661 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "576/684 [========================>.....] - ETA: 0s - loss: 0.4842 - acc: 0.8785Epoch 00008: val_loss did not improve\n",
      "684/684 [==============================] - 0s 627us/step - loss: 0.4609 - acc: 0.8845 - val_loss: 0.4691 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "608/684 [=========================>....] - ETA: 0s - loss: 0.4632 - acc: 0.8849Epoch 00009: val_loss did not improve\n",
      "684/684 [==============================] - 0s 730us/step - loss: 0.4587 - acc: 0.8845 - val_loss: 0.4719 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.4654 - acc: 0.8824Epoch 00010: val_loss did not improve\n",
      "684/684 [==============================] - 1s 813us/step - loss: 0.4599 - acc: 0.8845 - val_loss: 0.4693 - val_acc: 0.8816\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 665us/step - loss: 0.4624 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 520us/step - loss: 0.4615 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 662us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 700us/step - loss: 0.4623 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 616us/step - loss: 0.4596 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 752us/step - loss: 0.4605 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 650us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.4598 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 445us/step - loss: 0.4591 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 619us/step - loss: 0.4600 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 560us/step - loss: 0.4596 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 646us/step - loss: 0.4597 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 507us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 618us/step - loss: 0.4601 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 478us/step - loss: 0.4568 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 518us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 497us/step - loss: 0.4592 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 469us/step - loss: 0.4588 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 516us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 704us/step - loss: 0.4586 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 682us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 599us/step - loss: 0.4582 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 589us/step - loss: 0.4578 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 660us/step - loss: 0.4558 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 681us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 749us/step - loss: 0.4573 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 656us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 874us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 533us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 644us/step - loss: 0.4569 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 606us/step - loss: 0.4584 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 705us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 564us/step - loss: 0.4559 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 639us/step - loss: 0.4563 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 477us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 516us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 548us/step - loss: 0.4574 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 648us/step - loss: 0.4569 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 518us/step - loss: 0.4576 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 563us/step - loss: 0.4561 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 0s 547us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 570us/step - loss: 0.4580 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 592us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 766us/step - loss: 0.4570 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 501us/step - loss: 0.4564 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 562us/step - loss: 0.4577 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 671us/step - loss: 0.4565 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 465us/step - loss: 0.4560 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 475us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 480us/step - loss: 0.4574 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n",
      "Train on 912 samples, validate on 0 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 628us/step - loss: 0.4567 - acc: 0.8838\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 568us/step - loss: 0.4573 - acc: 0.8838 0s - loss: 0.4471 - acc: \n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 782us/step - loss: 0.4556 - acc: 0.8838\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 661us/step - loss: 0.4581 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 551us/step - loss: 0.4556 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 0s 497us/step - loss: 0.4579 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 683us/step - loss: 0.4572 - acc: 0.8838\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 643us/step - loss: 0.4571 - acc: 0.8838\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 531us/step - loss: 0.4585 - acc: 0.8838\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 565us/step - loss: 0.4564 - acc: 0.8838\n",
      "number of correct positive predictions is 0\n",
      "number of correct positive predictions is 0\n",
      "number of position exple is 0\n",
      "Recall and precision are 0\n",
      "number of correct positive predictions is 0\n"
     ]
    }
   ],
   "source": [
    "m = create_model(X_encoded.shape[1], len(tagSet))\n",
    "resultCrossVal, trainByTagResult, testByTagResult, ewoByTagResult = algoCrossVal(m, X_encoded, y, X_ewo_encoded, y_ewo, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    0    0    0    0    0    0    0    0    0\n",
       "F1-ewo    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "F1-test   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "F1-train  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "P_ewo     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "P_test    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "P_train   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "R_ewo     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "R_test    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "R_train   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if with_encoding:\n",
    "    resultCrossVal.to_csv(\"results/merge-{}-encoding.csv\".format(max_depth))\n",
    "else:\n",
    "    resultCrossVal.to_csv(\"results/merge-{}-no-encoding.csv\".format(max_depth))\n",
    "resultCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "F1-ewo    NaN\n",
       "F1-test   0.0\n",
       "F1-train  NaN\n",
       "P_ewo     0.0\n",
       "P_test    0.0\n",
       "P_train   0.0\n",
       "R_ewo     0.0\n",
       "R_test    0.0\n",
       "R_train   0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-ewo</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-test</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-train</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_ewo</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_test</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_train</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ewo</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_test</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_train</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "F1-ewo    NaN\n",
       "F1-test   0.0\n",
       "F1-train  NaN\n",
       "P_ewo     0.0\n",
       "P_test    0.0\n",
       "P_train   0.0\n",
       "R_ewo     0.0\n",
       "R_test    0.0\n",
       "R_train   0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultCrossVal.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "      <td>93.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "      <td>88.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        0        0        0        0        0        0  \\\n",
       "F1-LOC       NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "F1-MISC      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "F1-O      93.829   93.829   93.829   93.829   93.829   93.829   93.829   \n",
       "F1-ORG     0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "F1-PER       NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "P-LOC      0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "P-MISC     0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "P-O       88.379   88.379   88.379   88.379   88.379   88.379   88.379   \n",
       "P-ORG      0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "P-PER      0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "R-LOC      0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "R-MISC     0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "R-O      100.000  100.000  100.000  100.000  100.000  100.000  100.000   \n",
       "R-ORG      0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "R-PER      0.000    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "\n",
       "               0        0        0  \n",
       "F1-LOC       NaN      NaN      NaN  \n",
       "F1-MISC      NaN      NaN      NaN  \n",
       "F1-O      93.829   93.829   93.829  \n",
       "F1-ORG     0.000    0.000    0.000  \n",
       "F1-PER       NaN      NaN      NaN  \n",
       "P-LOC      0.000    0.000    0.000  \n",
       "P-MISC     0.000    0.000    0.000  \n",
       "P-O       88.379   88.379   88.379  \n",
       "P-ORG      0.000    0.000    0.000  \n",
       "P-PER      0.000    0.000    0.000  \n",
       "R-LOC      0.000    0.000    0.000  \n",
       "R-MISC     0.000    0.000    0.000  \n",
       "R-O      100.000  100.000  100.000  \n",
       "R-ORG      0.000    0.000    0.000  \n",
       "R-PER      0.000    0.000    0.000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if with_encoding:\n",
    "    trainByTagResult.to_csv(\"results/train-by-tag-merge-{}-encoding.csv\".format(max_depth))\n",
    "else:\n",
    "    trainByTagResult.to_csv(\"results/train-by-tag-merge-{}-no-encoding.csv\".format(max_depth))\n",
    "trainByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>93.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>88.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "F1-LOC       NaN\n",
       "F1-MISC      NaN\n",
       "F1-O      93.829\n",
       "F1-ORG     0.000\n",
       "F1-PER       NaN\n",
       "P-LOC      0.000\n",
       "P-MISC     0.000\n",
       "P-O       88.379\n",
       "P-ORG      0.000\n",
       "P-PER      0.000\n",
       "R-LOC      0.000\n",
       "R-MISC     0.000\n",
       "R-O      100.000\n",
       "R-ORG      0.000\n",
       "R-PER      0.000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>1.497956e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "F1-LOC            NaN\n",
       "F1-MISC           NaN\n",
       "F1-O     1.497956e-14\n",
       "F1-ORG   0.000000e+00\n",
       "F1-PER            NaN\n",
       "P-LOC    0.000000e+00\n",
       "P-MISC   0.000000e+00\n",
       "P-O      0.000000e+00\n",
       "P-ORG    0.000000e+00\n",
       "P-PER    0.000000e+00\n",
       "R-LOC    0.000000e+00\n",
       "R-MISC   0.000000e+00\n",
       "R-O      0.000000e+00\n",
       "R-ORG    0.000000e+00\n",
       "R-PER    0.000000e+00"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "      <td>37.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "      <td>35.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       0       0       0       0       0       0       0  \\\n",
       "F1-LOC    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "F1-MISC   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "F1-O     37.529  37.529  37.529  37.529  37.529  37.529  37.529  37.529   \n",
       "F1-ORG    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "F1-PER    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "P-LOC     0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "P-MISC    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "P-O      35.351  35.351  35.351  35.351  35.351  35.351  35.351  35.351   \n",
       "P-ORG     0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "P-PER     0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "R-LOC     0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "R-MISC    0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "R-O      40.000  40.000  40.000  40.000  40.000  40.000  40.000  40.000   \n",
       "R-ORG     0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "R-PER     0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   \n",
       "\n",
       "              0       0  \n",
       "F1-LOC    0.000   0.000  \n",
       "F1-MISC   0.000   0.000  \n",
       "F1-O     37.529  37.529  \n",
       "F1-ORG    0.000   0.000  \n",
       "F1-PER    0.000   0.000  \n",
       "P-LOC     0.000   0.000  \n",
       "P-MISC    0.000   0.000  \n",
       "P-O      35.351  35.351  \n",
       "P-ORG     0.000   0.000  \n",
       "P-PER     0.000   0.000  \n",
       "R-LOC     0.000   0.000  \n",
       "R-MISC    0.000   0.000  \n",
       "R-O      40.000  40.000  \n",
       "R-ORG     0.000   0.000  \n",
       "R-PER     0.000   0.000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if with_encoding:\n",
    "    testByTagResult.to_csv(\"results/test-by-tag-merge-{}-encoding.csv\".format(max_depth))\n",
    "else:\n",
    "    testByTagResult.to_csv(\"results/test-by-tag-merge-{}-no-encoding.csv\".format(max_depth))\n",
    "testByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>37.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>35.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "F1-LOC    0.000\n",
       "F1-MISC   0.000\n",
       "F1-O     37.529\n",
       "F1-ORG    0.000\n",
       "F1-PER    0.000\n",
       "P-LOC     0.000\n",
       "P-MISC    0.000\n",
       "P-O      35.351\n",
       "P-ORG     0.000\n",
       "P-PER     0.000\n",
       "R-LOC     0.000\n",
       "R-MISC    0.000\n",
       "R-O      40.000\n",
       "R-ORG     0.000\n",
       "R-PER     0.000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "F1-LOC   0.0\n",
       "F1-MISC  0.0\n",
       "F1-O     0.0\n",
       "F1-ORG   0.0\n",
       "F1-PER   0.0\n",
       "P-LOC    0.0\n",
       "P-MISC   0.0\n",
       "P-O      0.0\n",
       "P-ORG    0.0\n",
       "P-PER    0.0\n",
       "R-LOC    0.0\n",
       "R-MISC   0.0\n",
       "R-O      0.0\n",
       "R-ORG    0.0\n",
       "R-PER    0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testByTagResult.std(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>89.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       0       0       0       0       0       0       0  \\\n",
       "F1-LOC      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "F1-MISC     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "F1-O      94.46   94.46   94.46   94.46   94.46   94.46   94.46   94.46   \n",
       "F1-ORG      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "F1-PER      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "P-LOC      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "P-MISC     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "P-O       89.50   89.50   89.50   89.50   89.50   89.50   89.50   89.50   \n",
       "P-ORG      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "P-PER      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "R-LOC      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "R-MISC     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "R-O      100.00  100.00  100.00  100.00  100.00  100.00  100.00  100.00   \n",
       "R-ORG      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "R-PER      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "\n",
       "              0       0  \n",
       "F1-LOC      NaN     NaN  \n",
       "F1-MISC     NaN     NaN  \n",
       "F1-O      94.46   94.46  \n",
       "F1-ORG      NaN     NaN  \n",
       "F1-PER      NaN     NaN  \n",
       "P-LOC      0.00    0.00  \n",
       "P-MISC     0.00    0.00  \n",
       "P-O       89.50   89.50  \n",
       "P-ORG      0.00    0.00  \n",
       "P-PER      0.00    0.00  \n",
       "R-LOC      0.00    0.00  \n",
       "R-MISC     0.00    0.00  \n",
       "R-O      100.00  100.00  \n",
       "R-ORG      0.00    0.00  \n",
       "R-PER      0.00    0.00  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if with_encoding:\n",
    "    ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{}-encoding.csv\".format(max_depth))\n",
    "else:\n",
    "    ewoByTagResult.to_csv(\"results/ewo-by-tag-merge-{}-no-encoding.csv\".format(max_depth))\n",
    "ewoByTagResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>94.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>89.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "F1-LOC      NaN\n",
       "F1-MISC     NaN\n",
       "F1-O      94.46\n",
       "F1-ORG      NaN\n",
       "F1-PER      NaN\n",
       "P-LOC      0.00\n",
       "P-MISC     0.00\n",
       "P-O       89.50\n",
       "P-ORG      0.00\n",
       "P-PER      0.00\n",
       "R-LOC      0.00\n",
       "R-MISC     0.00\n",
       "R-O      100.00\n",
       "R-ORG      0.00\n",
       "R-PER      0.00"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.mean(axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-LOC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-MISC</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-O</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-ORG</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-PER</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-LOC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-MISC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-O</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-ORG</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-PER</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-LOC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-MISC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-O</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-ORG</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-PER</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "F1-LOC   NaN\n",
       "F1-MISC  NaN\n",
       "F1-O     0.0\n",
       "F1-ORG   NaN\n",
       "F1-PER   NaN\n",
       "P-LOC    0.0\n",
       "P-MISC   0.0\n",
       "P-O      0.0\n",
       "P-ORG    0.0\n",
       "P-PER    0.0\n",
       "R-LOC    0.0\n",
       "R-MISC   0.0\n",
       "R-O      0.0\n",
       "R-ORG    0.0\n",
       "R-PER    0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewoByTagResult.std(axis=1).to_frame()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-ner.ipynb",
   "provenance": [
    {
     "file_id": "1bSiRRO29rixupIV6ume9T9B4KUKtYVKI",
     "timestamp": 1513688449690
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
